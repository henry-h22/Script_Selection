( henrySimon_00001 "zone" )
( henrySimon_00002 "e" )
( henrySimon_00003 "Joins are bad!" )
( henrySimon_00004 "I'll make my evaluation" )
( henrySimon_00005 "When I say "unit-in-context" I'm talking about the all the different diphones in all the different linguistic contexts" )
( henrySimon_00006 "We get a great, big, long HMM" )
( henrySimon_00007 "So, it'll be a weighted sum of mismatches" )
( henrySimon_00008 "Now we have a full working speech synthesizer" )
( henrySimon_00009 "However, we're not quite there yet" )
( henrySimon_00010 "And we need a language model" )
( henrySimon_00011 "It's local" )
( henrySimon_00012 "Unfortunately Taylor fails to label his axes" )
( henrySimon_00013 "I've no idea how you would do that" )
( henrySimon_00014 "Try another sequence" )
( henrySimon_00015 "Perhaps we'll normalize "number of types" by "the length of the sentence"" )
( henrySimon_00016 "Now I'd like to find out which  of them was the best idea" )
( henrySimon_00017 "They will propagate" )
( henrySimon_00018 "I'll remove it from the large database" )
( henrySimon_00019 "But this is very uncommon these days" )
( henrySimon_00020 "We could predict simple acoustic things such as F0" )
( henrySimon_00021 "And that's called rounding" )
( henrySimon_00022 "Maybe then we can publish a paper" )
( henrySimon_00023 "I am going to shorten that" )
( henrySimon_00024 "So let's 'grep'" )
( henrySimon_00025 "Who those listeners might be" )
( henrySimon_00026 "We just get natural output" )
( henrySimon_00027 "We are better off using diphones" )
( henrySimon_00028 "Hopefully you're doing the exercise at the same time" )
( henrySimon_00029 "The motivation for that should be obvious" )
( henrySimon_00030 "That measure of "sounding the same" involves an extra step of making some prediction of the acoustic properties of those target units" )
( henrySimon_00031 "They're both also voiced" )
( henrySimon_00032 "Or vice versa" )
( henrySimon_00033 "That will fail to capture things like sudden changes of direction" )
( henrySimon_00034 "The outcome helps me make a decision" )
( henrySimon_00035 "We've got "context" which is the combination of linguistic features in the environment of this unit" )
( henrySimon_00036 "So it's a hybrid sorting on rating task" )
( henrySimon_00037 "Here's what our speaker said" )
( henrySimon_00038 "So to wrap this part up" )
( henrySimon_00039 "We have to look at the waveforms (i" )
( henrySimon_00040 "The function simply worked with symbolic features" )
( henrySimon_00041 "That doesn't need to be a full-blown N-gram" )
( henrySimon_00042 "That's not true" )
( henrySimon_00043 "So the potential is for extremely high quality" )
( henrySimon_00044 "The algorithm requires the large corpus" )
( henrySimon_00045 "Maybe we've taken lots of novels from Project Gutenberg" )
( henrySimon_00046 "So we should be talking about "base unit types in linguistic contexts"" )
( henrySimon_00047 "Or it has, optionally, vowel reduction like this" )
( henrySimon_00048 "Cepstral coefficients would be a good choice there" )
( henrySimon_00049 "There's a lattice of paths" )
( henrySimon_00050 "There's no guarantee of that" )
( henrySimon_00051 "Let's spell that out" )
( henrySimon_00052 "This is completely possible" )
( henrySimon_00053 "Here's an old-fashioned way of doing that: "translate" ('tr') it" )
( henrySimon_00054 "Let's work through an example to make that crystal clear" )
( henrySimon_00055 "Let's just give them names: refer to them a Path A and Path B" )
( henrySimon_00056 "You might not actually store it in memory" )
( henrySimon_00057 "The key concepts that are involved" )
( henrySimon_00058 "This HMM now is an HMM of this little phrase" )
( henrySimon_00059 "We've understood now this "domino effect": that one choice, anywhere in the search, has an effect potentially on all of the other units that are chosen to go with it, because of the join cost" )
( henrySimon_00060 "That's five by five, 25 things" )
( henrySimon_00061 "it just takes a moment to run because we're going through this big document" )
( henrySimon_00062 "That needs to come from somewhere" )
( henrySimon_00063 "I would only really, ever trust people typing in what they heard as a task" )
( henrySimon_00064 "I use "extended grip" ('egrep') - it's a bit more powerful" )
( henrySimon_00065 "It could also be the half-phone" )
( henrySimon_00066 "I'm now going to count how often each letter occurs" )
( henrySimon_00067 "and various other diphones have gone" )
( henrySimon_00068 "It's lower than all of the rest" )
( henrySimon_00069 "Everything else - for example prosody - had to be imposed using fairly extensive signal manipulation" )
( henrySimon_00070 "It might be hard to read newspaper sentences out loud" )
( henrySimon_00071 "We say those units are heterogeneous" )
( henrySimon_00072 "Do the readings to understand precisely what he means by that" )
( henrySimon_00073 "That's a rather cumbersome phrase!" )
( henrySimon_00074 "Think about why we even need to evaluate" )
( henrySimon_00075 "That's not enough" )
( henrySimon_00076 "And there is our kind-of classical Zipf-like distribution" )
( henrySimon_00077 "That's all we have to go on" )
( henrySimon_00078 "So how big to make the test" )
( henrySimon_00079 "We could do anything we like" )
( henrySimon_00080 "Go and do this on your own" )
( henrySimon_00081 "We decided when to do it" )
( henrySimon_00082 "The search will just find the best overall path" )
( henrySimon_00083 "Let's wrap up our discussion of the target cost function" )
( henrySimon_00084 "Before you look at this module, you should just  check that you already know the following things" )
( henrySimon_00085 "We go through the short pause model" )
( henrySimon_00086 "We could go further" )
( henrySimon_00087 "For example we could make a complete closure, and let sound pressure release in an explosive fashion" )
( henrySimon_00088 "We have to figure out that for ourselves" )
( henrySimon_00089 "Maybe you could write it in Python" )
( henrySimon_00090 "For example, are listeners able to give absolute judgements about naturalness played a single sample with no reference" )
( henrySimon_00091 "Now there's already a huge number of assumptions in doing that" )
( henrySimon_00092 "and you can imagine how many more there are" )
( henrySimon_00093 "So what we do, we form groups of subjects, which are the rows of this square" )
( henrySimon_00094 "So let's finish by looking forward to what's coming up" )
( henrySimon_00095 "This is essentially just a Hidden Markov Model" )
( henrySimon_00096 "That's easy" )
( henrySimon_00097 "We want to achieve that with the smallest possible database" )
( henrySimon_00098 "Let's draw the arcs on the network" )
( henrySimon_00099 "The task now is to choose amongst them" )
( henrySimon_00100 "This model's just an HMM" )
( henrySimon_00101 "We don't need coverage" )
( henrySimon_00102 "We won't consider these in any great depth here" )
( henrySimon_00103 "On top of that phonetic labelling (or "segmentation"), we need to annotate the speech with all of the supra-segmental linguistic information: all the other things that the target cost might need to query" )
( henrySimon_00104 "and so on, all with weights accordingly" )
( henrySimon_00105 "So now on to how to do the evaluation" )
( henrySimon_00106 "That's probably but maybe not saying it" )
( henrySimon_00107 "We can push things through them one direction" )
( henrySimon_00108 "Or is it down near the bottom?" )
( henrySimon_00109 "What the stimulus should be" )
( henrySimon_00110 "I've only got a tiny database in this toy example, so I just found 5" )
( henrySimon_00111 "Equally, we could predict values for duration or energy (all correlates of prosody)" )
( henrySimon_00112 "But that's an open question" )
( henrySimon_00113 "So far, we only know how to compare them in terms of linguistic features, which both have" )
( henrySimon_00114 "Where are we going to find them, while offering a payment is usually effective" )
( henrySimon_00115 "Those points might be described" )
( henrySimon_00116 "We might have the noise that's always going to make the task harder" )
( henrySimon_00117 "The acoustic predictions will have an intrinsic error in them" )
( henrySimon_00118 "Let's pursue the idea of diphones for a moment" )
( henrySimon_00119 "We could keep doing that for all of the linguistic context factors that we think are important" )
( henrySimon_00120 "Here too, there's the third dimension" )
( henrySimon_00121 "Will a listener notice there's a join?" )
( henrySimon_00122 "There's not a whole lot to do with perception in here" )
( henrySimon_00123 "Our pronunciation model is basically a dictionary" )
( henrySimon_00124 "That's what these red lines indicate" )
( henrySimon_00125 "Taken together, they are frequent" )
( henrySimon_00126 "I've rewritten segments as diphones" )
( henrySimon_00127 "We can't change the code for  the purpose of testing it" )
( henrySimon_00128 "We could try and mitigate that by having multiple natural examples" )
( henrySimon_00129 "The payoff is speed" )
( henrySimon_00130 "Well, we have a choice" )
( henrySimon_00131 "If the contours are identical, the RMSE is zero" )
( henrySimon_00132 "Maybe you could have a neural network" )
( henrySimon_00133 "They're not widely used in  synthetic speech evaluation" )
( henrySimon_00134 "We'll think about what we're going   to ask our listeners to do" )
( henrySimon_00135 "How can we reduce the number of joins?" )
( henrySimon_00136 "Those are not the same thing as perception" )
( henrySimon_00137 "And now we need to think, how are they going to do on this task" )
( henrySimon_00138 "In other words, from a blank starting sheet without any prior information" )
( henrySimon_00139 "Maybe MFCCs" )
( henrySimon_00140 "There's an example in the table of where a "near match" might be OK" )
( henrySimon_00141 "I'm going to use the letter as the unit" )
( henrySimon_00142 "Now, you might be shouting out at this point that training the models on the same data we're aligning is cheating!" )
( henrySimon_00143 "That's coming next" )
( henrySimon_00144 "Imagine considering choosing this unit" )
( henrySimon_00145 "Older systems used to be built like that" )
( henrySimon_00146 "For example: is it near the roof of the mouth?" )
( henrySimon_00147 "We'll explore all paths in parallel, this way" )
( henrySimon_00148 "We have to automate it" )
( henrySimon_00149 "You've built that voice and listened to it and so you're asking yourself now, "How good is that synthetic voice?" We need to evaluate that, so the topic of the next module will be evaluation" )
( henrySimon_00150 "So again, we will get more joins in our units" )
( henrySimon_00151 "We could try modifying PESQ which has been done" )
( henrySimon_00152 "I'm not sure what it is, because it doesn't matter!" )
( henrySimon_00153 "That is that they're distributed very unevenly" )
( henrySimon_00154 "We're going to make a plan" )
( henrySimon_00155 "We're working with features that have already been produced by our front-end" )
( henrySimon_00156 "We now have a complete picture of unit selection" )
( henrySimon_00157 "They don't have waveforms" )
( henrySimon_00158 "So we can go off and fetch more from the database: we'll get all of them in fact" )
( henrySimon_00159 "So there are some modified versions, and they do work to some limited extent" )
( henrySimon_00160 "Let's wrap this part up with a little orientation, putting ourselves in the bigger picture to see how far we've got, and what's coming up" )
( henrySimon_00161 "That's the most common choice" )
( henrySimon_00162 "What motivates the method?" )
( henrySimon_00163 "Unfortunately, if we enumerate all the possible contexts, they'll actually be pretty much infinite because context (theoretically at least) spans the entire sentence - possibly beyond" )
( henrySimon_00164 "That's already a schwa, so can't be reduced any further" )
( henrySimon_00165 "Then we could put zero join costs between pairs of half-phones that make up diphones" )
( henrySimon_00166 "Again we see the same sort of pattern we saw with letters" )
( henrySimon_00167 "We're going to attach all the information to the phoneme tier" )
( henrySimon_00168 "That's going to help get us out of a sparsity problem" )
( henrySimon_00169 "This state here is going to contain a Gaussian or Gaussian mixture model that emits observations with an appropriate distribution for silence" )
( henrySimon_00170 "We'd like those sentences to be heard by a set of listeners" )
( henrySimon_00171 "Which of those ideas was best?" )
( henrySimon_00172 "We're trying to guide   the future development of the system" )
( henrySimon_00173 "Our text selection algorithm will have very likely provided us with a script in an order of decreasing richness" )
( henrySimon_00174 "But we should exercise their use with caution and they're not a replacement for using listeners" )
( henrySimon_00175 "How should we record it? Do we need to be very careful about that?" )
( henrySimon_00176 "Then I'll repeat that procedure" )
( henrySimon_00177 "We just generalise that idea" )
( henrySimon_00178 "So Mel Cepstral distortion" )
( henrySimon_00179 "But there are some constraints" )
( henrySimon_00180 "Then we can combine the advantages of both types of sub-cost" )
( henrySimon_00181 "These are very much research tools" )
( henrySimon_00182 "So could even use minimal pairs" )
( henrySimon_00183 "We would choose the best path through that" )
( henrySimon_00184 "I'm going to write down my wish list" )
( henrySimon_00185 "We compare it to our other ideas" )
( henrySimon_00186 "We don't want a single listener's responses to have an undue influence on the overall statistics" )
( henrySimon_00187 "For example, in this piece of source code,   we can see who wrote it, so there's a  high chance there might be a bug here" )
( henrySimon_00188 "In fact, we won't even cut them up" )
( henrySimon_00189 "But I ask only for comparisons" )
( henrySimon_00190 "We might actually go much smaller than that, and in online situations where we don't have control over the listeners, and they're listening situation where they're recruited via the Web" )
( henrySimon_00191 "That's an articulatory process" )
( henrySimon_00192 "Let's think more generally about that" )
( henrySimon_00193 "That's a common term in speech coding" )
( henrySimon_00194 "And I'll take that idea forward and  the other ideas will stay on the shelf" )
( henrySimon_00195 "It's whatever the front-end might produce and whatever we might derive from that, such as these positional things" )
( henrySimon_00196 "And it needs to obtain their response" )
( henrySimon_00197 "I'm using over a thousand sentences of transcribed speech here, and in those thousand sentences there are a couple of phonemes that occurred fewer than a hundred times, regardless of the context" )
( henrySimon_00198 "And once we've finished evaluation, we  need to do something with what we've found" )
( henrySimon_00199 "We have measured things about their pupils" )
( henrySimon_00200 "The assumption here is that all subjects behave the same and that we can take five individual people, split the test across them and then aggregate the results" )
( henrySimon_00201 "Now, there might be two of our own systems,  like the four variants of my great ideas" )
( henrySimon_00202 "I was never taught this explicitly, and  I've never seen it really in a textbook" )
( henrySimon_00203 "We could look at the rate of change (the deltas)" )
( henrySimon_00204 "In a real system, the length of these lists of candidates will be much, much longer" )
( henrySimon_00205 "Underlying all of this there's an assumption" )
( henrySimon_00206 "the prosodic variation might be limited" )
( henrySimon_00207 "I also know that they happen at the end of a line" )
( henrySimon_00208 "Maybe there's a big F0 discontinuity" )
( henrySimon_00209 "We need to know a lot more about this database" )
( henrySimon_00210 "That's the process known as co-articulation" )
( henrySimon_00211 "Now, precisely how we know that, we'll cover in the module on the database, a little bit later" )
( henrySimon_00212 "We also know F0 for all the candidates" )
( henrySimon_00213 "And we put it in the listening test and in the same listening test are some variants on that system, which all are all really, really bad, our "quite good" system is going to get good scores" )
( henrySimon_00214 "Here's part of my very large text corpus, that I've put through my text-to-speech front end" )
( henrySimon_00215 "We're going to use a simple greedy algorithm" )
( henrySimon_00216 "An obvious one there is: if text normalisation goes  wrong - the synthesiser says the wrong words   and the listener understands the wrong thing" )
( henrySimon_00217 "This was covered in the course Speech Processing" )
( henrySimon_00218 "And then we look at the consistency across that to get a measure of how reliable our listening was" )
( henrySimon_00219 "Occasionally we might measure speaker similarity" )
( henrySimon_00220 "Unit selection errors might be that the units we  chose were from inappropriate contexts" )
( henrySimon_00221 "It's got the special property that each number appears in every row and every column just once" )
( henrySimon_00222 "We might prefer to have much, much shorter tasks" )
( henrySimon_00223 "This is about the simplest possible algorithm" )
( henrySimon_00224 "We just need to predict sufficient properties to enable a comparison with candidate units" )
( henrySimon_00225 "The number of concatenation points is the same" )
( henrySimon_00226 "The optional short pause model at the word juncture" )
( henrySimon_00227 "The exception to that would be an expert listener" )
( henrySimon_00228 "They're in fact a part of international standards" )
( henrySimon_00229 "A good way to do that would be dynamic time warping" )
( henrySimon_00230 "Imagine just asking for versions of each diphone in stressed and unstressed prosodic environments" )
( henrySimon_00231 "There are a few types up here that are very frequent" )
( henrySimon_00232 "That might be of individual components,   or the end-to-end system,  depending what we want to learn" )
( henrySimon_00233 "Let's do it with speech this time: transcribed speech" )
( henrySimon_00234 "We know that we keep coming across new words all the time" )
( henrySimon_00235 "If you don't like that one, pick any other model you like" )
( henrySimon_00236 "All modern methods of speech synthesis - including unit selection that we've already covered - rely on a fairly substantial database of recorded natural speech" )
( henrySimon_00237 "So, how open or closed is the vocal tract by the tongue?" )
( henrySimon_00238 "Let's convince ourselves that linguistic units of various types have got this Zipf-like distribution" )
( henrySimon_00239 "For example, in the front end,   things might go wrong very early in text normalisation,   the wrong words are said" )
( henrySimon_00240 "That's actually rarely used these days, much more common" )
( henrySimon_00241 "We're going to add a little rule-based pronunciation variation: we're going to allow every vowel to be reduced to schwa" )
( henrySimon_00242 "We might use throwaway listeners who are very unreliable" )
( henrySimon_00243 "I suggest doing it with words or with linguistic unit-types-in-context: perhaps something like triphones" )
( henrySimon_00244 "Let's summarize the key problems with diphone synthesis" )
( henrySimon_00245 "Now, you'll often see this curve called a Zipf distribution" )
( henrySimon_00246 "We can't push the errors back through them in the other direction" )
( henrySimon_00247 "We would like them to each synthesize the same set of sentences" )
( henrySimon_00248 "We can describe the linguistic context of a sound: for example, the preceding phoneme + the following phoneme" )
( henrySimon_00249 "We're going to use a technique borrowed from speech recognition" )
( henrySimon_00250 "As with most of the examples in this part of the course, I'm drawing my lattice in terms of whole phones because it's neater" )
( henrySimon_00251 "We'll compile this model with the pronunciation model, which essentially means replacing each word with its sub-word units" )
( henrySimon_00252 "We could throw away sentences with very low frequency or polysyllabic words that we think our speaker will find difficult" )
( henrySimon_00253 "It'll always give you the same sequence for the same input text" )
( henrySimon_00254 "So each word could have its canonical pronunciation, like this" )
( henrySimon_00255 "We're just going to sum up penalties for all of those mismatches" )
( henrySimon_00256 "That makes the calculation really simple, but it is a weakness" )
( henrySimon_00257 "We saw how the pronunciation model was simply the dictionary from our speech synthesizer with some rule-based vowel reduction" )
( henrySimon_00258 "Coming back to this terminology, we'll  sometimes see this term: "black box"" )
( henrySimon_00259 "So we would replace those targets with parameters: for example, F0 or some parameterization of the spectral envelope" )
( henrySimon_00260 "Now, even these simple descriptors  are probably not that simple" )
( henrySimon_00261 "What should we record? Before proceeding, let's do the usual check" )
( henrySimon_00262 "It would be better if we could soften that somewhat and say that that's a "near match" and maybe there should be a lower penalty in that case" )
( henrySimon_00263 "This is now when we're not allowed to  look inside and see how things work" )
( henrySimon_00264 "So for big differences, this measure is probably going to work, however, that relationship between Mel Cepstral Distortion and what listeners think isn't completely smooth and monotonic and so small differences are not going to be captured so reliably by this measure" )
( henrySimon_00265 "What we will do is look at a typical, simple approach to script design" )
( henrySimon_00266 "They're going to be given a task, and it's up to us what that task might be" )
( henrySimon_00267 "Let's pretend for a moment that these HMMs here are whole word models" )
( henrySimon_00268 "That seems a great idea because it's going to be be simple to deploy and it's going to be balanced because all listeners hear hear all stimuli" )
( henrySimon_00269 "The first one is not to stress the listeners out too much on very definitely not to allow them to become bored because their judgments might change" )
( henrySimon_00270 "This has got a fairly similar place of articulation to the desired (the target) left-phonetic-context of [b]" )
( henrySimon_00271 "We're not going to look in complete detail at the target cost function because that will come a little bit later, but we'll finish off by seeing how a search is conducted efficiently to find the optimal unit sequence" )
( henrySimon_00272 "And that would be our measure, and a large distance would imply less natural" )
( henrySimon_00273 "So that's about all we have to say about the evaluation of speech synthesis" )
( henrySimon_00274 "If there are N phoneme categories, there are about N^2 diphone types" )
( henrySimon_00275 "So here's our finite state network model of the pronunciation of the word /k ae n/, but it can also be reduced to /k ax n/" )
( henrySimon_00276 "The source of that weakness is the sparsity of these linguistic features, due to the extremely large number of permutations of possible values" )
( henrySimon_00277 "Now, of course there is one of the sequences that has the lowest total cost" )
( henrySimon_00278 "But it might be something else: maybe the other way around, or maybe something else" )
( henrySimon_00279 "If you're looking for a source of text to use in your own algorithm, the obvious choice is to go to Project Gutenberg where there's a repository of text of out of copyright novels, which you can scrape and use as a source of material" )
( henrySimon_00280 "We can't allow an individual subject to hear the same sentence more than once" )
( henrySimon_00281 "We still, though, might pay a little bit of attention to them and use some design text" )
( henrySimon_00282 "It's given me a sequence of phonemes, from which I've got the sequence of diphones" )
( henrySimon_00283 "Maybe we'll just take the log and then expressed these differences in semitones" )
( henrySimon_00284 "First we sort them into order, and then we'll put them through a tool called 'uniq'" )
( henrySimon_00285 "These have the nice property that within these lists, there's some phonetic balance" )
( henrySimon_00286 "There is a place where reasonably sophisticated models of perception in fact, things that have been fitted to perceptual data are widely used and are reliable" )
( henrySimon_00287 "And so it's possible to make a further contrast, for example between /p/ and /b/ by vibrating the vocal folds in the case of /b/" )
( henrySimon_00288 "Very often that will be done in a Web browser so that we could do these tests online" )
( henrySimon_00289 "But before I carry on, I'm going to cross off all the diphones that I got with that sentence" )
( henrySimon_00290 "Let's look at the sort of materials that are typical when testing intelligibility" )
( henrySimon_00291 "We have to ask ourselves: Would it even be possible to record one example of every unit-in-context? Let's just point out a little shorthand in the language I'm using here" )
( henrySimon_00292 "It's tempting just to choose that - because we'll make an instant local decision - and then repeat that for each target position, choosing its candidate with the lowest target cost" )
( henrySimon_00293 "All my diagrams were using whole phones, although that's not really a sensible choice in practice" )
( henrySimon_00294 "But throughout all of this, let's always remember that were not yet able to replace listeners" )
( henrySimon_00295 "We might distract the listener with a parallel task that's increasing their cognitive load" )
( henrySimon_00296 "And the most common form of that are sometimes known as the Harvard or the IEEE sentences" )
( henrySimon_00297 "A nice advantage of a half-phone system is that it can sometimes make joins at phone boundaries" )
( henrySimon_00298 "There are other ways than semantically unpredictable sentences to avoid the ceiling effect" )
( henrySimon_00299 "We're going to combine that similarity measure with a join cost to enable smooth concatenation" )
( henrySimon_00300 "That sudden change from increasing to decreasing will also be unnatural: listeners might notice" )
( henrySimon_00301 "That way, we can say anything, but we try and use the biggest units available in the database" )
( henrySimon_00302 "Therefore, rather than just having these base units, we'll have context-dependent versions or "flavours" of those units" )
( henrySimon_00303 "Are we going to do that   for an end-to-end Text-to-Speech  system: text in, synthetic speech out" )
( henrySimon_00304 "But if you go back to look at the material on token passing, you'll realize that we can ask the tokens to remember anything at all while they're passing through the HMM states, not just the ends of words" )
( henrySimon_00305 "How on earth will we get any prosody at all? How is prosody created using such a cost function?" )
( henrySimon_00306 "I'm just using it to make the diagrams simpler to draw and simpler for you to understand" )
( henrySimon_00307 "So we know we need to evaluate: to make decisions,  for example, about where to go with our research" )
( henrySimon_00308 "Let's draw a picture of what it would be like for diphone units, just so we see that it can be done" )
( henrySimon_00309 "So once again, for the transmission of natural speech, which gets distorted in transmission on these things either measure the receive signal or the difference between the transmitted and received signal" )
( henrySimon_00310 "The states are these words, and we just join them up with arcs, with an end state and a start state" )
( henrySimon_00311 "We're going to measure the two  principal things that we can:   the naturalness and the intelligibility" )
( henrySimon_00312 "Between words we always go through the short pause model, which can emit zero or more frames of silence" )
( henrySimon_00313 "Therefore the signal that we observe - the waveform - is a result of several interacting processes" )
( henrySimon_00314 "Also, the sort of variation we get in it might be unlike what we normally get in spoken language" )
( henrySimon_00315 "But in evaluating synthetic speech, we're usually more concerned with getting a lot of listeners" )
( henrySimon_00316 "There are methods out there to try and  probe people's effort or attention,   or all sorts of other factors" )
( henrySimon_00317 "So, I'd like you to go and play with this interactive example and then continue watching the videos" )
( henrySimon_00318 "You will see reports or evaluations that don't really say what they're looking for It's just preference" )
( henrySimon_00319 "We're going to do it in the only way we know how: that's the way that HTK does it in its simple HVite tool" )
( henrySimon_00320 "But intelligibility could also be impacted by   audible joins that disrupt the listener's perception" )
( henrySimon_00321 "We're going to have to use candidate units from mismatched non-identical linguistic contexts" )
( henrySimon_00322 "Imagine then adding all possible linguistic features and enumerating a very long wish list in this way" )
( henrySimon_00323 "In general, in a big system, we might find hundreds or thousands for some of the more common unit types" )
( henrySimon_00324 "So the questions we're going to answer in the next module are: Can we judge how good a synthetic voice is in isolation? Or, is it only possible to do that by comparing to some other system that's better or worse than it?" )
( henrySimon_00325 "That's a LOT of joins! We know that joins are the single biggest problem with unit selection speech synthesis" )
( henrySimon_00326 "We're just going to assume that our target cost is of the most simple IFF type when designing our database" )
( henrySimon_00327 "We're going to come back to that when we talk about the database, and we can see where these pseudo-features come from" )
( henrySimon_00328 "So we'll pull all of the waveform fragments out that have been labelled, in this case, with the phoneme /@/" )
( henrySimon_00329 "An obvious one is that we can put an [s] on the end of something to make the plural" )
( henrySimon_00330 "It seems a reasonable hypothesis that it's   hard work listening to synthetic  speech compared to natural speech" )
( henrySimon_00331 "It will be then easy to make a comparison between that predicted F0 and the true F0 of a candidate" )
( henrySimon_00332 "If you implement an algorithm, you may or may not actually construct this list, because it's going to be huge" )
( henrySimon_00333 "To get a better understanding of the issues in text selection, let's work through a rather simplified example" )
( henrySimon_00334 "Nevertheless, the number of possible contexts is still very, very large and that's going to be a problem" )
( henrySimon_00335 "So we could improve that: we could put several frames around the join and measure the join cost across multiple frames" )
( henrySimon_00336 "In other words, some of the linguistic environment has a very weak or negligible effect on the current sound" )
( henrySimon_00337 "Those were our ingredients for forced alignment: a language model, a pronunciation model and an acoustic model" )
( henrySimon_00338 "The most perceptible artefact we get in unit selection synthesis is sometimes those concatenation points, or "joins"" )
( henrySimon_00339 "For example, their fundamental frequency and their duration are strongly influenced by their position in the phrase" )
( henrySimon_00340 "One would hope that making an improvement  anywhere in the system would lead to an   improvement in the synthetic speech" )
( henrySimon_00341 "We'll do the same thing that we did for the letters: sort it,'uniq -c' it, and order it by frequency in reverse order" )
( henrySimon_00342 "We know that the beginning of the HMM aligns with the beginning of the audio, and the end of the HMM aligns with the end of the audio" )
( henrySimon_00343 "We made two in the Blizzard Challenge, and  indeed, in all sorts of internal testing   we'll keep certain things under control" )
( henrySimon_00344 "We're similarly going to quantify the difference in the spectral envelope just before the join and just after the join" )
( henrySimon_00345 "Therefore, we're going to have to quantify how good each join is, and take that into account when choosing the sequence of candidates" )
( henrySimon_00346 "The join cost then makes sure that we only choose sequences of candidates that will concatenate smoothly and imperceptibly" )
( henrySimon_00347 "So there's an explosion (an exponential increase) in the number of types, just by taking one aspect of context into account" )
( henrySimon_00348 "When we think we've got a pretty good system,   we might then go out and compare it somebody  else's system and hope that we're better" )
( henrySimon_00349 "Those interactions can actually  mean that improving something   early in the pipeline actually causes  problems later in the pipeline" )
( henrySimon_00350 "For the worked example, I'm going to actually just ignore linguistic context and try and get coverage just of diphones" )
( henrySimon_00351 "However, there are attempts to take these measures, which are typically big combinations of many, many different features and modify them" )
( henrySimon_00352 "So we made a first order solution to that which was just to capture the co-articulation between adjacent phones in the speech signal" )
( henrySimon_00353 "What we should understand so far is that a unit selection speech synthesizer has the same front end as as any other synthesizer" )
( henrySimon_00354 "Before starting on that, you need to make sure you already know the following things: The first area of importance is a little bit of phonetics" )
( henrySimon_00355 "So there's still an advantage of a pipeline architecture made of modules that we understand that we can take apart and we can replace" )
( henrySimon_00356 "If our base unit is the diphone, then our first N sentences (our first few hundred sentences) will be designed just to get one of each diphone" )
( henrySimon_00357 "And here we can see that all the points along the scale are described and when they've done that, they submit their score and move on to the next sample" )
( henrySimon_00358 "Both of those are competing to affect F0, but this function just considers them independently, and just accumulates the penalties" )
( henrySimon_00359 "That's a reasonable criticism of them, but they will take us away from the ceiling effect and help us to differentiate between different systems" )
( henrySimon_00360 "This is to make sure we have particularly good coverage in these smaller domains, so our voice will perform particularly well on these domains" )
( henrySimon_00361 "If we were to plot those numbers (and I'll let you do that for yourself, maybe in a spreadsheet) we'd see that has this Zipf-like decaying distribution" )
( henrySimon_00362 "What makes unit selection synthesis feasible? The answer is that some (hopefully very many) linguistic contexts lead to about the same speech sound" )
( henrySimon_00363 "Well, very simply by choosing candidates from an appropriate context - for example, phrase final - we'll get appropriate prosody automatically" )
( henrySimon_00364 "Let's examine each of those points in a little bit more detail and make them concrete with some examples of how they might appear to a listener by far and away" )
( henrySimon_00365 "You're going to find out that for yourself in the exercise! Because written text was not usually intended to be read aloud, its readability might be poor" )
( henrySimon_00366 "We're going to look at the match / mismatch between each candidate in turn and that target specification, and compute the target cost for each of them" )
( henrySimon_00367 "At each place is possibly used several different manners of making the sound and those are arranged on the vertical axis, not in any particular order" )
( henrySimon_00368 "It's the job of the target cost to measure similarity (or distance) between units in the database - which we call candidates - and the target specification" )
( henrySimon_00369 "We have better models, and so we could indeed today envisage predicting a complete acoustic specification - in fact, all the way to the waveform if you wanted" )
( henrySimon_00370 "If we miss here a word, how do we know we've misheard it? So I would never recommend the use of opinion scores or MUSHRA or anything like that to rate intelligibility" )
( henrySimon_00371 "Now, the context is potentially unbounded: it certainly spans the sentence in which we find the unit and we may even want to consider features beyond the sentence" )
( henrySimon_00372 "That's neat, because we can just run our algorithm and select a very large script and go into the studio and record for as long as (for example) we have money" )
( henrySimon_00373 "Whereas perhaps in a more complex sound, such as a liquid or a diphthong, with a complex and changing spectral envelope, it's more difficult to hide the joins in those sounds" )
( henrySimon_00374 "But this use off a single natural reference as gold standard is obviously flawed for the reason that we've already stated: there is more than one correct way of saying any sentence" )
( henrySimon_00375 "Now there's a whole lot of terminology flying  around testing, whether it's software testing   or whole system testing, whatever it might be,  we're not really going to get bogged down in it" )
( henrySimon_00376 "So to that extent that will correlate with listeners judgments very high cepstral distortion would suggest that they'll say they sound very different or if played only the synthetic sample" )
( henrySimon_00377 "We're going to look at a more sophisticated form of target cost now, where we predict some acoustic properties for the targets and compare those with actual acoustic properties of candidates" )
( henrySimon_00378 "We might also put a lower bound a bottom sample in that we know should always be worse than all of the systems that's known as the anchor, not obvious what that would be for synthetic speech, so it's not currently used" )
( henrySimon_00379 "We want maximum variation, so that our target cost function has a lot of candidates to choose amongst for each target position, and that our join cost function can find nice smooth joins between those candidates" )
( henrySimon_00380 "Using data where we just have a word transcription that's only aligned at the sentence level is so important and is the standard way of training an automatic speech recognition system, it comes with a special name" )
( henrySimon_00381 "Evaluation is obviously playing a critical role  in this because it's helping us to make the   decision that this was the best, and this was the  best, and that the route our research should take   should be like this, not some other path" )
( henrySimon_00382 "We're going to see that's a general trend   in evaluation: that we might be able to measure  something in the synthetic speech, but that thing   that we measure doesn't have a direct connection  back to only one property of the system" )
( henrySimon_00383 "The way I've just described that is in terms of linguistic features: effectively counting how many linguistic features (for example left phonetic context, or syllable stress, or position in phrase) match and how many mis-match" )
( henrySimon_00384 "The first feature is place and that's where in the mouth the sound is made and in particular with a consonant where some sort of constriction is formed and in the IPA chart those are arranged along the horizontal axis of this table" )
( henrySimon_00385 "Plotting those distributions of frequencies-of-types, from the most frequent to the least frequent (ordering them by their frequency of occurrence) and then plotting their frequency on this axis we always tend to get this sort of shape, this decaying curve" )
( henrySimon_00386 "The obvious ones are going to be the pitch (or the physical underlying property: fundamental frequency / F0), the energy - if speech suddenly gets louder or quieter we will notice that, if it's in an unnatural way - and, more generally, the overall spectral characteristics" )
( henrySimon_00387 "So what we're really looking for is not to cover every possible context (because that's impossible), it's to cover a wide variety of contexts so that the target cost and the join cost can between them choose units that don't mismatch too badly in linguistic features, and join together well" )
( henrySimon_00388 "The sort of things that you might include in your script design might be: choosing sentences that are easy to read out loud, so that your speaker can say them fluently without too many mistakes; you might want to cover low-frequency linguistic forms such as questions; you might want to boost the coverage of phrase-final and phrase-initial units, because in long sentences they're very rare; and you might want to include some domain-specific material, if you think your final system is going to be more frequently used in a particular domain (for example, reading out the news, or reading out emails, or something really simple like telling the time)" )
( henrySimon_00389 "And eventually we'll join together the statistical parametric method and the unit selection method for something called hybrid synthesis" )
( henrySimon_00390 "We'll probably still want coverage in that database, although it might not be as important as in unit Selection" )
( henrySimon_00391 "We'll still need a database" )
( henrySimon_00392 "And what we've talked about in this module on evaluation, all still applies" )
( henrySimon_00393 "Of course, we will want to evaluate that synthesis from the statistical parametric method" )
( henrySimon_00394 "And what you've learned in this unit selection part will still be highly relevant for several reasons" )
( henrySimon_00395 "What we'll move on to next is a different form of synthesis, and that's called Statistical Parametric Speech Synthesis" )
( henrySimon_00396 "And it's all about unit selection, the data behind it and how to evaluate it" )
( henrySimon_00397 "Well, we've reached the end of the first part of the course" )
( henrySimon_00398 "In this case, if we're really not sure what we're asking listeners to do, we're just saying, Do you like this system more or this other system more and all you can really do is forced choice preference test, because you're not really telling them what to listen to it all, just an overall preference that would also be appropriate for choosing between two different voices, which was most pleasant, for example, which is different to naturalness" )
( henrySimon_00399 "They're implying natural" )
( henrySimon_00400 "The only exception to That might be if there are only a couple of possible things they could hear, such as in minimal pairs, and you could possibly do a forced choice" )
( henrySimon_00401 "But fine distinctions" )
( henrySimon_00402 "How do you know whether you've understood something? Okay, so if something is perfectly intelligible or very unintelligible, then we could make a judgement on that and give an opinion" )
( henrySimon_00403 "It's hard to see where that will be acceptable" )
( henrySimon_00404 "One thing you'll find in the literature and indeed in some standards, is the use of the opinion scores to rate intelligibility" )
( henrySimon_00405 "This is probably fine" )
( henrySimon_00406 "You could use forced choice to say which of the two sounds more like a particular target speaker Judging whether something is or is not a target speaker is a slightly odd task for listeners because in real life, someone either is or is not the target making graded distinctions maybe a little bit tricky" )
( henrySimon_00407 "Obviously, with a reference sample of what the target speakers supposed to sound like" )
( henrySimon_00408 "Similarity to Target Speaker is essentially the same sort of task is naturalness, so people tend to do MOS or MUSHRA type tests" )
( henrySimon_00409 "I can't immediately think of a task that you could ask listeners to do other than those things from which you could gauge the naturalness of a signal" )
( henrySimon_00410 "And a forced choice is also perfectly okay, because it's quite a straightforward task to explain to listeners which of these two sample sounds the most natural" )
( henrySimon_00411 "It's perfectly good to use Mean Opinion Score very often on a five point scale that you might like a seven point scale for some reason, or something that's closely related to that which is MUSHRA, which has a built in error checking and calibration mechanism" )
( henrySimon_00412 "What tests should you pick? Naturalness is the most common thing to be evaluated" )
( henrySimon_00413 "Let's finish off with a table of recommendations about what test to use to measure what property, so depending what you want to evaluate" )
( henrySimon_00414 "Of course, that great big machine learning black box isn't a final solution, because although we might be able to learn in an end-to-end fashion When it does make mistakes, we really can't point to any part of the system to blame for it because it's a black box" )
( henrySimon_00415 "And that's one direction to field is heading into - something that's learnable in an end to end fashion and not just in a modular fashion" )
( henrySimon_00416 "If we had a complete end-to-end machine learning approach to the problem, for example, a great big neural net that went all the way from text to a waveform, we could imagine now back propagating errors through the system" )
( henrySimon_00417 "Now that's because these pipeline architectures are simply not invertable" )
( henrySimon_00418 "For example, the front end, the database, the signal processing, whatever we haven't changed must be identical, so there are no confounds when we do this evaluation and find that one of the variants was better and take it forward, we're then, assuming that it was our change that was responsible for that, what we can't do easily is do a listening test, Look at the result of it and somehow back propagate that through the pipeline of the text-to-speech system and find that it was the letter to sound system that was to blame" )
( henrySimon_00419 "So when we look at these 1, 2, 3, 4 systems, the only difference between them must be the thing we changed and everything else must be kept constant" )
( henrySimon_00420 "We need to make sure there's no confounding factors" )
( henrySimon_00421 "We need a very sensitive evaluation that can detect that and tell us to take that improvement forward and to leave the others behind" )
( henrySimon_00422 "Brilliant idea may have made only a very small improvement in the quality of the synthetic speech" )
( henrySimon_00423 "And let's just wrap up by reminding ourselves why we were doing that in the first place and looking again at what to do with the outcome of that So let's just repeat our diagram of how research works and, indeed, how development works We need carefully controlled experiments to tell the differences between, for example, these four system variants that might be all very similar" )
( henrySimon_00424 "So it's the evaluation of synthetic speech" )
( henrySimon_00425 "We could evaluate things about the system, but mainly we wanted evaluate the speech itself" )
( henrySimon_00426 "It's not a good predictor of what listeners would say if we did the proper listening test" )
( henrySimon_00427 "Unfortunately, that number's pretty meaningless" )
( henrySimon_00428 "That's tempting to think we could just apply those two synthetic speech, and they will give us a number" )
( henrySimon_00429 "There are standards out there, like PESQ" )
( henrySimon_00430 "They're not yet good enough to replace listeners, but they are now correlating, roughly speaking with listeners opinions" )
( henrySimon_00431 "For example, modify the weights in this waited combination and fit those weights to listening test results for synthetic speech" )
( henrySimon_00432 "So we can't just take these black boxes and use them to evaluate the naturalness of synthetic speech, pretending that synthetic species just a distorted form of natural speech because the distortions are completely different to the sort of distortions we get in transmission of speech" )
( henrySimon_00433 "As they stand - certainly you can say for PESQ - they don't well correlate, or they don't in fact correlate at all with listeners opinions of synthetic speech" )
( henrySimon_00434 "These both standards the exist in software implementation and they're used widely by telecommunications companies" )
( henrySimon_00435 "The standard measure until recently was called PESQ and recently, there's a new, better measure being proposed that's called POLQA" )
( henrySimon_00436 "And that's from the field of telecommunications" )
( henrySimon_00437 "And so it seems reasonable to try and put much more complex perceptual model into our objective measure" )
( henrySimon_00438 "We could put a little perceptual knowledge, but not a lot" )
( henrySimon_00439 "We might put that onto a perceptual scale" )
( henrySimon_00440 "In F0 we might not do it on Hertz" )
( henrySimon_00441 "The cepstrum might be Mel cepstrum to get some perceptual warping" )
( henrySimon_00442 "But these are very simple, low level, signal processing based measures" )
( henrySimon_00443 "We might want to report these results alongside subjective results and if there's a disagreement, we'll probably believe the subjective result, and not this objective measure" )
( henrySimon_00444 "They're actually quite close to the measures were minimising when training statistical models anyway" )
( henrySimon_00445 "They have some uses, a development tool because they could be done very quickly during development without going out to listeners" )
( henrySimon_00446 "So the summary message for the simple objective measures is: you'll find them widely used and reported in the literature, especially for statistical parametric synthesis" )
( henrySimon_00447 "And our one reference contour isn't the only way of saying the sentence, and so error won't perfectly correlate with listeners' opinions" )
( henrySimon_00448 "But once again, there are lots of valid natural contours" )
( henrySimon_00449 "If they're radically different, we get a large error, and that's a prediction of unnatural this" )
( henrySimon_00450 "And we would expect listeners to say this prosody was perfect or perfectly natural" )
( henrySimon_00451 "Again this has some reasonable properties" )
( henrySimon_00452 "For example, whether they have peaks in the same place" )
( henrySimon_00453 "Correlation would measure the similarity in the shapes of these two things" )
( henrySimon_00454 "Perhaps just this absolute difference or the mean squared difference and sum that up across so that we get this root mean squared error" )
( henrySimon_00455 "We'll look at local differences" )
( henrySimon_00456 "We'll have to make some alignment between synthetic and natural" )
( henrySimon_00457 "Let's move on to the other common thing to measure objectively, and that's F0 and here again" )
( henrySimon_00458 "That's something to think about for yourself" )
( henrySimon_00459 "Would this measure capture naturalness of unit selection speech" )
( henrySimon_00460 "It might not be the same as the natural reference, but it's perfectly natural" )
( henrySimon_00461 "Something to think about for yourself is, would this measure make sense for synthetic speech made by concatenation of wave forms, remembering that those are locally, essentially, perfectly natural, so any local frame is natural speech" )
( henrySimon_00462 "It's very much the same thing that we're actually minimising when we're training our systems And so it's a possible measure of system performance or of predicted naturalness of the final speech" )
( henrySimon_00463 "Nevertheless, this distance measure or distortion in the mel cepstral domain is very widely used in a statistical parametric synthesis" )
( henrySimon_00464 "And in system development, as we incrementally improve our system, it's actually small differences that we really want to measure the most" )
( henrySimon_00465 "And zero distortion means the synthetic is identical to natural" )
( henrySimon_00466 "They would say that sounds very unnatural" )
( henrySimon_00467 "If the two signals were extremely different, distortion would be high and that seems reasonable" )
( henrySimon_00468 "If these two signals were identical than the distortion would be zero, that seems reasonable" )
( henrySimon_00469 "Now this is a pretty low level signal measure is the same sort of thing we might do in speech recognition to say if two things were the same or different, but it's got some properties that seem reasonable" )
( henrySimon_00470 "That'll be Mel Cepstral Distortion" )
( henrySimon_00471 "Then we'll just sum that up for every frame off the utterance" )
( henrySimon_00472 "compare these two things on measure the difference or distortion" )
( henrySimon_00473 "And in the cepstral domain" )
( henrySimon_00474 "We'll do the same here" )
( henrySimon_00475 "Here we might extract the spectral envelope represent that with cepstrum" )
( henrySimon_00476 "This is just a spectrum with frequency here and magnitude" )
( henrySimon_00477 "So those two were aligned by the dynamic time warping and we'll extract from this one" )
( henrySimon_00478 "Maybe we'll take that frame there on its corresponding frame" )
( henrySimon_00479 "And then we could take frames that have been aligned with one another and look at the local difference" )
( henrySimon_00480 "That's just going to make some non linear alignment between these two sequences, matching up the most similar sound with the most similar sound" )
( henrySimon_00481 "We'll do some procedure of alignment" )
( henrySimon_00482 "So we'll extract some features" )
( henrySimon_00483 "So if we've got a natural and a synthetic version of a sentence, the first thing of course we're going to do is make some alignment between them" )
( henrySimon_00484 "Let's just see what properties those measures are looking at" )
( henrySimon_00485 "So for F0 we might have a pair of measures: Error and Correlation" )
( henrySimon_00486 "It has peaks in the right places, for example" )
( henrySimon_00487 "If we produce a synthetic F0 contour that essentially has the right shape but is offset or is its amplitude is a little bit too big or too small, we would still predict that sounds very nice to listeners" )
( henrySimon_00488 "And so we might also measure the shape of the two contours with something like correlation" )
( henrySimon_00489 "That has a problem that if there's just a small offset between the two that will turn up to look like rather a large error" )
( henrySimon_00490 "That's just a sum of local differences" )
( henrySimon_00491 "And sum those up and calculate the root mean squared error between those two contours" )
( henrySimon_00492 "My just look at the difference in Hertz or some other units between the natural and synthetic contours" )
( henrySimon_00493 "For an F0 contour, there's a couple of different things we might measure" )
( henrySimon_00494 "And one thing that we know off that does that is the Mel Cepstrum" )
( henrySimon_00495 "We would want to do that in a representation that's, somehow relevant to perception, captures some perceptual properties" )
( henrySimon_00496 "For the special envelope, we just think about a distortion of the difference between natural and synthetic" )
( henrySimon_00497 "For example, spectral envelope and the stuff that might correlate with prosody, F0 contour, maybe energy" )
( henrySimon_00498 "And the properties are the obvious things, the stuff that might correlate with phonetic identity" )
( henrySimon_00499 "These simple, objective measures are just based on properties of the signal" )
( henrySimon_00500 "We can't really capture all of the possible valid and correct natural ways of saying a sentence" )
( henrySimon_00501 "So the method, as it stands, fails to account for natural variation" )
( henrySimon_00502 "And then we'll sum the local differences, and that will be some total distance" )
( henrySimon_00503 "Or we could force out synthesisers to generate speech with the same durational pattern is a natural reference" )
( henrySimon_00504 "So we're going to align the natural and synthetic that could be just, say, dynamic, time warping" )
( henrySimon_00505 "Most objective measures are just a sum of local differences" )
( henrySimon_00506 "It also assumes that distance between a synthetic sample on this natural reference is somehow going to indicate what listeners would have said about it is going to correlate with their opinion score" )
( henrySimon_00507 "And there are many, many possible ways" )
( henrySimon_00508 "But any natural speaker's rendition of a sentence is just one possible way of saying that sentence" )
( henrySimon_00509 "First of all, it assumes that natural speech is somehow gold standard, and we can't do better than that" )
( henrySimon_00510 "The reference will be natural speech and the comparison will probably be just some distance" )
( henrySimon_00511 "Simple, objective measures involve just comparing synthetic speech to a reference" )
( henrySimon_00512 "Think about why it would be non trivial, and then we'll look at what can be done so far" )
( henrySimon_00513 "So let's turn our minds then to whether an objective measure is even possible" )
( henrySimon_00514 "Or we might use some more sophisticated model and the model will try and take account of human perception" )
( henrySimon_00515 "It might be a simpler is measuring distances between synthetic speech and a reference sample, which is almost certainly going to be natural speech" )
( henrySimon_00516 "In an objective test, we have an algorithm" )
( henrySimon_00517 "So is that possible? In a subjective test, we have subjects, and they express perhaps an opinion about the synthetic speech" )
( henrySimon_00518 "So we're using the word objectively here to imply that listeners are subjective" )
( henrySimon_00519 "It would be nice if we could find a measure an algorithm perhaps that could evaluate objectively" )
( henrySimon_00520 "Now, while using listeners to evaluate your synthetic speech is by far the most common thing to do" )
( henrySimon_00521 "It might be some other domain" )
( henrySimon_00522 "It could be the domain of usage of the system" )
( henrySimon_00523 "Just pull them from some domain" )
( henrySimon_00524 "We can use relatively normal sentence" )
( henrySimon_00525 "Naturalness more straightforward" )
( henrySimon_00526 "Naturalness is more straightforward because we can use normal sentences" )
( henrySimon_00527 "Maybe you can think off some novel ways to avoid the ceiling effect without using rather unnatural, semantically unpredictable sentences" )
( henrySimon_00528 "But in this case, we're now starting to worry again that we're measuring something about the listeners ability and not about synthetic speech" )
( henrySimon_00529 "And so what they're trying to capture is not the effects of synthetic speech, but the effects of a transmission channel and the degradations it's imposed upon original natural speech, so these don't always automatically translate to the synthetic speech situation" )
( henrySimon_00530 "You need to be a little bit careful about just simply applying these standards because they're almost exclusively developed for measuring natural speech" )
( henrySimon_00531 "There are other standards out there for measuring intelligibility as there are for Naturalness and for quality" )
( henrySimon_00532 "And those lists might be of words of controlled frequency, medium frequency words or so on" )
( henrySimon_00533 "These could be generated by algorithm from template or a set of template sentences into which slots we drop words from some lists" )
( henrySimon_00534 "in fact, fairly standard is to use semantically unpredictable sentences" )
( henrySimon_00535 "This is very, very time consuming because we're getting one small data point from this full sentence" )
( henrySimon_00536 "They differing one phonetic feature and we can tell if I synthesizer is making that error" )
( henrySimon_00537 "We'll say gold again" )
( henrySimon_00538 "Now we will say cold again" )
( henrySimon_00539 "A simpler way off doing intelligibility testing that gets us down to specific individual errors is to use minimal pairs and will typically embed them in sentences because it's nicer for the listener" )
( henrySimon_00540 "That could be very important, especially in system development" )
( henrySimon_00541 "These are very far from actual system usage" )
( henrySimon_00542 "The standard way of making the task harder for listeners is to make the sentences less predictable and we tend to pick things that are syntactically correct, because otherwise it would sound very unnatural but semantically unpredictable because they kind of have conflicting meanings within them" )
( henrySimon_00543 "We can't tell if they're both synthesising such easy material, and so we have to pull them apart by making things harder for listeners" )
( henrySimon_00544 "One might be more intelligible than the other" )
( henrySimon_00545 "But it's not useful experimentally because we can't tell the difference between different systems" )
( henrySimon_00546 "Now that's success in the sense that our system works" )
( henrySimon_00547 "They're basically perfectly intelligible" )
( henrySimon_00548 "We'll tend to get a ceiling effect" )
( henrySimon_00549 "The problem with these sentences is that in quiet conditions, which we hope our listeners are in" )
( henrySimon_00550 "We would perhaps prefer to use nice, normal sentences, either from the domain of application or pull from a source such as a newspaper" )
( henrySimon_00551 "That's gonna be a lot more pleasant for listeners" )
( henrySimon_00552 "Or more likely we'll use full sentences to get bit more variety, but also to make things a little harder to analyse" )
( henrySimon_00553 "But it's still possible" )
( henrySimon_00554 "That's not so common these days" )
( henrySimon_00555 "So we might sometimes even want to use isolated words to narrow down the range of possible errors a listener can make and make our analysis much simpler" )
( henrySimon_00556 "That might conflict with other requirements of evaluation and the sort of analysis we might want to do, particularly if we want to test intelligibility" )
( henrySimon_00557 "If our systems for a particular domain, maybe it's a personal assistant, we would probably want to synthesise this sentences in that domain on measure its performance, saying naturalness on such sentences" )
( henrySimon_00558 "But what sentences are we actually going to synthesise and play to the listeners? In other words, what are the materials we should use Now there's a possible tension when choosing the materials to record" )
( henrySimon_00559 "They might be pull down menus or type in boxes and if it's necessary, and it very often is, using this between subjects design to remove the problem of repeated stimuli" )
( henrySimon_00560 "We looked at various test interfaces" )
( henrySimon_00561 "We decided what the task might be, such as typing in or choosing from a five point scale" )
( henrySimon_00562 "So we're talking still about subjective evaluation, in other words, using listeners and getting them to do a task" )
( henrySimon_00563 "And that's crucial in intelligibility because they will remember those sentences" )
( henrySimon_00564 "Okay, we got into a bit of detail there about a very specific listening test design, although it is a very highly recommended one and it's widely used, particularly in the Blizzard Challenge, to make sure that we don't have effects off repeated presentation of the same text to a listener" )
( henrySimon_00565 "And then we just aggregate the opinions or the responses in this case, the type in responses, for example, word error rates across all subjects to form our final statistics" )
( henrySimon_00566 "But no individual human being ever hears the same sentence twice" )
( henrySimon_00567 "This virtual listener, composed of five human beings, listens like this through the Latin square and they hear every synthesiser saying every sentence" )
( henrySimon_00568 "So we put the same number of people in each row" )
( henrySimon_00569 "And if we want more than five, we need multiples of five" )
( henrySimon_00570 "And so we need to have at least five people" )
( henrySimon_00571 "So we've got five individual subjects, but they're grouped together in forming a single virtual listener" )
( henrySimon_00572 "We need to balance the design by taking another subject and listening to the sentences said by a different permutation off the synthesisers and work our way down these rows" )
( henrySimon_00573 "So we need to complete that" )
( henrySimon_00574 "So that's not fair, because sentence A might be easier to synthesise then sentence B so at the moment System zero has an unfair advantage" )
( henrySimon_00575 "Now, when this subject has completed this row of the square, they've heard every synthesiser Well each synthesiser was only saying a single sentence" )
( henrySimon_00576 "Their relative judgments will be affected by having heard both the best and the worst synthesiser and not only bad ones are only good ones" )
( henrySimon_00577 "And then this achieves the property that we only hear each sentence once, but the subjects hearing all the different synthesises so they'll be somehow calibrated" )
( henrySimon_00578 "So they'll typing in what they heard, and then they'll move on and they'll hear the next one on the listening across a row of this Latin Square, and you'll notice that they're going to hear every sentence just once each and each time, it said, by a different synthesiser, different number in that cell" )
( henrySimon_00579 "So they must make one pass through one row of the Matrix, and they can't do any of the other rows" )
( henrySimon_00580 "Now here we're doing an intelligibility task where it's absolutely crucial that no subject hear's the same sentence more than once" )
( henrySimon_00581 "And they would perform a task" )
( henrySimon_00582 "So we'll take one of our subjects and they will listen across a row of this square, so they will hear Sentence A said by synthesiser number zero" )
( henrySimon_00583 "The square is called a Latin square" )
( henrySimon_00584 "Now that means it's not possible for a single subject to do the whole listening test because that would involve hearing every sentence synthesised by all five synthesisers" )
( henrySimon_00585 "Here they're called subjects" )
( henrySimon_00586 "So five synthesisers" )
( henrySimon_00587 "Here I've numbered them: 0 1 2 3 4" )
( henrySimon_00588 "The goals of the following that we have a set of synthesisers" )
( henrySimon_00589 "So I'm now going to explain one type of between subjects design that achieves a few very important goals" )
( henrySimon_00590 "Every pair, every A/B pair is played in the order, A followed by B and somewhere else in the test it's played as B followed by A so all pairs of repeated" )
( henrySimon_00591 "One way to do that in a forced choice - a pairwise test - is simply to repeat a pair, ideally in the opposite order and in fact, in some pairwise listening tests" )
( henrySimon_00592 "So to check listeners are consistent and not random" )
( henrySimon_00593 "In both designs, whether it's within subjects or between subjects, we can build various forms of quality control, and the simplest one is actually to deliberately repeat some items and make sure they give about the same judgement in the repeated case" )
( henrySimon_00594 "In other words, there's no memory carry over effect from listener to listener, so we can effectively make a virtual listener who doesn't have a memory" )
( henrySimon_00595 "On the essence of this design, is we form a virtual single subject from a group of people such that we can split the memory effect such that one thing heard by one listener can't possibly affect another thing heard by a different listener because they don't communicate with each other" )
( henrySimon_00596 "And that design is called between subjects" )
( henrySimon_00597 "So if we worried about these effects we're going to have to have a different sort of design" )
( henrySimon_00598 "Or ordering, for example, if we hear a really good synthesiser, then a really bad synthesiser, the bad one's score will be even lower because of that ordering effect" )
( henrySimon_00599 "In other words having heard one thing the response with some other thing changes" )
( henrySimon_00600 "But there's a more complex and much more important reason that we might not have a within subjects design, and that's because we might not want to play certain sequences or certain combinations of stimulus to the one listener, and that's because there might be effects off priming" )
( henrySimon_00601 "So we would have to split that across multiple listeners" )
( henrySimon_00602 "If we want to compare so many different systems and we sure we need many different texts, we simply can't fit all of that into a 45 minute test or a lot less" )
( henrySimon_00603 "One of them is obvious" )
( henrySimon_00604 "But there are two situations where it's not possible to do that" )
( henrySimon_00605 "They all hear the same stimuli and the most we might do is to put them in a different random order for each listener" )
( henrySimon_00606 "In other words, all listeners individually, each hear everything" )
( henrySimon_00607 "Far and away the easiest thing to do in the listening test is to construct one listening test and then just to repeat the same test with many different listeners" )
( henrySimon_00608 "And our test design might combine numbers of listeners and numbers of sentences as we're going to see in a bit, so the number of sentences might be determined for us by our number of systems And the number of listeners that we want to use" )
( henrySimon_00609 "And so again the only way to mitigate that is to use as many different sentences as possible" )
( henrySimon_00610 "It's possible that one sentence is a typical favours one system over another, just out of luck" )
( henrySimon_00611 "The same applies to the material text that we synthesise and then play to listeners" )
( henrySimon_00612 "I would say we need at least 20 listeners in any reasonable listening test, and preferably always more than that, maybe 30 or more" )
( henrySimon_00613 "And the only way to do that is to have a lot of different listeners" )
( henrySimon_00614 "Because one individual listener might be atypical - they might just hear synthetic speech in a different way, they might have different preferences to the population" )
( henrySimon_00615 "So a test duration of 45 minutes is actually really quite long, and we certainly wouldn't want to go beyond that" )
( henrySimon_00616 "Such as system A is better than system B, but what we can have is some pretty useful rules of thumb that we can use in all listening tests that we know from experience tends to lead to reliable results" )
( henrySimon_00617 "And so we're not going to go into the nitty gritty of exactly how the size of a sample determines the statistical power that we would need to make confident statements" )
( henrySimon_00618 "Now, this is definitely not a course on statistics" )
( henrySimon_00619 "And it catches listeners who are not doing the task properly, so it some quality control and some calibration" )
( henrySimon_00620 "But the idea of having this hidden reference is very useful because it both calibrates it provides a reference to listen to" )
( henrySimon_00621 "So this forces them to listen to everything, and it gives some calibration" )
( henrySimon_00622 "It instructs the listener that one of these eight stimulate is in fact the reference, and then they must give it a score of 100 and in fact, they're not allowed to move on to the next set until they do so" )
( henrySimon_00623 "MUSHRA builds in a nice form of quality control" )
( henrySimon_00624 "And then we have a set of stimuli, that we have to listen to: in this test there are eight so we can see you can do a lot of samples side by side and for each of them, the user, the listener has to choose a score, but in doing so is also implicitly sorting the systems" )
( henrySimon_00625 "We have a reference that we could listen to that would be natural speech" )
( henrySimon_00626 "There's variants on it, but this is the official MUSHRA design" )
( henrySimon_00627 "And here are some examples on these scales and finally, that MUSHRA design, which is an international standard" )
( henrySimon_00628 "For example, a paragraph from an audio book and we might try and get things that are not just naturalness, but maybe some of those sub-dimensions of naturalness" )
( henrySimon_00629 "We won't go into a lot of detail on this one, but we could ask for multiple judgments on the same stimulus that might be particularly appropriate if the stimulus is long" )
( henrySimon_00630 "And other designs are possible" )
( henrySimon_00631 "Certainly they would take longer to do the test" )
( henrySimon_00632 "And that's another design decision we have to to make: would their judgement change if they're allowed to listen many, many times" )
( henrySimon_00633 "In this particular design they're only allowed to listen to the speech once" )
( henrySimon_00634 "If we're asking them to transcribe what they heard, maybe that the interface would look like this some way of playing the audio and a place to type in their text" )
( henrySimon_00635 "Here is the pull down menu, but it could equally be boxes to tick, which is one option" )
( henrySimon_00636 "It's got on audio player, in this case, the listener can listen as many times as they want, and it's got a way of giving the response" )
( henrySimon_00637 "So here's a typical interface" )
( henrySimon_00638 "So mean opinion score is the most common by far, and that's because the most common thing we want to evaluate his naturalness" )
( henrySimon_00639 "We'll look a test in a moment that's called MUSHRA that attempts to take the best of the pairwise forced choice, which essentially relative and the MOS, which is essentially absolute and the idea of calibration by providing reference samples, putting all of that into a single test design that's intuitive for listeners and has some nice properties for us" )
( henrySimon_00640 "And we might include some references and might even hybridise rating and sorting" )
( henrySimon_00641 "There are variations on this that aren't just pairwise forced choice so we might use more than two stimuli" )
( henrySimon_00642 "A is better or B is better" )
( henrySimon_00643 "We could just have two options" )
( henrySimon_00644 "That's optional" )
( henrySimon_00645 "And if they always to choose that, then we know that these systems are hard to tell apart" )
( henrySimon_00646 "If you want to capture the strength of the preference, you might also put in a don't care or equally natural or can't tell the difference sort of option" )
( henrySimon_00647 "So ask only for relative judgments, so we'll give them multiple things to listen to, and the most obvious thing is two things, and we'll ask them to say which do they prefer" )
( henrySimon_00648 "One solution to this problem of not being able to get truly absolute calibrated opinions from listeners is not to ask for them at all" )
( henrySimon_00649 "We need to worry about that" )
( henrySimon_00650 "So we might get a different score for the same system, depending on the context around it In other words, listeners probably do recalibrate themselves according to what they've heard recently more elsewhere in the test" )
( henrySimon_00651 "So just give everything a score of three" )
( henrySimon_00652 "They can't tell the difference between them" )
( henrySimon_00653 "It's not really good" )
( henrySimon_00654 "It's very likely our listeners in that case, we'll just give everything three, which is halfway between one and five, because it's not really bad" )
( henrySimon_00655 "In fact, it's really hard to tell the difference between them, so they're all somewhere in the middle" )
( henrySimon_00656 "We put exactly the same system in its still quite good, but it's mixed in with some other variants on the system, and they're also quite good" )
( henrySimon_00657 "Let's imagine another version of the test" )
( henrySimon_00658 "It's not perfect, but it's quite good" )
( henrySimon_00659 "Maybe our listeners going to keep scoring four out of five because it's quite good" )
( henrySimon_00660 "I would have to design that in to understand To understand why there's this difference between the task being absolute in terms of the judgement the listener gives and the test not necessarily being repeatable or comparable: imagine we have a system that's quite good" )
( henrySimon_00661 "So in other words, it's not necessarily repeatable, and it's certainly not necessary comparable across listening tests" )
( henrySimon_00662 "However, that does not mean that if we repeat this task, another time will get exactly the same judgments" )
( henrySimon_00663 "However, we must be very careful to not conflate two things It's absolute in the sense that it's all a single stimulus, and we expect the listener to be able to do that task without reference to some baseline or some top line" )
( henrySimon_00664 "It's not relative to anything else" )
( henrySimon_00665 "Now, here we have to call this an absolute judgement because that score is on a scale of 1 to 5, and it's on a single stimulus" )
( henrySimon_00666 "We call that the mean opinion score" )
( henrySimon_00667 "And in this test, listeners hear a single stimulus in isolation, typically one sentence and then they give a judgement on that single stimulus, and then we take the average of those on DH" )
( henrySimon_00668 "The most common sort of listening test is one that attempts to measure the naturalness of the speech synthesiser" )
( henrySimon_00669 "Or is it because the listeners weren't paying attention? So we want some quality control and that would be built in to the test design as we're going through" )
( henrySimon_00670 "And importantly, how do we know that they're doing the job well? So, for example, when we failed to find any difference between two systems, is it because really there was no difference?" )
( henrySimon_00671 "Maybe it doesn't matter" )
( henrySimon_00672 "What type of listener are they? Maybe they should be native speakers" )
( henrySimon_00673 "Sometimes they're called subjects" )
( henrySimon_00674 "And something that we might talk about as we go through these points in detail, but always keep in mind the listeners themselves" )
( henrySimon_00675 "And how many listeners to do this with? So I need to think about the size of the test" )
( henrySimon_00676 "And what remains then, is how many samples to play them" )
( henrySimon_00677 "So we decided to get let's say, relative judgments from listeners, present them with a reference stimulus, and then the things they've got to judge - get them to, for example, choose from a pull down menu from a five point scale and get their response back" )
( henrySimon_00678 "That's pretty straightforward" )
( henrySimon_00679 "It needs to present the stimulus" )
( henrySimon_00680 "And that needs an interface" )
( henrySimon_00681 "When we've decided then whether our listeners needs some help calibrating their judgments or whether they can be relied upon to give absolute, in other words, repeatable judgments every time with a need to present, stimulated them and get these judgments back" )
( henrySimon_00682 "But there are other references, such as a standard speech synthesis system that never changes as our prototype system gets better" )
( henrySimon_00683 "And the most obvious reference, of course, is natural speech itself" )
( henrySimon_00684 "So many times we might want to make a safer assumption that listeners make relative judgments and one way to be sure that they're always making relative judgments and to give some calibration to that is to include some references" )
( henrySimon_00685 "If you've just heard a very unnatural system and then a more natural system, your rating would be inflated by that" )
( henrySimon_00686 "That's possibly not true for things like naturalness" )
( henrySimon_00687 "Are they going to reliably rate it always as a three out of five? If we think that's true, we could design the task that relies on this absolute nature of listeners judgments" )
( henrySimon_00688 "These are what we're going to concentrate on So we've decided to give our listeners a simple and obvious task" )
( henrySimon_00689 "It's not so common: by far and away the most common thing is to give a very obvious task and either pairwise or Likert scale type tasks or typing test for intelligibility" )
( henrySimon_00690 "Doing this more sophisticated analysis - here is something called multi-dimensional scaling, which projects the differences into a space and then we can interpret the axes - is not really mainstream" )
( henrySimon_00691 "Those judgements about difference in this pairwise forced choice test" )
( henrySimon_00692 "If we wanted a deeper analysis than simply a preference, an alternative to training the listeners is to give them what appears to be a very simple task and then you some sophisticated statistical analysis to untangle what they actually did and to measure, for example, on what dimensions they were making" )
( henrySimon_00693 "That such a simple, obvious task, they can do it without any further instructional training" )
( henrySimon_00694 "We'll just assume as, for example, as native speakers of the language, they were able to choose between two things and express a preference" )
( henrySimon_00695 "But naive listeners, the one we can recruit on the street and pay to do our listening test in general would not be trained" )
( henrySimon_00696 "For example, the linguist, the native speaker in a company listening to a system - a prototype system - and giving specific feedback on what's wrong with it" )
( henrySimon_00697 "So this is quite uncommon in evaluating synthetic speech" )
( henrySimon_00698 "It's quite time consuming, and we could be never certain that they've completely learned to do what we ask them to do" )
( henrySimon_00699 "And if we want a lot of listeners and they're going to listen to a lot of material and we're going to repeat test many times, training listeners is a bit problematic" )
( henrySimon_00700 "And so we might ask, Should we train the listeners in order to, for example, pay attention to specific aspects of speech? This idea of training is pretty common in experimental phonetics, where we would like the listeners to do something very specific to attend to a particular acoustic property" )
( henrySimon_00701 "It's reasonable to wonder whether just anybody could do these tasks" )
( henrySimon_00702 "Their task might be to do something else, for example, to type in the words that they heard" )
( henrySimon_00703 "They'll listen to one sample and give a response here on a 1 to 5 scale that's very common for naturalness" )
( henrySimon_00704 "Sometimes it described all the points" )
( henrySimon_00705 "Sometimes we just described the end points" )
( henrySimon_00706 "We might want more graded judgement than that For example, we might ask them to make a rating on a scale, maybe a Likert scale with a number of points on it" )
( henrySimon_00707 "We might just play pairs off samples of synthetic speech, perhaps from two different variants of our system, and just say, which one do you prefer? That's a forced choice pairwise preference test" )
( henrySimon_00708 "In other words, it doesn't need a lot of instruction because people don't read instructions" )
( henrySimon_00709 "In all cases, it's going to be best if it's simple and obvious to the listener" )
( henrySimon_00710 "And they're going to be asked to do something" )
( henrySimon_00711 "So in subjective evaluation, the subjects are people sometimes called listeners" )
( henrySimon_00712 "So we'll focus on the subjective, in other words, the listening test" )
( henrySimon_00713 "And that's definitely a research topic and not a well established way of evaluating synthetic speech at this time" )
( henrySimon_00714 "And we might need a model of perception to do that That's even harder" )
( henrySimon_00715 "You could try and model something about human perception, which isn't as simple as just a distance" )
( henrySimon_00716 "The most obvious idea would be to take some natural speech and measure somehow the difference - the distance between your synthetic speech and this reference sample of natural speech on the assumption that the distance of zero is the best you can do, and then you're perfectly natural, or you could use something a bit more sophisticated" )
( henrySimon_00717 "We'll look at a couple of forms off objective measure just in principle, not in huge detail" )
( henrySimon_00718 "However, objective measures are far from perfect, but they're currently not a replacement for subjective evaluation" )
( henrySimon_00719 "That's a very attractive idea because using listeners can be slow, expensive and just inconvenient to recruit people and get them to listen to your synthetic speech" )
( henrySimon_00720 "The other form of evaluation, something called objective and that would use some algorithms, some automated procedure to evaluate the synthetic speech without the need for listeners" )
( henrySimon_00721 "So we're going to look at how to design a test of that form, including things such as what materials you would use" )
( henrySimon_00722 "And their task involves listening to synthetic speech and doing something, making some response" )
( henrySimon_00723 "Subjective, in which we use human beings as listeners" )
( henrySimon_00724 "There's two main forms of evaluation" )
( henrySimon_00725 "And so what we need to do now is find out how" )
( henrySimon_00726 "What's normal in the field? What would be expected if you wanted to publish   a paper about your speech synthesis research? We're going to evaluate the output   from a complete system" )
( henrySimon_00727 "So from this point on in the next video,  we're going to focus on the mainstream" )
( henrySimon_00728 "And we've listed initially some aspects of  the the system, specifically of this speech,   that we could measure" )
( henrySimon_00729 "We could do it at various  points: and you need to choose" )
( henrySimon_00730 "We know why we should evaluate to  find stuff out and make decisions" )
( henrySimon_00731 "For now, let's wrap this  section up with a quick recap" )
( henrySimon_00732 "So I put that to one side" )
( henrySimon_00733 "It would be nice to think that we could use them  to get a deeper understanding of synthetic speech" )
( henrySimon_00734 "So at the moment these things are not widely used" )
( henrySimon_00735 "For example, we're measuring the listeners working  memory, not how good the synthetic speech was" )
( henrySimon_00736 "And so there's a confound there" )
( henrySimon_00737 "The reason for that is that is then very hard to  separate out measuring things about the listener   from things about the synthetic speech" )
( henrySimon_00738 "Sticking electrodes on their scalp to  measure things about their brain activity" )
( henrySimon_00739 "More generally, we might think about how much   effort it is to listen to synthetic speech" )
( henrySimon_00740 "Managed to transcribe the words,  but if the prosody was all wrong,   they might have understood a different meaning" )
( henrySimon_00741 "You might like to think about whether somebody  really understood the meaning of the sentence" )
( henrySimon_00742 "Similarly, intelligibility is usually defined  as the ability to transcribe what was said,   but there might be more to listening to synthetic  speech than just getting the words right" )
( henrySimon_00743 "So naturalness might need unpacking,  but the convention in the field is to   give that as an instruction to the listener:  "Please rate the naturalness  of the synthetic speech" )
( henrySimon_00744 "We could imagine speech that's segmentally natural  - the phonemes have reproduced nicely- but it's   prosodically unnatural" )
( henrySimon_00745 "And in particular, it seems to me that  naturalness is not a single dimension" )
( henrySimon_00746 "You could consider how pruning affects speed and how that trades off against,  for example, naturalness" )
( henrySimon_00747 "You could do those in experiments for yourself" )
( henrySimon_00748 "They will be straightforward to measure" )
( henrySimon_00749 "We're no longer going to consider these things" )
( henrySimon_00750 "You are going evaluate synthetic speech along a  dimension that's not one of the ones on this slide and see if you can find something  new that you could measure" )
( henrySimon_00751 "Go away and think about what they might be  and then put them into practise yourself" )
( henrySimon_00752 "And there's a whole lot of other  things you might imagine evaluating" )
( henrySimon_00753 "It doesn't always matter,   so there's no reason to evaluate  that unless you care about it" )
( henrySimon_00754 "That sometimes matters" )
( henrySimon_00755 "As I've already mentioned, in the parametric   synthesis case, it's possible to produce  synthetic speech that sounds reasonably natural,   is highly intelligible, but doesn't sound  very much like the person that we recorded" )
( henrySimon_00756 "So we're going to start measuring   listener properties when really we want to  measure our synthetic speech properties" )
( henrySimon_00757 "We might try and evaluate some higher level   things, such as understanding or comprehension,  but then we're going to start interacting with   things like the memory of the listener" )
( henrySimon_00758 "That's simply the ability of a listener to recall,   or to write down, the words that he or she heard" )
( henrySimon_00759 "And there's a load of different terms you  could use to talk about that property,   the most common one is "intelligibility"" )
( henrySimon_00760 "I would also like that  speech to be understandable" )
( henrySimon_00761 "In general, it's assumed that that's  what we're aiming for in Text-to-Speech" )
( henrySimon_00762 "Naturalness, implies some similarity to  natural speech from a real human talker" )
( henrySimon_00763 "Rather, we use the term naturalness" )
( henrySimon_00764 "So tend not to talk about that [quality] so much" )
( henrySimon_00765 "That's a little bit of a vague  term for synthetic speech,   because there are many different dimensions" )
( henrySimon_00766 "For transmission down telephone systems we  talk took about the "quality" of the speech" )
( henrySimon_00767 "It's tempting to use the word "quality"" )
( henrySimon_00768 "What aspects of speech could we possibly quantify?  There's lots of descriptors, lots of  words we could use to talk about this" )
( henrySimon_00769 "So we're now going to focus on  just synthetic speech evaluation   and forget about looking inside the system" )
( henrySimon_00770 "And now, when you think about   what it is about speech that we could evaluate" )
( henrySimon_00771 "We can do those evaluations for  components or the whole systems" )
( henrySimon_00772 "We might have to completely rebuild the system   and re-label the database whenever we change,  for example, our letter-to-sound module" )
( henrySimon_00773 "We want to improve those components,  but we might have to propagate those   improvements right through the pipeline" )
( henrySimon_00774 "Nevertheless, we're always going  to try and improve systems" )
( henrySimon_00775 "And in general, of course, in all of software   engineering, fixing one bug can easily reveal  other bugs that you hadn't noticed until then" )
( henrySimon_00776 "So, in general then, these pipeline architectures,  which are the norm in Text-to-Speech,   can lead to unfortunate interactions" )
( henrySimon_00777 "Similarly, improving the letter-to-sound module  might start producing phoneme sequences which are   low frequency in the database, because the  database used the old letter-to-sound module,   which never produced those sequences" )
( henrySimon_00778 "We might get worse performance - for example,   lower naturalness - now,  because we have more joins" )
( henrySimon_00779 "However, if we only do that in the run-time  system and don't change the underlying database,   we will now have a mismatch  between the database labels   and the content of what we try to say at run time" )
( henrySimon_00780 "Imagine we fix a problem in text normalisation   so that currencies are now correctly normalised  whereas they used to be incorrectly normalised" )
( henrySimon_00781 "Let's take some examples" )
( henrySimon_00782 "In other words, making improvement  actually makes synthetic speech worse!" )
( henrySimon_00783 "They typically have something like a  pipeline architecture that propagates errors   and that can lead to very tricky  interactions between the components" )
( henrySimon_00784 "If only that was the case!  Systems like Text-to-Speech  synthesisers are complex" )
( henrySimon_00785 "That will be the sort of thing we  might do for a Part-Of-Speech tagger" )
( henrySimon_00786 "So to measure performance, we can maybe get some  objective measures against gold standard data" )
( henrySimon_00787 "All we could do is put  things in and get things out" )
( henrySimon_00788 "Put in test cases with known correct  output and compare against them" )
( henrySimon_00789 "We might put in specific tests unit tests  to check that there are no silly bugs" )
( henrySimon_00790 "If we wanted to, we could go look at source code" )
( henrySimon_00791 "We're really not going to talk much about that" )
( henrySimon_00792 "This kind of testing is   normally about things like reliability and  speed to make sure the system doesn't crash,   make sure it runs fast enough to be usable" )
( henrySimon_00793 "We could even put changes into the code   for the purposes of testing" )
( henrySimon_00794 "We could go inside the code" )
( henrySimon_00795 "We have complete access to it" )
( henrySimon_00796 "That means we can look inside the   system that we're testing" )
( henrySimon_00797 "Sometimes we see this term: "glass box"" )
( henrySimon_00798 "But let's just look at a couple of  things that come up in some textbooks" )
( henrySimon_00799 "Like, we change the database" )
( henrySimon_00800 "We need to be sure that the only difference  between the systems is the one we're interested in   and everything else is controlled so that - when  we get our outcome - we know the only explanation   is the variable of interest and  not some other confounding thing" )
( henrySimon_00801 "So we're already seeing some  aspects of experimental design" )
( henrySimon_00802 "For example, we'll keep the same front end, and   we'll keep the same database if we're trying to  evaluate different forms of waveform generation" )
( henrySimon_00803 "Now, when we're making those  comparisons between variants of systems,   we need to be careful to control  things so that when we have a winner,   we know the reason was because of our  great idea, not some other change" )
( henrySimon_00804 "They might be competitive against other people   as in, for example, the Blizzard  Challenge evaluation campaigns" )
( henrySimon_00805 "They might be against the baseline - an  established standard - that's just Festival" )
( henrySimon_00806 "We're not in industry here, so we're not  going want to know: Did Does it pass or fail?  We really going to be concentrating  on comparing between systems" )
( henrySimon_00807 "We really going to focus on complete systems" )
( henrySimon_00808 "We're not going to say too much more about  evaluating components - that's better covered when   we're talking about how these components work" )
( henrySimon_00809 ", listen  to the waveforms) to know how good they are" )
( henrySimon_00810 "Some components, of course,   only make sense in a complete system, such  as the thing that generates a waveform" )
( henrySimon_00811 "But we also might want to know what the  effect of those components is when they   work within a complete system" )
( henrySimon_00812 "That's just normal machine learning  with a training set and the test set" )
( henrySimon_00813 "We might be able to - in those cases - do some   sort of objective testing against Gold Standard  data: against things we know, with labels" )
( henrySimon_00814 "We're going to put a better part of speech tagger in, or  the letter-to-sound model might have got better,   or we might have improved the dictionary" )
( henrySimon_00815 "For example, we might have a module  which does some normalisation" )
( henrySimon_00816 "If we're building a new front end for a language  or trying to improve the one we've already got,   we'll probably do a lot of testing  on those isolated components" )
( henrySimon_00817 "You could do these evaluations  at many possible points in time" )
( henrySimon_00818 "So that's why we need to evaluate" )
( henrySimon_00819 "We take that forward and refine it and  improve it until we can't make it any better" )
( henrySimon_00820 "We pick the best of them" )
( henrySimon_00821 "We have an idea" )
( henrySimon_00822 "And so research is a little bit like this   greedy evolutionary search" )
( henrySimon_00823 "Again, we'll do another evaluation, and perhaps  one of those turns out to be better than the rest" )
( henrySimon_00824 "And again, I'd like to find out  which of those was the best idea" )
( henrySimon_00825 "I had again four ideas (it's a magic number!)" )
( henrySimon_00826 "You have now got another   bunch of systems you would like to evaluate" )
( henrySimon_00827 "So I'll make some new systems in   this evolutionary way" )
( henrySimon_00828 "I'll take this idea, and I'll make some further   enhancements to it - some more variants on it" )
( henrySimon_00829 "So perhaps I'll drop the other ideas" )
( henrySimon_00830 "Let's imagine that the idea in  this system was a great idea" )
( henrySimon_00831 "There was some outcome from that" )
( henrySimon_00832 "So I'll generate some examples from those systems" )
( henrySimon_00833 "I've built four different variations on Festival,  each one embodying one of these brilliant ideas" )
( henrySimon_00834 "I've had four brilliant ideas  about how to make it better" )
( henrySimon_00835 "I've taken the Festival speech synthesis system" )
( henrySimon_00836 "Imagine I have basic system" )
( henrySimon_00837 "But why do we evaluate? Well, it's to make decisions" )
( henrySimon_00838 "Why do we need to evaluate it all?  It's not always obvious, because it's  something that's just not spelled out ever" )
( henrySimon_00839 "So on to the first of those  in a bit more detail, then" )
( henrySimon_00840 "For example, how do we improve our system,  knowing what we've learned in the listening test?  So what do we do with the outcome of  listening test or some other evaluation?" )
( henrySimon_00841 "When you've done all of that, you need  to then make a decision what to do next" )
( henrySimon_00842 "For example, comparing it to a natural  example and measuring some distance" )
( henrySimon_00843 "In other words, measures that don't need  a listener - measures that are in fact an   algorithm operating on the synthetic speech" )
( henrySimon_00844 "We'll also quite briefly mentioned  the idea of objective measures" )
( henrySimon_00845 "We'll think about how to measure the listeners'  performance on that task, with those materials" )
( henrySimon_00846 "Put that into some test design, which  includes the materials we should use on" )
( henrySimon_00847 "We're going to design a task" )
( henrySimon_00848 "We'll think about how to evaluate" )
( henrySimon_00849 "Then, having established all  of that, we'll get to the meat" )
( henrySimon_00850 "Because there's no guarantee that the synthetic   speech sounds like the person  that we want it to sound like" )
( henrySimon_00851 "Assuming that it's the synthetic speech we're  going to evaluate rather than the performance of   some component of the system, we have to think: "What is it about speech that we   could actually measure?" Some obvious things will be:  Can you understand what was said? Did it sound something like natural speech?  Maybe less obviously, and something that'll become  a lot more clear when we move on to parametric   forms of synthesis, is speaker similarity" )
( henrySimon_00852 "It might be during development" )
( henrySimon_00853 "If it's to improve our own system,  we might do it fairly frequently" )
( henrySimon_00854 "Depending on our goals, we might then need to  decide when we're going to do that evaluation" )
( henrySimon_00855 "If we're going to sell this  thing, we might simply want to say   it's good enough to put in front of customers  and that'll be just a simple pass-fail decision" )
( henrySimon_00856 "Our technique is an  improvement over some baseline" )
( henrySimon_00857 "We're going to start right   back at the beginning, thinking: "Why do we want to evaluate?"  "What is it that we want to  get out of that evaluation?" Most of the time, we're trying to learn  something for ourselves that will help us   make our system better" )
( henrySimon_00858 "We're not just going to make some synthetic   speech, play it to listeners  and see what they think" )
( henrySimon_00859 "We're going to be a little bit systematic" )
( henrySimon_00860 "Now, before we just jump in and  try and evaluate synthetic speech,   let's sit down and think  very carefully about that" )
( henrySimon_00861 "Because you can't feed back the  results of that listening test   down into the insides of the system and say,  "This error was because of letter-to-sound"" )
( henrySimon_00862 "And that's one reason it's rather hard   to automatically optimise the system  based on the results a listening test" )
( henrySimon_00863 "So both naturalness and intelligibility  can be affected by things that happen   in the front end and in waveform generation" )
( henrySimon_00864 "Other types of errors might in fact affect intelligibility" )
( henrySimon_00865 "It will sound unnatural in  some way: unnatural prosody,   unnatural signal quality  because of concatenation, perhaps" )
( henrySimon_00866 "Some things are going to obviously affect  the naturalness of the synthetic speech" )
( henrySimon_00867 "They'll impact different  aspects of the synthetic speech" )
( henrySimon_00868 "Different errors will lead to  different perceptual consequences" )
( henrySimon_00869 "We'll get concatenation artefacts To have a good understanding of why people  hear some errors but not other errors,   it will be useful to go and  revise your acoustic phonetics   and make sure you know a little  bit about speech perception" )
( henrySimon_00870 "Or they might not have joined very well" )
( henrySimon_00871 "So they have the wrong  co-articulation, for example" )
( henrySimon_00872 "Let's just think about unit  selection in this section" )
( henrySimon_00873 "Things will also go wrong  when we generate the waveform" )
( henrySimon_00874 "And other things like prosody could be wrong" )
( henrySimon_00875 "Pronunciations could be incorrect:   letter-to-sound could go wrong" )
( henrySimon_00876 "And because you've got that understanding, you  should have some ideas about where errors can come   from, why synthetic speech is not perfect" )
( henrySimon_00877 "Of course, you should have a pretty  good understanding of the complete   process of text to speech synthesis by this point" )
( henrySimon_00878 "So, what do we do with the  outcome of an evaluation?" )
( henrySimon_00879 "And some other aspects of experimental design" )
( henrySimon_00880 "How we present the stimuli to listeners" )
( henrySimon_00881 "How do you evaluate? In that section,   we will look at methodologies for evaluation" )
( henrySimon_00882 "Once we have established those things, we'll  move on to thinking about exactly how to do that" )
( henrySimon_00883 "But we are mainly going to   focus on the more obvious speech synthesis  evaluation, which is to listen to the speech   and make some judgements, perhaps about  its naturalness and its intelligibility" )
( henrySimon_00884 "We might evaluate its internal components,   its reliability, or speed" )
( henrySimon_00885 "There are many aspects of a system" )
( henrySimon_00886 "Do we do that while we're building a system? Do we wait until we're finished?" )
( henrySimon_00887 "That will help us think about  when it's appropriate to evaluate" )
( henrySimon_00888 "What we're going to do with the result of that" )
( henrySimon_00889 "We'll start right at the beginning" )
( henrySimon_00890 "In this module, we're going  to talk about evaluation" )
( henrySimon_00891 "Is it how intelligible the speech is? Or is there something else we can measure?" )
( henrySimon_00892 "We'll think in detail about exactly what aspects of the speech we want to measure and put quantities on: Is it naturalness?" )
( henrySimon_00893 "All of those have advantages and disadvantages and we'll consider those" )
( henrySimon_00894 "We'll answer the question about who should be listening to the speech, and whether it should be us or other listeners, or indeed some algorithms (some objective measures)" )
( henrySimon_00895 "But, in general, we need to have a good think about what do we want to measure and why exactly do we want to do evaluation" )
( henrySimon_00896 "Maybe we can measure some objective properties of the speech to decide how good it is?" )
( henrySimon_00897 "Of course we should listen to it ourselves: that's going to be helpful! We probably want to ask other people to listen to it, so we can get multiple listeners for a bit more reliability" )
( henrySimon_00898 "We'll think about what are fair means to evaluate it" )
( henrySimon_00899 "Unit selection then is just retrieval of candidates from that labelled database, followed by a search" )
( henrySimon_00900 "That concludes our look at databases: what to put in the recording script; how to annotate that speech once we've recorded in the studio" )
( henrySimon_00901 "If we looked inside the Festival utterance structure after all of this process, we'd see that some timestamps had appeared on it" )
( henrySimon_00902 "Those sequences are not identical, but they're very similar, so we can make that transfer and in doing so we can also add in the short pauses where they existed, and we can mark which vowels got reduced by the speaker when he or she said this sentence" )
( henrySimon_00903 "You just take the timestamps off one and transfer them to the other" )
( henrySimon_00904 "This was the canonical sequence from the front end" )
( henrySimon_00905 "It's got timestamps" )
( henrySimon_00906 "This level was the force-aligned phone sequence" )
( henrySimon_00907 "But the simple method actually works quite well and it's the standard way of building voices when we use Festival, for example" )
( henrySimon_00908 "That's a little bit simplistic: we might imagine we could do better than that by, for example, hand-labelling prosody (if we think we can do that accurately" )
( henrySimon_00909 "We'll just take the predictions from the front end" )
( henrySimon_00910 "We're not going to do any alignment or modifications to try and make it match what the speaker said" )
( henrySimon_00911 "We're just going to get the supra-segmental information from the text, using the front-end" )
( henrySimon_00912 "Here's the phonetic sequence from forced alignment We're going to attach that to all the supra-segmental information" )
( henrySimon_00913 "We need to attach supra-segmental information to that" )
( henrySimon_00914 "We know the start and end times of every segment" )
( henrySimon_00915 "What we now have then is a phonetic sequence with timestamps" )
( henrySimon_00916 "We'll repeat that for every sentence in the database with our fully-trained models, that have been acquired using flat start training" )
( henrySimon_00917 "In other words, we'd know the time that we left each of these phone models" )
( henrySimon_00918 "This token would remember its state sequence and its model sequence and would let us recover the timestamps" )
( henrySimon_00919 "and this with its full pronunciation" )
( henrySimon_00920 "maybe we say this with its full pronunciation" )
( henrySimon_00921 "we maybe reduce this vowel" )
( henrySimon_00922 "We might say "There" )
( henrySimon_00923 "Let's imagine a route that the token might take" )
( henrySimon_00924 "On this network here, we just do token passing" )
( henrySimon_00925 "Then we end" )
( henrySimon_00926 "The canonical pronunciation or the vowel reduction" )
( henrySimon_00927 "Again the canonical pronunciation, or reduce the vowel" )
( henrySimon_00928 "The word can have its canonical full pronunciation, or the vowel can be reduced" )
( henrySimon_00929 "I'll omit the arrows (they all flow from left to right, of course)" )
( henrySimon_00930 "So we add some more nodes in the network for that, and now we can draw the arcs in to see how this finite state network looks" )
( henrySimon_00931 "The other was to put this special short pause model at every word juncture, in case speakers put pauses where our front-end didn't predict it in the phone sequence" )
( henrySimon_00932 "One was to allow every vowel to be reduced, so it's optional vowel reduction" )
( henrySimon_00933 "We can now enhance that with those two little tricks" )
( henrySimon_00934 "I won't draw them in, just to keep things neat" )
( henrySimon_00935 "Again, remember these are all finite state and there are arcs joining all of those together" )
( henrySimon_00936 "That's this model here" )
( henrySimon_00937 "Let's just remind ourselves: it's got arcs and states like this" )
( henrySimon_00938 "There's a language model: that's finite state" )
( henrySimon_00939 "Let's start with the language model" )
( henrySimon_00940 "That's to compile together language model, pronunciation model, and acoustic model into a single finite state network, and then do token passing" )
( henrySimon_00941 "Right, let's do some speech recognition!" )
( henrySimon_00942 "So that's a little trick to get us an optional short pause model and to train it easily by tying it to our main silence model" )
( henrySimon_00943 "This model here, we're going to call 'sp' and there's an easy way to initialize the parameters of the state of this model and it's just to tie them to the centre state of this model, which will be easier to train because we'll always have a few 100 ms of silence at the beginning and end of every sentence that we recorded in the studio" )
( henrySimon_00944 "This 3-state silence model (we'll typically call it silence, or something like that)" )
( henrySimon_00945 "So we're always going to have our traditional (perhaps 3-state) silence model" )
( henrySimon_00946 "But what we do know is that there's silence at the beginning and the end of the sentence and we're going to have a 'long silence' model to deal with those" )
( henrySimon_00947 "It's not obvious how to train this model, because we don't know where these optional silences are" )
( henrySimon_00948 "So we need to train this model" )
( henrySimon_00949 "This skip transition has given us a model of optional silence" )
( henrySimon_00950 "We can do that just by adding this extra transition, like this" )
( henrySimon_00951 "We'd like to be able to emit no observations so that we have optionality, in other words it can have zero duration" )
( henrySimon_00952 "As it stands there, it must emit at least one observation to get from the start to the end" )
( henrySimon_00953 "That's just a 1-state HMM that can emit observations" )
( henrySimon_00954 "So it's got a state, it's got a self-transition, it's got a start and an end non-emitting state (because we're using HTK)" )
( henrySimon_00955 "The way that we do that is to insert an additional acoustic model at every word juncture, that's a model of optional silence" )
( henrySimon_00956 "Perhaps our front end didn't predict a pause in that situation" )
( henrySimon_00957 "This speaker has inserted a pause between these two words" )
( henrySimon_00958 "Let's just make our language model a little bit more sophisticated, to accommodate variations that the speaker might make that our front end doesn't predict, and that is inserting pauses between words" )
( henrySimon_00959 "Right, we've got all the ingredients then: a language model constructed from the sentences we know; a pronunciation model from the dictionary, plus rules; acoustic models created with this thing called flat start training" )
( henrySimon_00960 "That extends out to a whole sentence" )
( henrySimon_00961 "We just do exactly the same sort of training to train this long model from this long observation sequence" )
( henrySimon_00962 "We know the start aligns with the start of the audio, the end aligns with the end of the audio" )
( henrySimon_00963 "So we essentially had isolated digit training data" )
( henrySimon_00964 "Then, given this set of observations, we could train the model of "one" and the same for all the other digits" )
( henrySimon_00965 "In the exercise to "Build your own digit recognizer", we needed to know that the beginning of this model aligned with the speech and where the end of the model aligned with the speech" )
( henrySimon_00966 "They're models of digits" )
( henrySimon_00967 "Let's see how flat start training is just a generalization of what we already know about speech recognition" )
( henrySimon_00968 "It's called "flat start training"" )
( henrySimon_00969 "Training that big, long HMM is no different to training a whole word model on segmented data" )
( henrySimon_00970 "We just take our sub-word models (say, phone models) and we concatenate them together to get models of words, and then we concatenate word models to get a model of a sentence" )
( henrySimon_00971 "That's easy, in fact" )
( henrySimon_00972 "We can generalize the idea of not needing state-level alignments to not needing model- or word-level alignments" )
( henrySimon_00973 "That we're very tedious to try and do by hand" )
( henrySimon_00974 "So, building a speech recognition system never needs state-level alignments" )
( henrySimon_00975 "But think again: when we train whole word models such as in the "Build your own digit recognizer" exercise, those word models have many states and we did not need to align the states to the speech" )
( henrySimon_00976 "If all you know about automatic speech recognition is how to use whole word models, then you might think that we need to align the data at the word level before we can train the system" )
( henrySimon_00977 "We know the word transcriptions of all the data and we have an alignment at sentence boundaries between the transcriptions and the speech" )
( henrySimon_00978 "Well it's no different to building any other speech recognition system" )
( henrySimon_00979 "So how can we train our acoustic models on the recorded speech data?" )
( henrySimon_00980 "The other remaining ingredient to build is the acoustic model" )
( henrySimon_00981 "If our dictionary was more sophisticated and had full pronunciation variation capabilities, that could be expressed in a finite state form and would become part of the alignment network" )
( henrySimon_00982 "We saw how the language model is just derived from the sentences that we ask the speaker to read" )
( henrySimon_00983 "It's that alignment that we want, not the word sequence" )
( henrySimon_00984 "We train models on the data and then find the alignment between the models and the data" )
( henrySimon_00985 "We've just got data" )
( henrySimon_00986 "So there's no concept of a split between training and testing here" )
( henrySimon_00987 "The product is not the word sequence, it's just the timestamps" )
( henrySimon_00988 "We're not really doing recognition: we're doing alignment" )
( henrySimon_00989 "We might have thousands or tens of thousands of sentences, which is plenty of data to train context-independent phone models" )
( henrySimon_00990 "We could borrow fully-trained models from an existing speech recognition system, for example speaker-independent models, although actually in practice we do tend to get better results with rather simpler models which we can make speaker-dependent, because we can train them on the same data that we're aligning" )
( henrySimon_00991 "The third and final ingredient is the acoustic model, that's going to actually emit observations" )
( henrySimon_00992 "I can say "What can [k ae n] it do for" )
( henrySimon_00993 "We'll write out our finite state pronunciation model of the word "can", add arcs, and optionally, instead of the full vowel, we could generate a reduced vowel" )
( henrySimon_00994 "It maps words - such as this word - to pronunciations, such as this" )
( henrySimon_00995 "The next ingredient is a pronunciation model that maps the words in the language model to phones, of which we have HMMs" )
( henrySimon_00996 "That was the language model" )
( henrySimon_00997 "That will get forced alignment for us" )
( henrySimon_00998 "We're going to compile that together with the acoustic model and pronunciation model to make our recognition network, do token passing, and ask the tokens to record when they left every single state or phone, depending what alignment we want" )
( henrySimon_00999 "That's a finite state language model" )
( henrySimon_01000 "It's a finite state language model" )
( henrySimon_01001 "So that's what we're going to force align to the speech that they produced" )
( henrySimon_01002 "Here's the sentence we asked the speaker to say" )
( henrySimon_01003 "Let's write the simplest language model we can think of" )
( henrySimon_01004 "Let's assume we have a set of fully-trained phone models for now, and see what the language model looks like" )
( henrySimon_01005 "We'll come back to exactly how to train the acoustic models in a moment" )
( henrySimon_01006 "One thing we might do is add optional silences between the words" )
( henrySimon_01007 "In fact, the language model will be different for every sentence: we'll switch the language model in and out as we're aligning each sentence" )
( henrySimon_01008 "That's a very simple language model" )
( henrySimon_01009 "What we need is just a model of the current word sequence for the current sentence" )
( henrySimon_01010 "We're going to see in a moment that some rule-based variation, and specifically vowel reduction, is often built in" )
( henrySimon_01011 "We might extend it in ways that we don't normally do for speech recognition, such as putting in pronunciation variation" )
( henrySimon_01012 "That's just going to be our pronunciation dictionary: the same one we already have for synthesis" )
( henrySimon_01013 "We need a pronunciation model that links the word level to the phone level" )
( henrySimon_01014 "They're going to be phone-sized models" )
( henrySimon_01015 "We need acoustic models, that is, models of the units that we want to align" )
( henrySimon_01016 "So the ingredients for a building forced aligner are basically exactly the same ingredients as for automatic speech recognition" )
( henrySimon_01017 "We could get model- or state-alignments trivially, just by asking the tokens to record these things as they make their way around the recognition network" )
( henrySimon_01018 "Or we could ask them to remember when they left each state" )
( henrySimon_01019 "They could also remember the times (the frames) where they left each model: in other words, each phoneme" )
( henrySimon_01020 "In automatic speech recognition, we normally only want to recover the word sequence, because that's all we want to output" )
( henrySimon_01021 "Knowing the word sequence is basically like having a really, really good language model: very highly constrained" )
( henrySimon_01022 "But this is much easier than full-blown speech recognition, because we know the word sequence" )
( henrySimon_01023 "The way that we're going to do that is basically to do automatic speech recognition to transcribe the speech" )
( henrySimon_01024 "In other words, if the speaker deviated from the text in some way - such as inserting a pause where the front end didn't predict a pause - we're going to discover that completely automatically" )
( henrySimon_01025 "We're going to consider only a way of doing this fully automatically" )
( henrySimon_01026 "We're not going to consider this idea of manual correction here: it's too time-consuming and too expensive" )
( henrySimon_01027 "They're really going to be looking for gross errors such as bad misalignments, or speakers saying something that really doesn't match the text" )
( henrySimon_01028 "Those corrections are not going to be small changes to alignments ('microscopic changes')" )
( henrySimon_01029 "Of course, that is possible, and that's standard practice actually in some companies" )
( henrySimon_01030 "A natural question is whether we could automatically label speech and then, by hand, make some small changes to match what the speaker actually said" )
( henrySimon_01031 "Having consistent names for those units in that index is more important than being very faithful to what the speech actually says" )
( henrySimon_01032 "A good way to understand that is to think about the labels on the database as not being a close phonetic transcription of the speech, but being just an index: a way of retrieving appropriate units for our search to choose amongst" )
( henrySimon_01033 "But an equally important reason is that it's more consistent between what's in the database and what happens when we synthesize an unseen sentence" )
( henrySimon_01034 "Yes, that's faster and cheaper, and that's a very important reason for doing it" )
( henrySimon_01035 "We're going to prefer this to be done automatically" )
( henrySimon_01036 "The sort of labelling we're doing, Taylor calls "analytical labelling"" )
( henrySimon_01037 "Our preference is going to be start from the text that we asked the speaker to read, get the phonetic sequence, and then make some further small modifications to adjust it so it's a slightly closer fit to what the speaker said in (for example) pausing" )
( henrySimon_01038 "Consistency will help us pull out longer contiguous units by getting an exact match between the labels on the database and what the front end does at synthesis time" )
( henrySimon_01039 "Joins are what listeners notice" )
( henrySimon_01040 "In other words, we'll make more joins than necessary" )
( henrySimon_01041 "Those mismatches will mean that - when we try and say this whole sentence, or perhaps just fragments of it - at synthesis time, we won't retrieve long contiguous sequences of units from the database" )
( henrySimon_01042 "There might be systemic mismatches there" )
( henrySimon_01043 "That phonetic sequence will be very faithful to what the speaker said, but it might be rather hard to match that up with what the front end does at synthesis times" )
( henrySimon_01044 "We could start from what the speaker said and we could hand transcribe and get a phonetic sequence" )
( henrySimon_01045 "A good example of that might be that the speaker put a pause between two words that our front end did not predict, because maybe our pausing model in the front end is not perfect" )
( henrySimon_01046 "That will be very consistent, but there might be things our speaker did that are radically different to what's in that canonical sequence" )
( henrySimon_01047 "We can then make some time alignment between that canonical sequence and what the speaker actually said (their waveform)" )
( henrySimon_01048 "That's the canonical sequence" )
( henrySimon_01049 "To summarize that situation: we have some text that our speaker reads out; we could put that through the text-to-speech front-end and get a phonetic sequence from that" )
( henrySimon_01050 "We'll see exactly how we make those modifications, and why, as we go through the next few sections" )
( henrySimon_01051 "We're going to move it a little bit closer to what the speaker actually said" )
( henrySimon_01052 "We're going to slightly modify the sequence that comes out of the front end" )
( henrySimon_01053 "Now there are some points in between these two extremes, and we're going to take one of those as our basis for labelling" )
( henrySimon_01054 "The only way we could do that, is if the database had exactly the same labels on it that our front end predicts at the time we try and synthesize that sentence, regardless of how the speaker said it" )
( henrySimon_01055 "We would obviously want to pull out the entire waveform and play it back and get perfect speech" )
( henrySimon_01056 "Consider the example of trying to say a sentence that exists in its entirety in the database" )
( henrySimon_01057 "If we had to choose between these two things, we'd actually want to choose this end, because we want consistency between the database and the runtime speech synthesis" )
( henrySimon_01058 "In other words, the sequence that is exactly what comes out of the front end" )
( henrySimon_01059 "We can call that the "canonical phone sequence"" )
( henrySimon_01060 "So another extreme would be to label the database in a way that's entirely consistent with what the front-end is going to do at synthesis time" )
( henrySimon_01061 "But that sequence might not be the same as our speaker said the particular sentence in the database" )
( henrySimon_01062 "It might make mistakes, but it will be at least consistent" )
( henrySimon_01063 "The front-end is not perfect" )
( henrySimon_01064 "The target sequence will have gone through our text-to-speech front-end" )
( henrySimon_01065 "We're going to retrieve units and that retrieval will try to match a target sequence" )
( henrySimon_01066 "We're going to do unit selection speech synthesis" )
( henrySimon_01067 "But, if we think about what we're going to do with this data" )
( henrySimon_01068 "We'll be down at this end of the continuum" )
( henrySimon_01069 "Then we might think we want to hand label from scratch" )
( henrySimon_01070 "If we think that we need a transcription of the speech that's exactly faithful to how the speaker said the text: It gets every vowel reduction, every slight mispronunciation, every pause, everything exactly faithful to the way the speaker said the text" )
( henrySimon_01071 "Let's think about two extremes of ways that we might label the speech, to understand why hand labelling might not be the right answer" )
( henrySimon_01072 "Then we'll see how we attach the supra-segmental (in other words, the stuff above the phonetic level), how we attach the supra-segmental information to that phonetic transcription that's been time aligned" )
( henrySimon_01073 "We'll start by looking at the time-aligned phonetic transcription" )
( henrySimon_01074 "What remains to be done is to segment the speech: to put phonetic labels on it, so we know where each (for example) diphone starts and ends" )
( henrySimon_01075 "So we'll record the script in that same order, meaning that we can stop at any point and maximize the coverage for that given amount of material" )
( henrySimon_01076 "They'll be recorded generally as isolated sentences" )
( henrySimon_01077 "With that script, we've gone into a recording studio and asked a speaker (sometimes called the "voice talent") to record those sentences" )
( henrySimon_01078 "It will aim to: cover the units-in-context; to be readable; to provide each base unit in a wide variety of different linguistic contexts; and possibly some other things as well, such as specific domains" )
( henrySimon_01079 "That script will have been designed, probably by a text selection algorithm that we've written" )
( henrySimon_01080 "What we've got so far is a script, which is composed of individual sentences" )
( henrySimon_01081 "We'll finish off this module on the database by looking at how we're going to label it ("annotate" it) But let's just orient ourselves in the bigger picture before we continue" )
( henrySimon_01082 "The next step will be to label that recorded database" )
( henrySimon_01083 "Then we're going to have a recorded database" )
( henrySimon_01084 "Find a voice talent who can read sentences fluently with a pleasant voice, and ask that person to read each of our sentences" )
( henrySimon_01085 "All that remains then is to go into the recording studio!" )
( henrySimon_01086 "Then we can get the best of both worlds: particularly good coverage in a domain and general-purpose coverage, so we can also say anything else" )
( henrySimon_01087 "So a standard approach to getting a domain-specific script is to first use your in-domain sentences (they might be manually written, or from some language-generation system); measure the coverage of that; then fill in the gaps with a standard text selection algorithm, from some other large corpus" )
( henrySimon_01088 "If we just selected a script of strictly in-domain sentences, we'd expect very good performance in that domain but we might be missing a lot of units that we need for more general-purpose synthesis" )
( henrySimon_01089 "These might be decided by, for example, the particular product that our synthesizer is going into" )
( henrySimon_01090 "Another thing we might do is try and include some domain-specific material for one or more domains" )
( henrySimon_01091 "That's because we'll get the high frequency ones along "for free" anyway" )
( henrySimon_01092 "In other words, give sentences a higher score for containing low-frequency diphones-in-context" )
( henrySimon_01093 "When we start looking for diphones-in-context, we might actually want to go looking for the hardest-to-find units first: the rare ones first" )
( henrySimon_01094 "After that we'll switch to looking for diphones-in-context" )
( henrySimon_01095 "That will mean we'll never have to back off at synthesis time" )
( henrySimon_01096 "One sensible thing - that our algorithm doesn't currently do - will be to guarantee at least one token of every base unit type" )
( henrySimon_01097 "I've already said there's as much art as there is science to script design, so it's perfectly reasonable to try and craft in some extra selection criteria into your text selection script" )
( henrySimon_01098 "The order of the sentences will be defined by the selection algorithm" )
( henrySimon_01099 "And we can stop at any point: we could record a hundred, or a thousand, or ten thousand sentences, depending how much data we wanted" )
( henrySimon_01100 "So, when we record that script, we probably want to record it in that order too, so we maximize richness" )
( henrySimon_01101 "The result of this algorithm is going to be a list of sentences in a specific order: in order of descending richness" )
( henrySimon_01102 "and some other ones" )
( henrySimon_01103 "Remember that was these ones" )
( henrySimon_01104 "The scores will be different than the first time round, because any diphones that have already gone into the script no longer score points" )
( henrySimon_01105 "Then we'll score the remaining sentences" )
( henrySimon_01106 "That sentence has been selected: it disappears from the large corpus" )
( henrySimon_01107 "Our wish list has got smaller, and sentences will no longer score any points for containing those diphones because we've already got them" )
( henrySimon_01108 "So: these diphones" )
( henrySimon_01109 "So I'll scan through the sentence and I'll look at all the diphones that occurred there and I'll cross them off my wish list" )
( henrySimon_01110 "So I will select that sentence, and I'll put it in my script for my speaker to read out in the recording studio later" )
( henrySimon_01111 "It's got the most new types in the smallest sentence" )
( henrySimon_01112 "Under my scoring function it turns out that this sentence here scores the highest" )
( henrySimon_01113 "So at the very least, we're going to control for length" )
( henrySimon_01114 "If we were just a count the number of types, then we would pretty much always choose long sentences, because they're more likely to have more types in" )
( henrySimon_01115 "We'll just do this impressionistically" )
( henrySimon_01116 "We won't write that out" )
( henrySimon_01117 "What we need is a function that assigns a score to each of these sentences" )
( henrySimon_01118 "So we can get rid of these duplicates" )
( henrySimon_01119 "When we're doing that scoring, if a sentence contains two copies of a particular unit-in-context (here, just the diphone) then only one of them will count" )
( henrySimon_01120 "Richness is going to be defined as the number of diphones that I don't yet have in my script" )
( henrySimon_01121 "What I'm going to do, I'm going to score each sentence for "richness"" )
( henrySimon_01122 "Again, in reality we might attach context to those" )
( henrySimon_01123 "Here's my wish list: it's just the diphones" )
( henrySimon_01124 "This is just the first few sentences of this very large corpus" )
( henrySimon_01125 "The method will work the same for diphones-in-context, of course" )
( henrySimon_01126 ") If we start adding linguistic context, that wish list will grow in size exponentially as we add more and more context features" )
( henrySimon_01127 "(Remembering that silence would also be treated as a phoneme in this system" )
( henrySimon_01128 "to this one" )
( henrySimon_01129 "If we were just looking for diphones (ignoring context for a moment), we would just write out the list of all possible diphones: from this one" )
( henrySimon_01130 "One way to think about the algorithm is to imagine a "wish list" that enumerates every possible type that we're looking for" )
( henrySimon_01131 "We only have the text, so all we can really do is put that text through the front end of our text-to-speech system and obtain - for each sentence - the base unit sequence (for example, the sequence of diphones) and the linguistic context attached to each of those" )
( henrySimon_01132 "Now we don't have a speaker reading these sentences out yet" )
( henrySimon_01133 "So we need to know - for all the sentences in this large text corpus - what units they contain" )
( henrySimon_01134 "The goal of our text selection algorithm is going to simply be coverage of unit types-in-context" )
( henrySimon_01135 "There are readability measures (that are beyond the scope of this course) that you could use, or we could base that on vocabulary" )
( henrySimon_01136 "Depending on who your speaker is, you might also want to throw away sentences that you deem "hard to read"" )
( henrySimon_01137 "We might also throw away very short sentences because their prosody is atypical" )
( henrySimon_01138 "We might throw away all sentences that are rather long: they're hard to read out loud with reasonable prosody, and we're also much more likely to make mistakes" )
( henrySimon_01139 "We might throw away all the sentences that have words that are not in our dictionary, because we don't trust letter-to-sound rules" )
( henrySimon_01140 "We're going to therefore need to clean up the text a bit" )
( henrySimon_01141 "And because, for example, they might be proper names, we don't anticipate that our letter-to-sound rules will work very well" )
( henrySimon_01142 "For example: they're not in our dictionary" )
( henrySimon_01143 "In that text there's likely to be a lot of words for which we don't have reliable pronunciation information" )
( henrySimon_01144 "The first step would be to clean up the corpus" )
( henrySimon_01145 "We'll assume we have some large corpus of text to start from" )
( henrySimon_01146 "But be very careful, because historical novels might have language that's archaic and might be very difficult for your speaker to read out loud" )
( henrySimon_01147 "We might want to correct for that in our text selection algorithm" )
( henrySimon_01148 "We've already mentioned that phrase-initial and phrase-final segments might be rather low frequency in text because the sentences are much longer than in spoken language" )
( henrySimon_01149 "There might be very simple differences, like there are far fewer questions in newspaper text than there are in everyday speech" )
( henrySimon_01150 "For example" )
( henrySimon_01151 "It might be hard to read sentences from old novels out loud" )
( henrySimon_01152 "That would have consequences for the readability" )
( henrySimon_01153 "Regardless of where you get the text from, it's most likely that this is written language and was never meant to be read out loud" )
( henrySimon_01154 "If you care about copyright, then you might want to get text for which either there is no copyright (for example, out-of-copyright material), or you might want to obtain permission from the copyright holder" )
( henrySimon_01155 "You might want to be very careful about where that text comes from" )
( henrySimon_01156 "At the end, we'll look at a few little modifications we might make to that" )
( henrySimon_01157 "We add the best sentence from the large corpus to the script, and then we iterate" )
( henrySimon_01158 "The sort of thing we might use to score will be, perhaps, finding sentences with the largest number of types that were not yet represented in our script" )
( henrySimon_01159 "The score is about how good it would be if it was added to the script" )
( henrySimon_01160 "The algorithm goes like this: we take our large text corpus, and for every sentence in that corpus we give it a score" )
( henrySimon_01161 "In other words, we're going to make decisions and never backtrack" )
( henrySimon_01162 "Every company that makes speech synthesis has their own script design method and probably has their own script that's evolved through many voice builds" )
( henrySimon_01163 "Now, there's as much art as there is science in script design! I'm not presenting this as the only solution" )
( henrySimon_01164 "We'll stop at some point: perhaps when the script is long enough, or when we think coverage is good enough" )
( henrySimon_01165 "In other words, we're going to choose - one at a time - sentences from a very large corpus, and accumulate them in our script" )
( henrySimon_01166 "It's going to start from a very large text corpus and make a script from that" )
( henrySimon_01167 "It's going to be an algorithm: in other words, it's automatic" )
( henrySimon_01168 "You're going to explore some of those things for yourself in the exercise, so we won't cover them too much more here" )
( henrySimon_01169 "That's because you can explore them for yourself in the "Build your own unit selection voice" exercise" )
( henrySimon_01170 "There might be other goals that we'd like to include in our script design, not just coverage in the smaller script possible" )
( henrySimon_01171 "So if we've got to store the database in the runtime system (that we might be shipping to our customer) we don't want it to be too many gigabytes" )
( henrySimon_01172 "The second reason to keep the database size small is that, at least in unit selection, the runtime system will include an actual copy of that entire database: the waveforms" )
( henrySimon_01173 "Professional speakers are much better at that; that's one reason to use them" )
( henrySimon_01174 "In particular, when the recording sessions are split over days or weeks or maybe even months, it's very hard to have the same speaking effort, voice quality, and so on" )
( henrySimon_01175 "Amateur speakers (like me, and probably you) find that very hard" )
( henrySimon_01176 "A side effect of taking a long time to record something is that it's harder and harder to maintain a very consistent speaking style over longer recording periods" )
( henrySimon_01177 "One is obvious: it will take time to record this thing" )
( henrySimon_01178 "There's a few good reasons for keeping the database size small" )
( henrySimon_01179 "The longer that list, then the more chance there is of finding sequences that concatenate well together" )
( henrySimon_01180 "Just as important then, is that - for each target position - we have a list of candidates from which the join cost can choose" )
( henrySimon_01181 "The target cost will rank and help us choose between various degrees of mismatch in the various linguistic features" )
( henrySimon_01182 "The target costs will quantify how bad the mismatch is, but the mismatch does not have to be zero" )
( henrySimon_01183 "In fact, the point of unit selection is that we don't need an exact match between the specification of the candidate and the specification of the target" )
( henrySimon_01184 "Now, we certainly would increase that, but it would remain very unlikely" )
( henrySimon_01185 "In other words, finding exactly the candidate that has the properties of the target: with all of the linguistic specification being the same" )
( henrySimon_01186 "What's that going to achieve? Well it would appear to increase the chance of finding an exact match at synthesis time" )
( henrySimon_01187 "In other words, to cover as many units-in-context as possible" )
( henrySimon_01188 "At first glance, it would appear the main design goal of our script is to improve coverage" )
( henrySimon_01189 "Well, all we can do then is to try and design a script that's better than random selection, in terms of coverage and maybe some other properties" )
( henrySimon_01190 "So what can we do then?" )
( henrySimon_01191 "In practice, it's going to be impossible to find a database (composed of a set of sentences) that includes at least one token of every unit-in-context type" )
( henrySimon_01192 "We know that - however large the database goes - we'll never cover all of those, because of this Zipf-like distribution" )
( henrySimon_01193 "In fact, we would find that even for very large databases, almost all types (in other words almost all units-in-context) will have no tokens at all" )
( henrySimon_01194 "So it would take a very long time to cover these things in the tail" )
( henrySimon_01195 "Because we're just scaling things up, potentially linearly with the database size" )
( henrySimon_01196 "All we do is move it upwards, so frequent types become ever more frequent and the rare types slowly become more frequent" )
( henrySimon_01197 "In other words, as we increase database size, we don't change the shape of this curve" )
( henrySimon_01198 "The number of infrequent types would grow very slowly, because that's the long tail in the Zipf distribution" )
( henrySimon_01199 "As we did that, the number of tokens, the number of recorded tokens, of frequent types would just increase steadily" )
( henrySimon_01200 "The only thing we could do to improve coverage would be to increase the size of that database: to record more and more sentences" )
( henrySimon_01201 "If we just randomly chose text to record, we would get that Zipf-like distribution, whatever our unit type is, whatever the context is" )
( henrySimon_01202 "We've seen this Zipf-like distribution of linguistic units which makes that very hard to achieve" )
( henrySimon_01203 "Because base units can occur in many possible contexts, there's a very large number of possible types that we'd like to record in our database" )
( henrySimon_01204 "We've established the key concepts of base unit type (let's just assume that's a diphone), of context in which those base unit types occur (that context applies to the sentences in the database and applies equally to the sentences we're going to synthesize)" )
( henrySimon_01205 "So really we should be talking about a Zipf-like distribution, not exactly a Zipf distribution" )
( henrySimon_01206 "In particular, it has this Large Number of Rare Events" )
( henrySimon_01207 "It just is somewhat similar, and has the same sort of properties" )
( henrySimon_01208 "Of course, real data doesn't exactly obey these distributions" )
( henrySimon_01209 "That should have a particular exact equation: it's a particular sort of distribution" )
( henrySimon_01210 "That's going to be one of the main challenges in creating our database" )
( henrySimon_01211 "But, even for just context-independent phonemes, there are a few that are very low frequency" )
( henrySimon_01212 "You should go and try this for yourself with a much bigger set of types" )
( henrySimon_01213 "Because this is a closed set, we don't get a very long tail" )
( henrySimon_01214 "There's a long tail of types down here that are much less frequent; again, at least an order of magnitude less frequent, and possibly more than that" )
( henrySimon_01215 "If we did this with words, or with any other unit, we'd get the same sort of pattern" )
( henrySimon_01216 "Let's run that" )
( henrySimon_01217 "Yes, that's pulling out all of those" )
( henrySimon_01218 "Let's just make sure that bit of pattern works" )
( henrySimon_01219 "I'm going to do that for all of my labelled speech files" )
( henrySimon_01220 "I'm going to look for lowercase letters and I know that they should occur once or twice: so, single letters or pairs of letters, these are what the phoneme labels look like" )
( henrySimon_01221 "Again, I just want to print out the part of the file that matches this expression" )
( henrySimon_01222 "I don't want to print out the filenames that are matching" )
( henrySimon_01223 "I know that these labels are always one or two characters long" )
( henrySimon_01224 "The first thing I'm going to do, I'm going to pull out the labels" )
( henrySimon_01225 "If you're not comfortable with that, do it in Python or whatever your favourite tool is! There's many different ways to do this kind of thing" )
( henrySimon_01226 "So again I'm going to be old-school: just do this directly on the command line" )
( henrySimon_01227 "I was going to pull out the phoneme label and I'm going to do the same thing that I did with the letters" )
( henrySimon_01228 "Let's look at one of those: they're sequences of phonemes, labelling the phones in a spoken utterance, with timestamps and so on" )
( henrySimon_01229 "It doesn't really matter where it's come from at this point" )
( henrySimon_01230 "I've got a directory full of label files of transcribed speech" )
( henrySimon_01231 "We'll look at the distribution of speech sounds" )
( henrySimon_01232 "Let's do one more example" )
( henrySimon_01233 "If we do this for linguistic objects with more and more types, we'll get longer and longer tails, until we end up looking at open-class types such as words, where we'll get a very, very long tail of things that happen just once" )
( henrySimon_01234 "So, the Zipf-like distribution is true for letters, even though there are only 26 types, we still see that decaying distribution" )
( henrySimon_01235 "There's a long tail of letters down here that's rather low in frequency: much, much lower; an order of magnitude lower than those more frequent ones" )
( henrySimon_01236 "We can see that there are a few letters up here that are accounting for a lot of the frequency: in other words, much of the document" )
( henrySimon_01237 "I'm going to reverse the sort, so I get the most frequent thing at the top" )
( henrySimon_01238 "I'm going to 'sort' and sort will just operate on the leftmost field, which is conveniently here the number, and we'll sort it numerically not alpha-numerically" )
( henrySimon_01239 "It's a little bit hard to read like that because it's ordered by letter and not by frequency, so let's sort it by frequency" )
( henrySimon_01240 "There's our distribution" )
( henrySimon_01241 "So there we now have each letter and the number of times it occurs" )
( henrySimon_01242 "Let's see if that works" )
( henrySimon_01243 "We can also ask it to print the count out" )
( henrySimon_01244 "In its own, it will just print out one copy of each set of duplicate lines" )
( henrySimon_01245 "uniq finds consecutive lines that are identical and just counts how many times they occur" )
( henrySimon_01246 "There's a nice way of doing that sort of thing on the command line" )
( henrySimon_01247 "That's just printing the document out letter by letter" )
( henrySimon_01248 "Let's check that bit of the pipeline works" )
( henrySimon_01249 "So we'll grep, and we'll print only the matching part of the pattern, and we'll grep for the pattern "any individual letter in the range a-to-z lowercase"" )
( henrySimon_01250 "I'm going to ignore numbers and punctuation for this exercise" )
( henrySimon_01251 "I'm only going to count the characters a-to-z" )
( henrySimon_01252 "I'm now going to pull out individual characters" )
( henrySimon_01253 "Everything there is lowercase - all has become downcased, you can see" )
( henrySimon_01254 "That's check that bit of the pipeline works" )
( henrySimon_01255 "We take all the uppercase characters and translate them individually to lowercase" )
( henrySimon_01256 "I'll take my document and the first thing I'm going to do is I'm going to downcase everything, so I don't care about case" )
( henrySimon_01257 "We'll see that those numbers have a Zipf-like distribution" )
( henrySimon_01258 "In other words, I'm going to count how many times each letter occurs in this document and then I'm going to sort them by their frequency of occurrence" )
( henrySimon_01259 "I'm going to plot the distribution of letter frequencies" )
( henrySimon_01260 "Let's just have a look at that: it's just some some random text document that I found" )
( henrySimon_01261 "I've downloaded something from the British National Corpus" )
( henrySimon_01262 "Let's take some random text" )
( henrySimon_01263 "I'm going to do it on the shell, because I'm old fashioned" )
( henrySimon_01264 "Use any data you want" )
( henrySimon_01265 "Here's an exercise for you" )
( henrySimon_01266 "Let's have a very simple practical demonstration of this distribution of types being very uneven" )
( henrySimon_01267 "These new words are the rare events, but taken together they're very frequent: they happen all the time" )
( henrySimon_01268 "We've already come across that problem when building the front end" )
( henrySimon_01269 "In other words, in any one particular sentence that we might have to synthesize at runtime, there's a very high chance that we'll need at least one rare type" )
( henrySimon_01270 "So we get this interesting property: that rare events are very large in number" )
( henrySimon_01271 "The flipside of that is that there are many, many types that are individually very, very rare, but there's very large number of such types" )
( henrySimon_01272 "It's certainly going to be true about our units-in-context" )
( henrySimon_01273 "That's true about almost any linguistic unit type" )
( henrySimon_01274 "Other words a very infrequent" )
( henrySimon_01275 "Think about words: you know that some words - such as this one here - are very, very frequent" )
( henrySimon_01276 "Whatever linguistic unit we think of - whether it's the phoneme or indeed the letter or the word - there are very few types - and for purposes of building the database, those types are units-in-context - very few types are very frequent" )
( henrySimon_01277 "Natural language has a very interesting property that is one of the reasons it's difficult to cover all of these contexts" )
( henrySimon_01278 "I'm going to say "unit-in-context" for the remainder of this module" )
( henrySimon_01279 "We've got "base unit types" such as diphones" )
( henrySimon_01280 "Even if we limit the scope of context to just the preceding sound, the following sound, and some basic prosodic features, and positional features, this list will still be very, very long" )
( henrySimon_01281 "If we would like to build a database of speech which literally contains every possible speech base unit type (for example each diphone - maybe there's one to two thousand different diphone types) each occurring in every possible linguistic context, that list will be very, very long" )
( henrySimon_01282 "Just think about the number of permutations of values of those linguistic specification: it's just very, very large" )
( henrySimon_01283 "We'll probably stick to features that are within the sentence" )
( henrySimon_01284 "Although the context in which a speech unit occurs is essentially unbounded (there are an infinite number of possible contexts because there are an infinite number of things that a person might say), in practice it will be finite because we will limit the set of linguistic features that we consider" )
( henrySimon_01285 "For the purposes of designing our database, we're going to keep things a little bit simple and we're just going to consider linguistic features" )
( henrySimon_01286 "The exact specification of context depends entirely on what our front-end can deliver and what our target cost is going to take into account, whether it's an Independent Feature Formulation or an Acoustic Space Formulation" )
( henrySimon_01287 "So the context certainly includes the phonetic context, the prosodic environment, and these derived positional features, and anything else that we think might be interesting to derive from our front-end's linguistic specification" )
( henrySimon_01288 "The number of linguistic features that we consider to be part of the context specification is also unlimited" )
( henrySimon_01289 "They're in sentences, typically" )
( henrySimon_01290 "Given the base unit type then, the second key concept is that these base units occur in a natural context" )
( henrySimon_01291 "All the target cost needs to do is to query the context in which each of the candidates occurs, and measure the mismatch between that and the target specification" )
( henrySimon_01292 "The list of candidates for a particular target position are all of exactly matching diphone type" )
( henrySimon_01293 "The consequence of insisting on this strict match is that our target cost does not need to query the base unit type: they all exactly match" )
( henrySimon_01294 "Then we might have to go and find some similar types of diphones, if we have no examples at all of a particular diphone" )
( henrySimon_01295 "The only exception to that would be if we've made a mistake designing our database" )
( henrySimon_01296 "So, if the target is of one particular diphone we only go and get candidates of that exact type of diphone, from all the different linguistic contexts" )
( henrySimon_01297 "At that retrieval stage, the only thing we do is to strictly match the base unit type" )
( henrySimon_01298 "In our unit selection engine, when we retrieve candidates from the database before choosing amongst them using the search procedure, we look for some match between the target and the candidate" )
( henrySimon_01299 "It's certainly going to be finite - a closed set - and it's maybe going to be of the order of thousands: one or two thousand types" )
( henrySimon_01300 "There's going to be a relatively small number of types of base unit" )
( henrySimon_01301 "So, from now on, let's just assume that our base unit type is the diphone" )
( henrySimon_01302 "We can use fixed-size units (such as the diphone) and the zero join cost trick, to effectively get larger units at runtime" )
( henrySimon_01303 "We also said that we don't really need to think about variable-size units" )
( henrySimon_01304 "In the modules about unit selection, we also talked about using heterogeneous unit types: things of variable linguistic size" )
( henrySimon_01305 "Most commonly that type is going to be the diphone" )
( henrySimon_01306 "Looking at each of those key concepts in a little bit of detail then: The base unit type is the thing that our unit selection engine uses" )
( henrySimon_01307 "That leads us into the third concept, which is coverage: how many of these unit-types-in-linguistic-context we could reasonably get into a database of finite size" )
( henrySimon_01308 "We might want to cover as many of those as possible in the database" )
( henrySimon_01309 "The second key concept is that these base units (for example, diphones) occur in very varied linguistic contexts" )
( henrySimon_01310 "The first key concept is going to be that of the "base unit type" such as the diphone" )
( henrySimon_01311 "Before starting the discussion of what's going in the database, let's just establish a few key concepts to make sure we have our terminology right" )
( henrySimon_01312 "So, you need to know just the basics of speech recognition: using simple Hidden Markov Models, for example context-independent models of phonemes; very simple language modelling using finite state models; and how decoding works, in other words, how we choose the best path through our network of language model and acoustic model" )
( henrySimon_01313 "We're going to borrow some techniques from Automatic Speech Recognition" )
( henrySimon_01314 "There might be some other good reasons not to do it by hand" )
( henrySimon_01315 "Because the database is large, we might not want to do that by hand" )
( henrySimon_01316 "So we need some time alignment" )
( henrySimon_01317 "At the very least, we need to know where every unit starts and finishes" )
( henrySimon_01318 "The database is going to be fairly large, and we're going to need to label it" )
( henrySimon_01319 "Our target cost function is going to rank units from the database: it's going to rank candidates" )
( henrySimon_01320 "Given that linguistic specification, you should also understand that we're going to select units at synthesis time from the most similar context we can find to the target" )
( henrySimon_01321 "In other words, what features the front-end is able to provide: Phonetic features, such as the current sound, preceding sound, following sound; Prosodic features; and also what we might be able to easily derive from those things, such as position - where we are in the current prosodic phrase, for example" )
( henrySimon_01322 "You need to know what's in that linguistic specification" )
( henrySimon_01323 "What should you already know? You should certainly know how the front end works, and in particular that it produces a thing called a linguistic specification" )
( henrySimon_01324 "So now we need to think about what's going to go into that database" )
( henrySimon_01325 "The target cost function would be making comparisons between these units here and the predicted acoustic properties from a powerful statistical model" )
( henrySimon_01326 "Here it's called a "sausage" but it's really a lattice" )
( henrySimon_01327 "We'd form them into a lattice" )
( henrySimon_01328 "We'd have the candidates as usual from the database" )
( henrySimon_01329 "Here it's something called Line Spectral Pairs" )
( henrySimon_01330 "The target cost will be in this acoustic space" )
( henrySimon_01331 "Here's classical unit selection and a hybrid method would take the target sequence of units and replace it with predicted acoustic parameters and use those to go and match candidates from the database" )
( henrySimon_01332 "Finally, we'll come full circle to this thing called "hybrid synthesis" which is probably best described as unit selection driven by a statistical model" )
( henrySimon_01333 "When we think about how to annotate the database, we'll probably want to do that automatically because the database is probably going to be very large" )
( henrySimon_01334 "Because that will help us decide how to cover all of the permutations of features in the database" )
( henrySimon_01335 "When we come on to talk about the database, it will be important to fully understand our target cost: what features it requires, for example" )
( henrySimon_01336 "Nevertheless, it will still need the database to learn that model" )
( henrySimon_01337 "There'll be no concatenation of waveforms" )
( henrySimon_01338 "After we've built the database, we can then move on to a more powerful form of speech synthesis, which is to use a statistical parametric model that will generate the waveform entirely with a model" )
( henrySimon_01339 "And how do we annotate it? We need to know where all of (say) the diphones start and finish, and annotate each of them with their linguistic properties for use in either an IFF or an ASF type target cost" )
( henrySimon_01340 "But what exactly should we record?" )
( henrySimon_01341 "It's going to need to be from a single speaker for obvious reasons: we're going to concatenate small fragments of it" )
( henrySimon_01342 "It's got to have natural speech in it" )
( henrySimon_01343 "The final design choice - the thing that we're going to cover next - is what to put in our database" )
( henrySimon_01344 "We're no longer guaranteed to find the lowest-cost candidate sequence" )
( henrySimon_01345 "As in Automatic Speech Recognition, pruning is an approximation" )
( henrySimon_01346 "Those that are worse than that path in other words have a cost greater than it by some margin - called the beam - are discarded" )
( henrySimon_01347 "During the dynamic programming, as paths explore this grid, we'll just apply beam search (just as in Automatic Speech Recognition), comparing all of the paths at any moment in time during the search to the current best path" )
( henrySimon_01348 "The two most common would be: firstly, to limit the number of candidates for any target position - so that will be based only on target cost, it will be computed locally and we just keep a few hundred candidates perhaps for each position (the ones with the lowest target cost); the second most common form of pruning is during the search" )
( henrySimon_01349 "There are many forms of pruning" )
( henrySimon_01350 "It's therefore normal to do some pruning, just as in Automatic Speech Recognition" )
( henrySimon_01351 "It's too large and the system will be too slow" )
( henrySimon_01352 "With such long candidate lists, the number of paths through the lattice becomes unmanageable" )
( henrySimon_01353 "There might be hundreds or thousands of common diphones" )
( henrySimon_01354 "We could implement it in any way we like: for example, Token Passing" )
( henrySimon_01355 "It can be formulated on a lattice to make it look like this picture here" )
( henrySimon_01356 "It can be done very efficiently" )
( henrySimon_01357 "The search is straightforward dynamic programming" )
( henrySimon_01358 "We're not going to deviate very much from the original natural units: that would degrade quality and also it will get us further away from this implicit or explicit prediction that we got from the unit selection process" )
( henrySimon_01359 "For example, to manipulate F0 in the locality of a join to make it more continuous" )
( henrySimon_01360 "We didn't say anything about any further signal processing, but in many systems (although not in Festival) a little bit of further signal processing is done" )
( henrySimon_01361 "Or a duration model that tells us what duration candidates to prefer" )
( henrySimon_01362 "So we might have a prosody model that's "sketching out" an F0 contour that we'd like to try and meet" )
( henrySimon_01363 "But almost always we'll have some acoustic prediction in there" )
( henrySimon_01364 "Better just to get units from the right context in the database" )
( henrySimon_01365 "Those things aren't all easy to predict" )
( henrySimon_01366 "For example, features like phrase-final are really good at getting all of the different acoustic properties that correlate with phrase finality: lengthening, F0 falling, voice quality changes such as creakiness" )
( henrySimon_01367 "But most common of all probably is to do both of those things: to use features, because we have them from the front end - they're good in some situations" )
( henrySimon_01368 "You've then got to decide which acoustic properties (which acoustic features) to predict so that that comparison is meaningful and will find you the right candidates" )
( henrySimon_01369 "Or we could use a purely Acoustic Space Formulation, doing sufficient partial synthesis so that we only make comparisons in acoustic properties" )
( henrySimon_01370 "It's just got a couple of little bits of acoustic information in there" )
( henrySimon_01371 "Festival is almost a pure Independent Feature Formulation style target cost" )
( henrySimon_01372 "You need to choose what kind of target cost you going to use" )
( henrySimon_01373 "It doesn't matter to the search" )
( henrySimon_01374 "On others the join cost function will compute the cost" )
( henrySimon_01375 "On some of those paths would be zero join costs" )
( henrySimon_01376 "joining everything together" )
( henrySimon_01377 "The lattice will be formed as usual, with all the paths" )
( henrySimon_01378 "For example, maybe these units were contiguous, and we'll just write zero join cost between them" )
( henrySimon_01379 "You just need to remember which candidates were contiguous in the database and define their join cost to be zero, and not have them calculated by the join cost function" )
( henrySimon_01380 "That's really easy to implement" )
( henrySimon_01381 "Those might be actually much larger units" )
( henrySimon_01382 "In either case - but especially the half-phone case - the "zero join cost trick" is very important to effectively get larger units" )
( henrySimon_01383 "Far more commonly, we'll find systems using diphones or half-phones" )
( henrySimon_01384 "The first choice is: what kind of unit you're going to use" )
( henrySimon_01385 "I'm going to conclude that discussion of unit selection speech synthesis, including the different forms that the target cost function could take, with a summary of the different design choices that you have when you're going to build a new system" )
( henrySimon_01386 "So, many real systems use some combination of these two things: a target cost function that combines linguistic features and acoustic properties as well" )
( henrySimon_01387 "The Acoustic Space Formulation gets us over some of the sparsity problems, but we run into problems of accuracy of predicting acoustic properties" )
( henrySimon_01388 "But is suffering from extreme sparsity problems" )
( henrySimon_01389 "To summarize: the Independent Feature Formulation uses rather more robust, perhaps slightly less error-prone features from the front-end" )
( henrySimon_01390 "So everything has errors and we need to take that into account" )
( henrySimon_01391 "The more detailed those predictions, the harder the task is in fact, so the greater the error" )
( henrySimon_01392 "Even the linguistic features from the front-end will occasionally be wrong" )
( henrySimon_01393 "Finally, of course, we should always remember that all of these features have errors in" )
( henrySimon_01394 "We'd probably use them alongside acoustic properties as well" )
( henrySimon_01395 "So, using features still has a place" )
( henrySimon_01396 "We'd probably be a lot better off using linguistic features, such as "Is it phrase final?" and pulling candidates that are phrase final and would automatically have creaky voice where appropriate" )
( henrySimon_01397 "It will be very difficult to go all the way to a full prediction of that and then go find candidates with that property" )
( henrySimon_01398 "And things aren't easily captured even by the spectral envelope, such as for example creaky voice" )
( henrySimon_01399 "For example, things happen phrase-finally other than changes in F0 and duration and amplitude" )
( henrySimon_01400 "However, we don't know how to predict every single acoustic property" )
( henrySimon_01401 "The Independent Feature Formulation inherently suffers from extreme sparsity and so predicting some acoustic features can escape some of those sparsity problems inherent in that formulation" )
( henrySimon_01402 "It's going to be even more difficult to set the weights than in the Independent Feature Formulation case, but we'd have to do it somehow" )
( henrySimon_01403 "There's absolutely no problem then to build a mixed-style target cost function where we have a whole set of sub-costs; some of them using linguistic features, some using acoustic features, and we have to set weights" )
( henrySimon_01404 "We could sum up the differences in linguistic features plus the absolute difference in F0 plus the absolute difference in duration," )
( henrySimon_01405 "There's no problem with that" )
( henrySimon_01406 "We could have both sorts of features in a single target cost function" )
( henrySimon_01407 "Of course, we don't need to have that artificial separation" )
( henrySimon_01408 "We have initially made a hard distinction between two different sorts of target cost function: the Independent Feature Formulation, strictly based on linguistic features; the Acoustic Space Formulation, strictly based on comparing acoustic properties" )
( henrySimon_01409 "We call that a "hybrid method"" )
( henrySimon_01410 "When we fully understood statistical parametric synthesis - which will use models such as trees or neural networks - we can then come full circle and use that same statistical model to drive the target cost function and therefore to do unit selection" )
( henrySimon_01411 "That's coming later in the course" )
( henrySimon_01412 "We're actually going to stop talking now about Acoustic Space Formulation, because we're getting very close to statistical parametric synthesis" )
( henrySimon_01413 "That would work fine as well, or any other statistical model that can perform regression" )
( henrySimon_01414 "It's not the greatest model in the world, but it's one we know how to use" )
( henrySimon_01415 "We'll write the values in here and these would be the predicted values for things with appropriate linguistic features" )
( henrySimon_01416 "For example, the leaves of this tree might have actual values for F0" )
( henrySimon_01417 "We'll run it in regression mode, because we're going to predict continuously-valued things" )
( henrySimon_01418 "Here one you know about: the fantastic Classification And Regression Tree" )
( henrySimon_01419 "So you just need to pick your favourite regression model" )
( henrySimon_01420 "anything that you like" )
( henrySimon_01421 "We have a thing we're trying to predict: it could be F0, duration, energy, MFCCs," )
( henrySimon_01422 "Well it's a regression problem! We've got inputs: the linguistic features that we already have from the front-end for our targets" )
( henrySimon_01423 "How would we do that?" )
( henrySimon_01424 "But we've got better at that" )
( henrySimon_01425 "Indeed that's why the earlier systems had the Independent Feature Formulation, because we didn't have sufficiently powerful statistical models or good enough data to build accurate predictors of anything else" )
( henrySimon_01426 "If we don't think we can accurately predict them, we're better off with the Independent Feature Formulation" )
( henrySimon_01427 "So all of this is only going to work if we can rather accurately predict these properties" )
( henrySimon_01428 "It's getting harder and harder to predict those things" )
( henrySimon_01429 "The more detailed the predictions need to be - for example the full spectral envelope - the less certain we are that they're correct" )
( henrySimon_01430 "However, these are all predicted values and the predictions will have errors" )
( henrySimon_01431 "That's true in principle" )
( henrySimon_01432 "It would seem that the more and more detail that we can predict, the better, because we can make more accurate comparisons to the candidates" )
( henrySimon_01433 "Typically we're going to encode the envelope in some compact way that makes it easy to compare to the candidates" )
( henrySimon_01434 "We could predict some much more detailed specification: maybe even the full spectral envelope" )
( henrySimon_01435 "It would produce values for these things which you could compare to the true acoustic values of the candidates" )
( henrySimon_01436 "We'd have to build it, train it, put it inside the front-end, run it at synthesis time" )
( henrySimon_01437 "So: we'd need a predictive model of prosody" )
( henrySimon_01438 "In other words, have a model of prosody that predicts values of F0" )
( henrySimon_01439 "Now, what acoustic features are we going to try and add to our targets?" )
( henrySimon_01440 "We would compare these things, and we could do that for any acoustic properties we liked" )
( henrySimon_01441 "Let's just think of one: let's imagine adding a value for F0 to all of the target units" )
( henrySimon_01442 "We're going to give them some acoustic properties" )
( henrySimon_01443 "What we're going to do now: we're going to try and move target units closer to the space in which the candidates live" )
( henrySimon_01444 "The targets are abstract linguistic specifications only, with no acoustics" )
( henrySimon_01445 "We can measure duration; we could estimate F0; we could look at the spectral envelope or formants if we wanted" )
( henrySimon_01446 "We have waveforms from which we could estimate any acoustic properties" )
( henrySimon_01447 "These candidates here are fully-specified acoustic recordings of speech" )
( henrySimon_01448 "Again, just for the purpose of explanation, our units are phone-sized" )
( henrySimon_01449 "Back to this diagram again" )
( henrySimon_01450 "Let's try to make this clearer with a picture" )
( henrySimon_01451 "So we really don't need a waveform and neither do we need to predict every acoustic property" )
( henrySimon_01452 "We're only going to use them to choose candidates" )
( henrySimon_01453 "We don't necessarily need to predict a speech waveform because we're not going to play back these predicted acoustic properties" )
( henrySimon_01454 "Now, for our target units to move closer to the candidates (which are acoustic things) we need to predict some acoustic properties for the targets" )
( henrySimon_01455 "It's that interchangeability that's the foundation of unit selection: that's what we're trying to discover" )
( henrySimon_01456 "They're apparently linguistically different, but they are acoustically interchangeable" )
( henrySimon_01457 "The point is that in acoustic space things might be close together, but in linguistic space they're far apart" )
( henrySimon_01458 "It doesn't really matter" )
( henrySimon_01459 "It might be that this one's duration and this is some other acoustic property" )
( henrySimon_01460 "c1 and c2 could be any dimensions of acoustic space that you want" )
( henrySimon_01461 "It's probably deliberate because he's trying to say this is an abstract acoustic space" )
( henrySimon_01462 "Because, in linguistic feature space, we won't be able to detect that they would have sounded similar" )
( henrySimon_01463 "But the only way to discover that is actually to go into acoustic space and measure the distance in acoustic space: measure this distance between these two things" )
( henrySimon_01464 "But if it's the case that [stress -] and [phrase-finality +] happens to sound very similar to [stress +] and [phrase-finality -] then we shouldn't consider these two things here are far apart at all" )
( henrySimon_01465 "These other possible candidates would appear to be closer in linguistic feature space" )
( henrySimon_01466 "It would incur a high target cost: it mismatches twice (both features)" )
( henrySimon_01467 "It could be the case that we are looking for a target that has this linguistic specification and - using the Independent Feature Formulation - this potential candidate here would be very far away" )
( henrySimon_01468 "There is some ideal acoustic property of each target and so the same situation could hold" )
( henrySimon_01469 "We're trying to predict the acoustic properties" )
( henrySimon_01470 "At synthesis time our target units do not have acoustic properties because they're just abstract linguistic structures" )
( henrySimon_01471 "To fully understand the implications of this, we need to also think about the target units" )
( henrySimon_01472 "It's possible that two things that have different linguistic specifications but sound very similar" )
( henrySimon_01473 "The axes of this space are acoustic properties, and these two units lie very close to each other in acoustic space" )
( henrySimon_01474 ") Yet it's possible that they sound very similar" )
( henrySimon_01475 "(We're just considering those two dimensions in this picture" )
( henrySimon_01476 "These are maximally-different linguistic features: they mismatch in both stress and phrase finality" )
( henrySimon_01477 "What Taylor is saying with this diagram is that it's possible that there are two different speech units that have very different linguistic features: this one and this one" )
( henrySimon_01478 "For now, let's just think about candidates that have both linguistic specifications and actual acoustic properties" )
( henrySimon_01479 "Let's see if we can understand what's going on in this diagram" )
( henrySimon_01480 "Taylor tries to summarize this situation in this one diagram" )
( henrySimon_01481 "That's going to involve making a prediction of the acoustic properties of the target" )
( henrySimon_01482 "We want to compare how a candidate actually sounds (because we have its waveform) with how we think - or how we predict - a target should sound" )
( henrySimon_01483 "What we need to do is to compare how the units sound" )
( henrySimon_01484 "It's very hard to detect which combinations of features lead to the same sound" )
( henrySimon_01485 "It's very hard to get round that when we're only looking at these linguistic features" )
( henrySimon_01486 "It could sound very similar to the ideal target" )
( henrySimon_01487 "Yet, the candidate could be ideal for that position" )
( henrySimon_01488 "The target and the candidate may have differing (in other words, mismatched) linguistic features" )
( henrySimon_01489 "We could summarize this weakness by thinking about a single candidate for a particular target position" )
( henrySimon_01490 "That's computationally efficient, but it creates an artificial form of sparsity" )
( henrySimon_01491 "That compares only linguistic features: symbolic things produced by the front-end" )
( henrySimon_01492 "The motivation for that is the weakness of the Independent Feature Formulation" )
( henrySimon_01493 "We compute join costs and perform a search" )
( henrySimon_01494 "The weights are the penalties for each mismatched linguistic feature" )
( henrySimon_01495 "It's just a weighted sum" )
( henrySimon_01496 "So far, we understand the Independent Feature Formulation style of target cost" )
( henrySimon_01497 "For each candidate, we compute a target cost" )
( henrySimon_01498 "We just go for an exact match on the base unit type and we hope for variety in all of the other linguistic features" )
( henrySimon_01499 "For each target unit, we retrieve all possible candidates from the database" )
( henrySimon_01500 "From the linguistic specification, we construct a target sequence, essentially flattening down the specification on to the individual targets" )
( henrySimon_01501 "So we run that text processor" )
( henrySimon_01502 "I think this is a good time to orient ourselves again, to check that we understand where we are in the bigger picture of unit selection" )
( henrySimon_01503 "That might help was improve the system in a way that's rather opaque in the Independent Feature Formulation" )
( henrySimon_01504 "But also we can then observe those acoustic predictions: measure their accuracy in an objective sense" )
( henrySimon_01505 "That's the Acoustic Space Formulation" )
( henrySimon_01506 "Something that does make some acoustic predictions - explicit predictions of actual acoustic properties - and then measures the difference between target and candidate in that acoustic space" )
( henrySimon_01507 "So, what we're going to move on to now is we're going to look at a different formulation of the target cost function" )
( henrySimon_01508 "All we can do is indirectly control that by, for example, changing the weights in the target cost" )
( henrySimon_01509 "We can't really see how it's making this acoustic prediction" )
( henrySimon_01510 "There's also a weakness: we can't really inspect the system" )
( henrySimon_01511 "We don't need to make explicit acoustic predictions, so we don't need complicated models for that, that will make mistakes" )
( henrySimon_01512 "There's an advantage to being completely implicit" )
( henrySimon_01513 "However, it's completely implicit" )
( henrySimon_01514 "It's a complicated sort of regression from the linguistic specification to a speech waveform" )
( henrySimon_01515 "Taken as a whole, the database, the target cost function, the search for the best candidate sequence: that whole complex system is making acoustic predictions" )
( henrySimon_01516 "Whilst the cost function itself only deals with symbolic features, the output of the system is synthetic speech and that of course has acoustic properties" )
( henrySimon_01517 "It's just implicit in the procedure" )
( henrySimon_01518 "But thinking about the system as a whole, of course we are making predictions about the acoustics, because we're generating synthetic speech" )
( henrySimon_01519 "It simply gets the candidates, and whatever acoustic properties they have, that's what the synthetic speech has" )
( henrySimon_01520 "I just stated that an Independent Feature Formulation makes no attempt to make any acoustic predictions whatsoever about the target" )
( henrySimon_01521 "It would have to have its own weight" )
( henrySimon_01522 "Optionally - and I say optionally because predicting prosody even symbolically is very error-prone - optionally, we could attempt to predict prosody and then use that as part of the cost function as just another linguistic feature" )
( henrySimon_01523 "That will get us prosody" )
( henrySimon_01524 "An awful lot of that rests simply on position-within-prosodic-constituents: where the syllable is within the word, within the phrase," )
( henrySimon_01525 "Therefore, all we really need to do to get prosody is to make sure that the linguistic features from our front end capture sufficient contextual information relevant to prosody" )
( henrySimon_01526 "We'll get prosody simply by choosing candidates essentially from the right position in the prosodic phrase" )
( henrySimon_01527 "That's the same principle that we use to get the correct phonetic co-articulation or the correct syllable stress" )
( henrySimon_01528 "But what if we don't have that? What if we don't explicitly mark up prosody even symbolically on either the target or the candidates in the database?" )
( henrySimon_01529 "Of course, we'll have to annotate the database with the same features" )
( henrySimon_01530 "Those can be taken into account when selecting candidates from the database" )
( henrySimon_01531 "So, if the front-end can predict them with sufficient accuracy - for example we might attempt to predict ToBI accents and boundary tones - we will have these symbolic features that capture prosody" )
( henrySimon_01532 "The symbolic features could optionally include symbolic prosodic features" )
( henrySimon_01533 "Now, we didn't make any acoustic predictions at all in computing this target cost" )
( henrySimon_01534 "It's almost a pure Independent Feature Formulation target cost function in Festival" )
( henrySimon_01535 "This is pretty much what Festival does" )
( henrySimon_01536 "Nevertheless, it will work" )
( henrySimon_01537 "That's good! It makes some dramatic simplifications though" )
( henrySimon_01538 "So this target cost function will be fast" )
( henrySimon_01539 "Of course a weighted sum of mismatches is very cheap to compute" )
( henrySimon_01540 "So computation of this is going to be cheap" )
( henrySimon_01541 "So we're just deriving simple symbolic features from - in Festival's case - the existing utterance structure, or more generally the linguistic specification" )
( henrySimon_01542 "Those are calculations we had to do to disambiguate pronunciation (for example)" )
( henrySimon_01543 "We've already had to do all of that front-end processing, so those features are things we already have: they come "for free"" )
( henrySimon_01544 "That's super-convenient and is also going to be computationally quick" )
( henrySimon_01545 "So, that's pretty much all there is to the Independent Feature Formulation" )
( henrySimon_01546 "This function is unable to do that" )
( henrySimon_01547 "However, this still incurred the maximum penalty of 4 here" )
( henrySimon_01548 "So we might prefer to take candidates from [v] left-phonetic-contexts than radically different ones, like a liquid" )
( henrySimon_01549 "Candidate 2 came from a left-phonetic-context of [v]" )
( henrySimon_01550 "So there's no distance: things are either exactly the same (incurring zero penalty) or different (incurring the maximum penalty: the weight in that column)" )
( henrySimon_01551 "There's no concept of a "near match"" )
( henrySimon_01552 "The other oversimplification of this function is that things strictly match or mismatch: it's a binary distinction" )
( henrySimon_01553 "For example, there might be interactions between the stress status of a syllable and whether it's phrase final or not" )
( henrySimon_01554 "One thing that it fails to consider is combinations of features" )
( henrySimon_01555 "The target cost function doesn't consider two rather important things" )
( henrySimon_01556 "It's a bit too simplistic - it's too naive - and the simplicity is because we've treated the features as independent for the purposes of calculating the target cost" )
( henrySimon_01557 "If we return to this example that we just worked through, we can see that there's a problem with the Independent Feature Formulation type of target cost" )
( henrySimon_01558 "In fact, it's a bit too simple" )
( henrySimon_01559 "An Independent Feature Formulation target cost is really rather simple" )
( henrySimon_01560 "We just calculate the target cost as two sub-costs: the left and right halves, and then add those together" )
( henrySimon_01561 "The left half of the diphone might be in a different Part Of Speech to the right half" )
( henrySimon_01562 "That's because some features might actually differ going through the diphone: it might cross (for example) a syllable or word boundary" )
( henrySimon_01563 "Now the calculation of target cost for diphones is just a little bit messier because we do it separately for the left and the right halves" )
( henrySimon_01564 "Then we can look at other features around them" )
( henrySimon_01565 "We can see that we're always matching on the base unit type: that's always an exact match; that's how we retrieve the candidates, just by looking at that" )
( henrySimon_01566 "For each of those utterances (these are in the database) they've got natural recorded speech plus a complete linguistic specification" )
( henrySimon_01567 "We know the recorded utterances that each of those candidates came from: "They saw each other for the first time in Boston" So the top candidate there came from that utterance" )
( henrySimon_01568 "We have two available candidates" )
( henrySimon_01569 "Let's again focus in on one particular target position: we'd like to say this diphone" )
( henrySimon_01570 "In the Independent Feature Formulation, it's only the linguistic specification that we're going to use for comparison" )
( henrySimon_01571 "Each of these candidates has a waveform, and of course also has a linguistic specification" )
( henrySimon_01572 "So that's now my target sequence, and I'm going to go and retrieve diphone candidates from the database" )
( henrySimon_01573 "In diphone units, I'll run the front end in the same way" )
( henrySimon_01574 "Those costs (those target costs) just go into the lattice and become part of the total cost of all the different paths passing through each of these candidates" )
( henrySimon_01575 "Now remember, we don't simply use these two values to choose between these two candidates, because we don't yet know how their waveforms will concatenate with the candidates left and right of them in the lattice" )
( henrySimon_01576 "Separately for candidate 2: that stress mismatch incurs a penalty of 10, the Part Of Speech mismatch costs 6, and the left-phonetic-context mismatch costs 4, giving us a total of 20" )
( henrySimon_01577 "The syllable position mismatch incurs a penalty of 5 and the right-phonetic-context mismatch incurs a penalty of 3, giving us a total of 8" )
( henrySimon_01578 "Candidate 1 has two mismatches, but we need to do a weighted sum to take into account the relative importance of those mismatches" )
( henrySimon_01579 "I will do the same for candidate 2 separately: stress mismatches, syllable position matches, word position matches, Part Of Speech mismatches, phrase position matches, left-phonetic-context mismatches, right-phonetic-context matches" )
( henrySimon_01580 "For candidate 1: stress matches, syllable position mismatches, word position matches, Part Of Speech matches, phrase position matches, left-context matches, but right-phonetic-context mismatches" )
( henrySimon_01581 "Let's do candidate 1 first" )
( henrySimon_01582 "It's just a simple process of deciding if there's a mismatch and noting that" )
( henrySimon_01583 "I've got two competing candidates, each with their linguistic specifications" )
( henrySimon_01584 "That's its linguistic specification" )
( henrySimon_01585 "I'm going to consider a single target position in the sentence I'd like to say" )
( henrySimon_01586 "So here they are, and their weights" )
( henrySimon_01587 "Let's just take the main features that are produced by the front end and forget these special values that Festival uses to detect problems in the database" )
( henrySimon_01588 "Those are the ones produced by the front end and those are the ones used to choose between competing candidates from different linguistic contexts" )
( henrySimon_01589 "Concentrate on these features: phonetic context and the prosodic context" )
( henrySimon_01590 "Don't worry about these for now" )
( henrySimon_01591 "They're to do with the automatic labelling of the database, in fact" )
( henrySimon_01592 "They're there to detect problems with the database" )
( henrySimon_01593 "Festival has a couple of special things in its target cost that aren't really part of the target cost itself: it's just a convenient way of implementing something" )
( henrySimon_01594 "But currently that's the best method for picking those weights" )
( henrySimon_01595 "That's quite hard to do; that's obviously a very skilled thing" )
( henrySimon_01596 "Well they're set by hand, by listening to a lot of synthetic speech and tuning the weights" )
( henrySimon_01597 "Where do these weights come from?" )
( henrySimon_01598 "That's capturing our knowledge of co-articulation: that left context has a stronger effect on the current sound than the right context" )
( henrySimon_01599 "We can see, for example, that a mismatch in left-phonetic-context incurs a slightly higher penalty than a mismatch in right-phonetic-context" )
( henrySimon_01600 "So, for example, in Festival's multisyn unit selection module, these are the weights" )
( henrySimon_01601 "The only way of weighting one against the other is to put these weights as we sum up those mismatches" )
( henrySimon_01602 "The simplest form of the Independent Feature Formulation target cost considers all the features - it considers them to be independent - and it just sums up the number of mismatches" )
( henrySimon_01603 "So, we need to capture that difference in importance between the different features" )
( henrySimon_01604 "We should know enough phonetics to know that some linguistic contexts have a bigger effect on sound - and more importantly on perception of that sound - than others" )
( henrySimon_01605 "So: left-phonetic-context mismatches, right-phonetic-context matches" )
( henrySimon_01606 "We know that this candidate came from before a [k] and we also know that target comes before a [k]: that's a match" )
( henrySimon_01607 "And of course we know the phonetic context: this candidate came after a silence however for the target position we want something that's after "the": there's a mismatch" )
( henrySimon_01608 "We also know that the target position is word-final" )
( henrySimon_01609 "We know that it was word-final - there's a word boundary here" )
( henrySimon_01610 "For example, imagine that the candidate that we're considering here (we're measuring the target cost for) actually occurred in the natural sentence "A car" )
( henrySimon_01611 "anything that our front-end text processor can generate for us at synthesis time" )
( henrySimon_01612 "That context is described as a set of separate linguistic features: phonetic context, perhaps stress, position-in-syllable, position-in-word, position-in-phrase," )
( henrySimon_01613 "It's not this context necessarily, it's the context of the natural sentence it came from" )
( henrySimon_01614 "We know the phonetic context which it was extracted from in its source sentence" )
( henrySimon_01615 "For this candidate, we also know the same things" )
( henrySimon_01616 "So we know the context in which this appears - it's actually this left and right phonetic context - although remember it can be attached locally, because this sequence is constant" )
( henrySimon_01617 "That's going to include things like their phonetic context" )
( henrySimon_01618 "We'll make a direct comparison between the two in terms of their linguistic specification" )
( henrySimon_01619 "Let's focus in on one particular target position, one particular candidate that we're considering for that target" )
( henrySimon_01620 "So, let's make that completely clear" )
( henrySimon_01621 "We can just make a direct comparison between them" )
( henrySimon_01622 "So, we know the same things for every target and for every candidate" )
( henrySimon_01623 "For every candidate that we are considering for that target position, we also know the same linguistic specification" )
( henrySimon_01624 "For every target, the front end text processor has provided us with a linguistic specification" )
( henrySimon_01625 "The advantage of this Independent Feature Formulation type of target cost function is that it works with things we already know" )
( henrySimon_01626 "Always remember that the target cost function (like the join cost function) is computing a cost, and that cost is only a prediction of how bad this candidate might sound if we were to use it in this target position" )
( henrySimon_01627 "If the mismatch is in terms of linguistic features, we can just sum up the individual mismatches" )
( henrySimon_01628 "The more mismatched the context is between the candidate and target, the higher the cost" )
( henrySimon_01629 "Those exactly-matching candidates will have a cost of zero: there'll be no mismatch (a sum of zeros)" )
( henrySimon_01630 "Ideally - although it doesn't happen very often - we would like to find exactly-matching candidates" )
( henrySimon_01631 "It's a simple count of how many don't match" )
( henrySimon_01632 "The features will be the same because they'll be produced in the same way" )
( henrySimon_01633 "So we know the same things for the target and for each of the candidates" )
( henrySimon_01634 "That's true in both the target sequence and for each individual candidate, because the candidates came from real recorded sentences, where we also knew the full linguistic specification" )
( henrySimon_01635 "Each of them has a specification attached to it, so it knows the context in which it appears" )
( henrySimon_01636 "So, what we're dealing with then is a sequence of pronunciation units: phonemes, or maybe diphones" )
( henrySimon_01637 "We've already described how we can essentially flatten those on to the segment (on to the pronunciation level)" )
( henrySimon_01638 "What we already have, of course, is the linguistic specification of the targets, and that comprises a set of linguistic features" )
( henrySimon_01639 "We can call it simple because it's going to use things we already have from our front end" )
( henrySimon_01640 "We'll start with measuring that mismatch in the simplest possible way" )
( henrySimon_01641 "We need to decide how that mismatch could be measured" )
( henrySimon_01642 "So let's get into those details about the target cost: It's measuring mismatch between a target and a candidate for that target position" )
( henrySimon_01643 "We've already talked about that" )
( henrySimon_01644 "Therefore, to minimize the total cost, we need to conduct a search" )
( henrySimon_01645 "Because of the join cost, the selection of one candidate depends on the preceding and following candidates, all the way to the ends of the utterance" )
( henrySimon_01646 "The selection of candidates is based on two costs: a target cost function, which we're going to talk a lot more about now, and a join cost function, which calculates the mismatch across concatenation points (across the joins)" )
( henrySimon_01647 "We haven't said much about that yet, because it's going to come later" )
( henrySimon_01648 "Obviously, that speech is going to have to be annotated so we can find those units" )
( henrySimon_01649 "You need to know that unit selection is basically about selecting waveform fragments from a database of pre-recorded natural speech" )
( henrySimon_01650 "Before carrying on, make sure that you understand the general principles of unit selection from the previous videos" )
( henrySimon_01651 "A mismatch in one feature doesn't interact with mismatches in other features" )
( henrySimon_01652 "What he's saying is that - in the target cost computation - the features are all considered independently" )
( henrySimon_01653 "When Taylor says Independent Feature Formulation, he doesn't mean that the linguistic features are completely independent of each other in a statistical sense" )
( henrySimon_01654 "That's to calculate the cost as a weighted sum of mismatches in linguistic features" )
( henrySimon_01655 "We're going to first look at the simplest way we could configure the target cost function" )
( henrySimon_01656 "We're going to use Taylor's terminology here, to be consistent with his book" )
( henrySimon_01657 "The first thing we're going to look at is the target cost function" )
( henrySimon_01658 "Now we've got a complete picture of how unit selection works, we can start to look in more detail at some of the most important components" )
( henrySimon_01659 "We'll see that we want coverage" )
( henrySimon_01660 "We'll look at how to design the ideal database" )
( henrySimon_01661 "But, what sentences? What's the ideal database?" )
( henrySimon_01662 "We think it's probably got natural speech: probably someone reading out whole sentences" )
( henrySimon_01663 "At the moment we just know there is a database" )
( henrySimon_01664 "After we've completed our look at the target cost, we'd better decide what's going in our database" )
( henrySimon_01665 "When we talk about the Acoustic Space Formulation we'll once again point forward to statistical models and then eventually to hybrid systems" )
( henrySimon_01666 "And mixing those two things together, which is what actually happens in many real systems" )
( henrySimon_01667 "We're going to look in a lot more detail about these two different formulations: the Independent Feature Formulation and the Acoustic Space Formulation" )
( henrySimon_01668 "The target cost is so important, it's covered in its own section of the course and that's coming next" )
( henrySimon_01669 "But we didn't say exactly how those two things would be done" )
( henrySimon_01670 "We said that we could simply look at the mismatches in linguistic features, or that we could make some acoustic prediction about the target and then look at the mismatch in acoustic features" )
( henrySimon_01671 "We didn't say very much about the target cost" )
( henrySimon_01672 "We can make that join at the phone boundary fairly successfully" )
( henrySimon_01673 "Generally, it's not a good idea, but there are specific cases where joining at phone boundaries works pretty well" )
( henrySimon_01674 "A half phone system makes a lot of sense with this zero join cost trick, where we get effectively variable-sized units from half-phone to diphone to multi-diphone" )
( henrySimon_01675 "It can do what's called "backing off"" )
( henrySimon_01676 "Perhaps, because of about database design, there was a diphone missing" )
( henrySimon_01677 "We'd get a system that's effectively a diphone system that can fall back to half-phones where the diphones aren't suitable" )
( henrySimon_01678 "Another good idea would be to write out the problem in half-phones" )
( henrySimon_01679 "We'll finish with a final reminder that this picture should really be written with diphones but that would be a little messy and confusing to understand" )
( henrySimon_01680 "The search will decide" )
( henrySimon_01681 "Maybe it's got a lower total cost than the other path" )
( henrySimon_01682 "This path takes advantage of some of those "free" or zero-cost joins" )
( henrySimon_01683 "Maybe this path" )
( henrySimon_01684 "There might be better paths through this lattice that don't concatenate exactly those whole words" )
( henrySimon_01685 "It doesn't matter; we don't need to make a hard decision" )
( henrySimon_01686 "So that might not be the best path through this lattice" )
( henrySimon_01687 "But it might be the case that the joins between them are very unnatural" )
( henrySimon_01688 "Those individual words are going to sound perfect because they're just recordings of whole words from the database" )
( henrySimon_01689 "There it is" )
( henrySimon_01690 "For example there's a path here that essentially concatenates whole words" )
( henrySimon_01691 "But, it's not forced to do that, because it might not always be the best path" )
( henrySimon_01692 "When we search this lattice, the search is going to find (in general) lower cost paths, if it can join up more of these red lines, because they have zero join cost" )
( henrySimon_01693 "We just remember that, if we make a path that passes through all three of them, it incurs no join cost" )
( henrySimon_01694 "So we put that into the lattice, but we put it in as the three separate units" )
( henrySimon_01695 "So, for example in this particular database it looks like the word cat occurred in its entirety" )
( henrySimon_01696 "That's to just simply record these contiguous units and define the join cost as 0 between them and not calculate it" )
( henrySimon_01697 "There's one little trick that's very common (it's pretty much universal in unit selection systems) to take a system that's essentially homogeneous and get magically larger units out of it" )
( henrySimon_01698 "We write down the individual constituent units of those larger units, but we note that they were consecutive in the database: that they were spoken contiguously together as a single unit" )
( henrySimon_01699 "This picture could simply be redrawn as follows" )
( henrySimon_01700 "Of course, in a real system we'd have multi-diphone units made of single diphones" )
( henrySimon_01701 "We can do that simply by realizing that each of these multi-phone units is made of several single phone units" )
( henrySimon_01702 "At the same time, it can make shorter units out of longer units where that's preferable" )
( henrySimon_01703 "Fortunately there's a very easy way to build a system that effectively has longer and longer units in it, where they're available in the database, but automatically falls back to shorter units" )
( henrySimon_01704 "They're a little bit messy to code, and you have to be a little bit careful about normalizing the costs of each path, so that they could be compared with each other" )
( henrySimon_01705 "I've built ones like that with half-syllables and diphones and things, all mixed together" )
( henrySimon_01706 "You could build systems like that" )
( henrySimon_01707 "When I say lattice, I'm referring to the fact that there are paths that can go through these units, like this, and so forth" )
( henrySimon_01708 "Here's a lattice of candidates that has these heterogeneous unit types" )
( henrySimon_01709 "We could potentially reduce the number of concatenation points (the number of joins) by trying to find longer units where they're available, and kind of "filling in the gaps" with smaller units when they're not available" )
( henrySimon_01710 "The number of joins is the same for any path through this lattice" )
( henrySimon_01711 "When I say size, I mean size of linguistic unit, so, a half-syllable or a syllable" )
( henrySimon_01712 "It could be any unit you like, but they must all be of the same approximate size" )
( henrySimon_01713 "They could be diphones" )
( henrySimon_01714 "Here they're whole phones" )
( henrySimon_01715 "All the units are of the same type" )
( henrySimon_01716 "Here's a homogeneous system" )
( henrySimon_01717 "Let's see that in pictures because it's going to be easier to understand" )
( henrySimon_01718 "The lattice is going to look a bit messy in that case, but we could still implement it and still build such a system" )
( henrySimon_01719 "It might use whole words, if we happen to have the word in the inventory, and then syllables to make up words we don't have, and then diphones to make up syllables that we don't have" )
( henrySimon_01720 "A more complicated system might use units of different types" )
( henrySimon_01721 "The lattice will look very much like the pictures we've drawn so far, but the unit type might change" )
( henrySimon_01722 "One is where all of the units are of the same type - they're all diphones, or they're all syllables - so they're all the same: they're homogeneous" )
( henrySimon_01723 "There are two sorts of system we could imagine building" )
( henrySimon_01724 "Generally we're going to get higher quality" )
( henrySimon_01725 "That will work extremely well: bigger units = fewer joins" )
( henrySimon_01726 "That's a great idea" )
( henrySimon_01727 "For example, instead of diphones, we could use half-syllables or whole syllables, or some other bigger unit" )
( henrySimon_01728 "An obvious way is to make the units longer in duration: bigger units" )
( henrySimon_01729 "The joins are what our listener is most likely to notice" )
( henrySimon_01730 "That implies that there's a join between every pair of consecutive candidates" )
( henrySimon_01731 "To synthesize this target sequence, we pick one from each column of the candidates, and concatenate them" )
( henrySimon_01732 "To understand that, let's just go back to this diagram" )
( henrySimon_01733 "In either case, there still seems to be a fundamental problem with the way that we've described the situation" )
( henrySimon_01734 "But, we've been reminding ourselves all along that that's not really going to work very well" )
( henrySimon_01735 "In our rather simplified toy examples we've been pretending that those fragments are phones (whole phones: recordings of phonemes)" )
( henrySimon_01736 "As we've described it so far, unit selection concatenates small fragments of waveform" )
( henrySimon_01737 "We can see that the costs are local and that the shape of this graph allows us to do dynamic programming in a very simple way" )
( henrySimon_01738 "This diagram is a way of writing down the search problem" )
( henrySimon_01739 "This is the classic paper from Hunt & Black, where this formulation of unit selection was written down for the first time" )
( henrySimon_01740 "You'll see the idea written formally in the readings" )
( henrySimon_01741 "Or we could think of this as a lattice: we're passing tokens through the lattice, so it's something like a Hidden Markov Model" )
( henrySimon_01742 "That looks incredibly similar to dynamic time warping on the grid" )
( henrySimon_01743 "That's the dynamic programming step" )
( henrySimon_01744 "The past and the future are independent, given the present" )
( henrySimon_01745 "Because, if we've decided that we're choosing this unit, then all of the choices here are now independent from all the choices here" )
( henrySimon_01746 "We can state the same thing as we stated in dynamic time warping, or in Hidden Markov Model-based speech recognition: That the lowest cost path through this point must include the lowest cost path up to this point" )
( henrySimon_01747 "It has a concatenation cost and then the paths could head off in other directions: or it could go here, or here" )
( henrySimon_01748 "It's either preceded by that unit, that unit, that one, or that one" )
( henrySimon_01749 "This unit lies on several possible paths coming from the left" )
( henrySimon_01750 "Let's look at the middle part of the problem" )
( henrySimon_01751 "We'll start at the beginning, and we'll send paths forwards in parallel" )
( henrySimon_01752 "It doesn't matter: we could do right to left, but we'll do left to right" )
( henrySimon_01753 "To make the dynamic programming work, we're going to explore in this example from left to right" )
( henrySimon_01754 "Let's see where the dynamic programming step happens" )
( henrySimon_01755 "In fact we can break the problem right down and use dynamic programming to make this search just as efficient as if this was a Hidden Markov Model" )
( henrySimon_01756 "That idea generalizes to paths that have common suffixes, or common infixes" )
( henrySimon_01757 "We only have to compute the bit that's different - this point here" )
( henrySimon_01758 "Therefore, when we're computing the total cost of Path B, we can reuse the computations of Path A up to that point" )
( henrySimon_01759 "Up to the choice of this unit they're the same" )
( henrySimon_01760 "Path A and Path B be have a common prefix" )
( henrySimon_01761 "Consider these two paths" )
( henrySimon_01762 "Let's draw a couple of paths and see how dynamic programming could make that computation more efficient" )
( henrySimon_01763 "It works by breaking the problem into separate independent problems" )
( henrySimon_01764 "So, let's remind ourselves in general terms how the magic of dynamic programming works" )
( henrySimon_01765 "Now we're going to understand why it was so important that all of those costs (the target cost and the join cost) could be computed entirely locally, and therefore we can do dynamic programming" )
( henrySimon_01766 "The search is going to be required to find that sequence" )
( henrySimon_01767 "There's a definition of best path: it's simply the one with the lowest total cost, which is a sum of local costs" )
( henrySimon_01768 "We could have drawn that path going from right to left" )
( henrySimon_01769 "Everything is symmetrical" )
( henrySimon_01770 "The choice of unit in this position will have an effect on the choice of unit in this position, and vice versa" )
( henrySimon_01771 "So, through the join cost there's a kind of "domino effect"" )
( henrySimon_01772 "We should already understand that we can't make local choices, because the choice of one candidate depends on what we're concatenating it to" )
( henrySimon_01773 "The total cost of this sequence will be the target cost of this candidate measured with respect to this target - the mismatch between those two things - possibly that's a simple weighted sum of linguistic feature mismatches; plus the join cost between these two units; plus the target cost of this candidate with respect to its target; plus the concatenation (or join) cost to the next unit; and so on, summed across the entire sequence" )
( henrySimon_01774 "There's one path through this lattice of candidates" )
( henrySimon_01775 "Let's draw one candidate sequence and define what the cost of that sequence would be" )
( henrySimon_01776 "The total cost is just a sum of local costs" )
( henrySimon_01777 "For now, we've got relatively simple cost functions and we're going to define the best candidate sequence as the one that has the lowest total cost" )
( henrySimon_01778 "We'll come back to that much later in the course when we come full circle and look at hybrid methods" )
( henrySimon_01779 "Eventually, the best possible current solution to these cost functions is actually a complete statistical model" )
( henrySimon_01780 "There's always a possibility of trying to make our cost functions better" )
( henrySimon_01781 "Our cost functions are just predictions of perceived quality" )
( henrySimon_01782 "They're either based on linguistic features, or acoustic properties" )
( henrySimon_01783 "Of course, these cost functions are not perfect" )
( henrySimon_01784 "In other words, it should sound as close as possible to the target that we're trying to say, and sound the most natural" )
( henrySimon_01785 "By definition, because our cost functions are measuring perceptual mismatch (either the perceptual mismatch between a target and a possible candidate for that target, or the perceptual mismatch between a candidate and a consecutive candidate that we're considering concatenating it with) the lowest cost path should sound the best" )
( henrySimon_01786 "The ideas here are very similar to those in automatic speech recognition, so make sure you understand the basics of Hidden Markov Models and the Viterbi algorithm before you start on this part" )
( henrySimon_01787 "We'll wrap up at the very end, by saying how that search could be made even faster if we needed to do so" )
( henrySimon_01788 "We'll see that that search can be made very efficient indeed" )
( henrySimon_01789 "It's finding the lowest cost sequence of candidates" )
( henrySimon_01790 "We need to understand why a search is necessary at all: what the search is finding for us" )
( henrySimon_01791 "We can now wrap up the description of unit selection by looking at the search" )
( henrySimon_01792 "When we use a statistical model underlying our unit selection system we call that "hybrid synthesis"" )
( henrySimon_01793 "So we're going to defer that for later, once we've understood statistical models and how they can be used to synthesize speech themselves, we'll then come back to unit selection and see how that statistical model can help us compute the joint cost, and in fact also the target cost" )
( henrySimon_01794 "Now, eventually we are going to go there: we're going to have a statistical model that's going to do that for us, but we're not ready for that yet because we don't know about statistical models" )
( henrySimon_01795 "Or we could just generalize that much further and build some probabilistic model of what trajectories of natural speech parameters normally look like, compare that model's prediction to the concatenated diphones, and measure how natural they are under this model" )
( henrySimon_01796 "Maybe F0 has no discontinuity but in the left diphone it was increasing and in the right diphone it was decreasing" )
( henrySimon_01797 "We just took the last frame (maybe 20ms) of one diphone and the first frame (maybe the first 20ms) of the next diphone (the next candidate that we're considering concatenating) and we're just measuring the very local mismatch between those" )
( henrySimon_01798 "Its main limitation is it's extremely local" )
( henrySimon_01799 "It's going to work perfectly well, although it's a little bit simple" )
( henrySimon_01800 "That's a really simple join cost" )
( henrySimon_01801 "We're going to sum up those mismatches with some weights that express the relative importance of them, perceptually" )
( henrySimon_01802 "The energy is continuous here, so there's very low mismatch (so, low cost) in the energy" )
( henrySimon_01803 "the F0 is slightly discontinuous, so that's going to contribute something to the cost" )
( henrySimon_01804 "For example" )
( henrySimon_01805 "We're going to measure the mismatch in each of these properties" )
( henrySimon_01806 "We'd use a more generalized representation like the cepstrum" )
( henrySimon_01807 "More generally, we wouldn't use formants: they're rather hard to track automatically" )
( henrySimon_01808 "This picture is using formants to make things obvious" )
( henrySimon_01809 "We could parameterize that spectral envelope any way we like" )
( henrySimon_01810 "It's plotted here as a spectrogram" )
( henrySimon_01811 "In this example, we've extracted fundamental frequency, energy and the spectral envelope" )
( henrySimon_01812 "Because we have their waveforms, we can extract any acoustic properties that we like" )
( henrySimon_01813 "(Or, in our simple example, just whole phones) We have their waveforms, because these are candidates from the database" )
( henrySimon_01814 "We have a diphone on the left, and a diphone on the right" )
( henrySimon_01815 "Here's a graphical representation of what the join cost is doing" )
( henrySimon_01816 "So, very commonly, join costs will also include some rules which express phonetic knowledge about where the joins are best placed" )
( henrySimon_01817 "So we can quite easily splice those things together" )
( henrySimon_01818 "For example, making joins in unvoiced fricatives is fairly straightforward: the spectral envelope doesn't have much detail, and there's no pitch to have a mismatch in" )
( henrySimon_01819 "A simple way of expressing that is to say that they are much more likely to notice a join in some segment types than in other segment types" )
( henrySimon_01820 "We know that listeners are much more sensitive to some sorts of discontinuities than others" )
( henrySimon_01821 "It's also quite common to inject a little bit of phonetic knowledge into the join cost" )
( henrySimon_01822 "Since some might be more important than others, there'll be some weights" )
( henrySimon_01823 "That's to measure the mismatch in each of those three properties separately and then sum them together" )
( henrySimon_01824 "A typical way is the way that Festival's Multisyn unit selection engine works" )
( henrySimon_01825 "If we're going to use multiple acoustic properties in the join cost function, then we have to combine those mismatches in some way" )
( henrySimon_01826 "The assumption is that measuring acoustic mismatch is a prediction of the perceived discontinuity that a listener will experience when listening to this speech" )
( henrySimon_01827 "Our join cost function is going to measure the sorts of things that we think listeners can hear" )
( henrySimon_01828 "So, if they do happen in synthetic speech they are likely to be heard by listeners" )
( henrySimon_01829 "For example, sudden discontinuities in F0 don't happen in natural speech" )
( henrySimon_01830 "That mismatch - that change in acoustic properties - will be larger than is normal in natural connected speech" )
( henrySimon_01831 "Well, that's because there'll be a mismatch in the acoustic properties around the join" )
( henrySimon_01832 "Why would a listener notice there's been a join in some speech?" )
( henrySimon_01833 "Our join cost function has to make a prediction about how perceptible the join will be" )
( henrySimon_01834 "So we have to compute all of these costs and they have to be taken into account when deciding which overall sequence of candidates is best" )
( henrySimon_01835 "and so on for all the other positions" )
( henrySimon_01836 "So, in general, then we're going to have to measure the join cost - the potential quality of the concatenation - between every possible pair of units" )
( henrySimon_01837 ", it's going to change, potentially) on the choice of candidate in the neighbouring positions" )
( henrySimon_01838 "e" )
( henrySimon_01839 "We can see now that the choice of candidate in this position depends (i" )
( henrySimon_01840 "The same will be true to the left as well" )
( henrySimon_01841 "So, before choosing this particular candidate, we need to quantify how well it will concatenate with each of the things it needs to join to" )
( henrySimon_01842 "However, that fails to take into account whether this candidate will concatenate well with the candidates either side" )
( henrySimon_01843 "Let's focus on this target position, and let's imagine we've decided that this candidate has got the lowest overall target cost" )
( henrySimon_01844 "So the second part of quantifying the best-sounding candidate sequence is to measure this concatenation quality" )
( henrySimon_01845 "What are we going to do with those candidates after we've selected them? We're going to concatenate their waveforms, and play that back, and hope a listener doesn't notice that we've made a new utterance by concatenating fragments of other utterances" )
( henrySimon_01846 "Measuring similarity between an individual candidate and its target position is only part of the story" )
( henrySimon_01847 "That closeness could be measured in terms of whether they have similar linguistic environments, or whether they "sound the same"" )
( henrySimon_01848 "All we need at this point is to know that we can have a function that measures how close a candidate is to the target" )
( henrySimon_01849 "The target cost is a very important part of unit selection, so we're going to devote a later part of the course to that, and not go into the details just at this moment" )
( henrySimon_01850 "So, if we wanted to measure the difference between a target and a candidate acoustically (which really is what we want to do: we want to know if they're going to sound the same or not) we would have to make a prediction about the acoustic properties of the target units" )
( henrySimon_01851 "They're just abstract linguistic specifications at this point" )
( henrySimon_01852 "We're trying to synthesize them" )
( henrySimon_01853 "Another way to think about measuring the mismatch between a candidate and a target is in terms of their acoustic features, but we can't do that directly because the targets don't have any acoustic features" )
( henrySimon_01854 "The function won't do anything clever about particular combinations of mismatch" )
( henrySimon_01855 "He calls that the "Independent Feature Formulation" because a mismatch in one feature and a mismatch in another feature both count independently towards the total cost" )
( henrySimon_01856 "It basically counts up the number of mismatched linguistic features" )
( henrySimon_01857 "One of them is what we've just described" )
( henrySimon_01858 "Taylor, in his book, proposes two possible formulations of the target cost function" )
( henrySimon_01859 "The number of mismatches will lead us to a cost" )
( henrySimon_01860 "That's rarely (if ever) going to be the case, so we're going to try and look for ones that have low target costs" )
( henrySimon_01861 "A target cost of zero means that the linguistic context - measured using whatever features are available to us - was identical between target and candidate" )
( henrySimon_01862 "The function is called the target cost function" )
( henrySimon_01863 "The function is going to return a cost (we might call that a distance)" )
( henrySimon_01864 "We're going to do that with a function" )
( henrySimon_01865 "We need to quantify it" )
( henrySimon_01866 "So we need a function to measure this mismatch" )
( henrySimon_01867 "So we're not (in general) going to find exactly-matched candidate units, measured in terms of their linguistic context" )
( henrySimon_01868 "Now, that's not possible in general, because there's an infinite number of sentences that our system will have to synthesize" )
( henrySimon_01869 "If we could find candidates from identical linguistic contexts to those in the target unit sequence, we'd effectively be pulling out the entire target sentence from the database" )
( henrySimon_01870 "The motivation for that is pretty obvious" )
( henrySimon_01871 "We're going to look at the similarity between a candidate and a target in terms of their linguistic contexts" )
( henrySimon_01872 "We could consider the linguistic environment of each individual candidate, and measure how close they are" )
( henrySimon_01873 "So, what do we need to take into account when selecting from amongst those many, many possible candidate sequences? Perhaps the most obvious one is that, when we're choosing a candidate - let's say for this position - from these available candidates, we could consider the linguistic context of the target: in other words, its linguistic environment in this target sentence" )
( henrySimon_01874 "Then we're going to pick the one that we predict will sound the best" )
( henrySimon_01875 "We want to quantify it: put a number on it" )
( henrySimon_01876 "We want to measure how well each of those will sound" )
( henrySimon_01877 "Let's just pick one of them for illustration" )
( henrySimon_01878 "There are many, many possible sequences of candidates, even for this very small example here" )
( henrySimon_01879 "We've retrieved from the database a number of possible candidate waveform fragments to use in each target position" )
( henrySimon_01880 "The next steps are to come up with some function that quantifies "best sounding", and then to search for the sequence of candidates that optimizes that function" )
( henrySimon_01881 "The linguistic features are determined by the source utterance in the recorded database where that candidate came from" )
( henrySimon_01882 "That will not change their linguistic features" )
( henrySimon_01883 "That's going to be particularly important for the candidates, because for different sequences of candidate units their neighbours might change" )
( henrySimon_01884 "Specifically, we don't need to look at the neighbours" )
( henrySimon_01885 "It's important to remember at all times that the linguistic features are locally attached to each target and each candidate unit" )
( henrySimon_01886 "We're going to have to formalize and define what we mean by "best sounding", quantify that, and then come up with an algorithm to find the best sequence" )
( henrySimon_01887 "Of course, what we want is the one that sounds the best" )
( henrySimon_01888 "We're going to need some principle on which to select from all the different possible sequences of candidates" )
( henrySimon_01889 "So what remains to be done is to choose amongst the multiple candidates for each target position, so that we end up with a sequence of candidates that we can concatenate to produce output speech" )
( henrySimon_01890 "So far, all we've managed to do is retrieve all possible candidates from the database, and we've just matched on the base unit type" )
( henrySimon_01891 "We're going to find - for each target - a single candidate from the database" )
( henrySimon_01892 "They do not yet have waveforms" )
( henrySimon_01893 "Those target units are each annotated with linguistic features" )
( henrySimon_01894 "That's given us a linear string: a sequence of target units" )
( henrySimon_01895 "We've attached the linguistic specification down on to the segment - on to the pronunciation level" )
( henrySimon_01896 "We have run the front end, and got a linguistic specification of the complete utterance" )
( henrySimon_01897 "Right, where are we at this point? Let's orient ourselves again into the bigger picture" )
( henrySimon_01898 "That should be pretty easy to design into any reasonable size database" )
( henrySimon_01899 "That implies that our database minimally needs to contain at least one recording of every base unit type" )
( henrySimon_01900 "At this stage, I haven't applied any selection criteria at all, except that we're insisting on an exact match between the base unit type of each target and the candidates that are available to synthesize that part of the utterance" )
( henrySimon_01901 "We'll go off now and get candidates for all of the other target positions" )
( henrySimon_01902 "So we can have silence-to-speech and speech-to-silence diphones, just like any other diphone" )
( henrySimon_01903 "Now, it seems a bit odd to treat silence as a recorded unit here, but remember in the case of diphones we're just going to treat silence as if it was another segment type - another phoneme" )
( henrySimon_01904 "Let's do the next one" )
( henrySimon_01905 "We're going to repeat that for all of the target positions" )
( henrySimon_01906 "In general (if we've designed our database well), we'll have multiple candidates for each target position" )
( henrySimon_01907 "That waveform's what we're going to concatenate eventually to produce speech" )
( henrySimon_01908 "They're also going to be annotated with the same linguistic specification as the target" )
( henrySimon_01909 "Here's one candidate for the first one we found, and remember that the candidates are waveform fragments" )
( henrySimon_01910 "For every target unit position - such as this one - we're going to go to the database and retrieve all the candidates that match the base unit type" )
( henrySimon_01911 "That's for a good reason: we don't know exactly what we need to put in that database yet, because that all depends on how we're going to select units from it" )
( henrySimon_01912 "The full details of the database are not yet clear to us" )
( henrySimon_01913 "We're going to get those candidate units from a pre-recorded database" )
( henrySimon_01914 "There's our target unit sequence, and what we'd like to do now is go and find candidate waveform fragments to render that utterance" )
( henrySimon_01915 "So we'll just pretend that the whole phone is the acoustic unit: so the base unit type is the phoneme" )
( henrySimon_01916 "That is going to make the diagram look a bit messy" )
( henrySimon_01917 "In reality we'll probably use diphones" )
( henrySimon_01918 "We could build a system like that, though we wouldn't expect it to work that well" )
( henrySimon_01919 "I'm just going to repeat again that the base unit type in this diagram is the phoneme - just for simplicity" )
( henrySimon_01920 "We do not need to refer to its context, to read off that linguistic specification" )
( henrySimon_01921 "It's essential to understand that this information here is stored inside this target unit specification" )
( henrySimon_01922 "What we have in this target unit sequence is a linear string of base unit types, and each of those is annotated with all of its linguistic context: everything that we think might be important for affecting the way that this particular phoneme is pronounced, in this particular environment" )
( henrySimon_01923 "I'm going to move that to the top of the page, because we need some room to put the candidates on this diagram later" )
( henrySimon_01924 "A real system probably wouldn't do that" )
( henrySimon_01925 "In this example, my base unit type is the phoneme" )
( henrySimon_01926 "One of them might be like that, and it's part of a sequence" )
( henrySimon_01927 "So: context-dependent phones" )
( henrySimon_01928 "What we've got effectively, is a string of segments (that's just a fancy word for phones) with contextual information attached" )
( henrySimon_01929 "We're going to produce a flat representation, where all of that higher-level structure - such as part of speech - is attached down on to the pronunciation" )
( henrySimon_01930 "For example, it might have some tree shapes, or some bracketing like this structure" )
( henrySimon_01931 "It has structure" )
( henrySimon_01932 "It has connections between the different tiers" )
( henrySimon_01933 "What the front-end gives us is this structured linguistic representation" )
( henrySimon_01934 "So, let's do that straight away" )
( henrySimon_01935 "That's going to reduce the complexity of the search problem dramatically" )
( henrySimon_01936 "When we talk about the search a bit later on, we'll find that we want the information about the target, about the candidates from the database, and also about the way that they join, to all be stored locally" )
( henrySimon_01937 "These target units are going to be abstract linguistic things" )
( henrySimon_01938 "That's a sequence of the ideal units that we would like to be able to find in the database" )
( henrySimon_01939 "The first thing we're going to construct is a target unit sequence" )
( henrySimon_01940 "Now that we have those key concepts established, let's work our way up to a complete description of unit selection" )
( henrySimon_01941 "Now, the actual base unit type in unit selection could well be the diphone" )
( henrySimon_01942 "When we say unit selection speech synthesis, we mean many copies of each unit type, in fact as many as possible in as many different variations as possible" )
( henrySimon_01943 "When we say diphone speech synthesis, we mean one copy of each type" )
( henrySimon_01944 "It's worth stating the terminology, because there is a potential for confusion here" )
( henrySimon_01945 "Synthesis is now going to involve very carefully choosing from that large database the sounds that are closest to the ones we want" )
( henrySimon_01946 "The best way to do that is going to be to record naturally-occurring speech: people reading out sentences - natural utterances" )
( henrySimon_01947 "What we're going to do now is we're going to deliberately record the variation that we want, to be able to produce at synthesis time lots of variation: all the speech sounds in lots of different contexts" )
( henrySimon_01948 "That only captures very local phonetic variation" )
( henrySimon_01949 "We'd already decided that whole phones (recordings of phonemes) were not appropriate because of co-articulation" )
( henrySimon_01950 "Until now, all we knew about was diphone speech synthesis, with one recorded copy of each type of unit" )
( henrySimon_01951 "The principles will be the same, so we don't need to decide that at this point" )
( henrySimon_01952 "All over the theory that we're going to talk about is going to apply to all of these different unit types" )
( henrySimon_01953 "Everything that we're going to say is general though, whether we're talking about diphones or half-phones, or even whole phones" )
( henrySimon_01954 "Lots of sizes are possible: the diphone is the most obvious one" )
( henrySimon_01955 "Neither do we quite know what the best unit size would be" )
( henrySimon_01956 "We're going to put aside the question of exactly what's in the database until a bit later, because we don't quite know yet what we want" )
( henrySimon_01957 "The key concepts are: to record a database of natural speech - probably somebody reading out sentences - that contains the natural variation we want to hear, that has been caused by linguistic context; at synthesis time, we're going to search for the most appropriate sequence of units, in other words the one that we predict will sound the best when concatenated" )
( henrySimon_01958 "We want the same speech sound many, many times in many different linguistic contexts, and sounding different in each of those contexts" )
( henrySimon_01959 "We want the effects of context because we don't want to have to impose them with single processing" )
( henrySimon_01960 "When we record this database (we're going to say a lot more about that later on in the course) what we want is variety" )
( henrySimon_01961 "We will always find, from amongst those, one that's "good enough" at synthesis time" )
( henrySimon_01962 "What that means then is that, instead of having to record and store a version of every speech sound in every possible linguistic context, we can instead have a sufficient variety that captures the acoustic variation" )
( henrySimon_01963 "More generally, certain combinations of linguistic features in the environment all lead to about the same speech sound" )
( henrySimon_01964 "What makes that possible?" )
( henrySimon_01965 "We have to do the best we can, choosing units that we think will sound as similar as possible to the unit that we wish we had, if only we had that infinite database" )
( henrySimon_01966 "From this finite database we have to "make do"" )
( henrySimon_01967 "and so on" )
( henrySimon_01968 "For example: stress, phrase-finality, phonetic environment," )
( henrySimon_01969 "That database can only capture some small fraction of the possible combinations of linguistic factors" )
( henrySimon_01970 "It might be very large but it won't be infinite" )
( henrySimon_01971 "In practice though, we can only record a fixed size database" )
( henrySimon_01972 "Then, at synthesis time, we'd always have the right unit available for any sentence we wanted to say" )
( henrySimon_01973 "In unit selection, we wish we could record this almost infinite database of all possible variation" )
( henrySimon_01974 "That's not going to work, but it's a reasonable way to start understanding unit selection" )
( henrySimon_01975 "The number of types is going to grow exponentially with the number of factors" )
( henrySimon_01976 "The database size will double again" )
( henrySimon_01977 "We need things to vary prosodically, so let's have things in phrase-final and non-final positions" )
( henrySimon_01978 "But that's not enough" )
( henrySimon_01979 "The database size will double" )
( henrySimon_01980 "So instead of N phoneme types giving us about N^2 diphone types, let's now have a version of each diphone in lexically stressed and unstressed positions" )
( henrySimon_01981 "Let's try hardwiring into the unit type ALL of the linguistic context" )
( henrySimon_01982 "Although it's too naive, and going this way won't actually work, it will help us understand what we're trying to do" )
( henrySimon_01983 "We'll see that later" )
( henrySimon_01984 "The way that we'll get them from the database - the way that we'll select them - will be an implicit prediction of their properties from text" )
( henrySimon_01985 "Unit selection is going to get us out of all of these problems by choosing units that already have the right properties" )
( henrySimon_01986 "We have to make predictions of what the speech should sound like, from the text, and then impose those predictions with signal processing" )
( henrySimon_01987 "What should we use the signal processing to modify?" )
( henrySimon_01988 "So, even if we had perfect signal processing - even if it didn't introduce any artifacts or degradation - we still wouldn't know exactly what to do with it" )
( henrySimon_01989 "However, there's a deeper more fundamental problem that's harder to solve: the things that we're imposing with signal-processing have had to be predicted from text, and our predictions of them aren't perfect" )
( henrySimon_01990 "That's a problem" )
( henrySimon_01991 "It introduces artifacts and degrades the signal" )
( henrySimon_01992 "The most obvious - the one word that we hear when we listen to diphone synthesis - is the signal processing" )
( henrySimon_01993 "So there's a question mark there" )
( henrySimon_01994 "Our techniques for modifying the spectral envelope are not as good as the ones for modifying F0 and duration" )
( henrySimon_01995 "It's not obvious what to modify there" )
( henrySimon_01996 "What's less obvious are the more subtle variations, for example of the spectral envelope, voicing quality, or things that do correlate with prosody" )
( henrySimon_01997 "Now, we have signal processing techniques that can do that reasonably well, so that seems OK" )
( henrySimon_01998 "The most obvious example of that would be prosody where we would need to modify F0 and duration to impose some predicted prosody" )
( henrySimon_01999 "Our single recorded example of each diphone still needs to be manipulated with some fairly extensive signal processing" )
( henrySimon_02000 "While diphone synthesis has solved the local co-articulation problem by hardwiring that into the unit type, in other words considering left or right phonetic context, it doesn't solve any of the other problems of variation according to linguistic context" )
