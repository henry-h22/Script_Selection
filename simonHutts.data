( henrySimon_00000 "In this module we're going to cover unit selection" )
( henrySimon_00001 "We're going to look at the entire system" )
( henrySimon_00002 "The key concepts that are involved" )
( henrySimon_00003 "The idea of selecting from a large database of relatively natural recorded speech" )
( henrySimon_00004 "Of using some cost functions to choose amongst the many possible sequences of units available in that database" )
( henrySimon_00005 "We're going to look at a thing called the target cost function and the join cost function that capture these costs" )
( henrySimon_00006 "We're not going to look in complete detail at the target cost function because that will come a little bit later, but we'll finish off by seeing how a search is conducted efficiently to find the optimal unit sequence" )
( henrySimon_00007 "Before starting on that, you need to make sure you already know the following things: The first area of importance is a little bit of phonetics" )
( henrySimon_00008 "What do we need to know about phonetics?" )
( henrySimon_00009 "We need to know what a phoneme is: a category of sound and a phone is a realization of that - someone speaking that sound" )
( henrySimon_00010 "For the consonants, we need to know that we can describe them using these distinctive features" )
( henrySimon_00011 "The first feature is place and that's where in the mouth the sound is made and in particular with a consonant where some sort of constriction is formed and in the IPA chart those are arranged along the horizontal axis of this table" )
( henrySimon_00012 "So going from the lips right back to the vocal folds, this is a dimension called place" )
( henrySimon_00013 "At each place is possibly used several different manners of making the sound and those are arranged on the vertical axis, not in any particular order" )
( henrySimon_00014 "For example we could make a complete closure, and let sound pressure release in an explosive fashion" )
( henrySimon_00015 "That's a plosive sound" )
( henrySimon_00016 "And finally, for any combination of place and manner, we can also vary the activity of the vocal folds" )
( henrySimon_00017 "That's voicing" )
( henrySimon_00018 "And so it's possible to make a further contrast, for example between /p/ and /b/ by vibrating the vocal folds in the case of /b/" )
( henrySimon_00019 "We can describe vowels in a similar way" )
( henrySimon_00020 "We can talk about the place in the mouth that the tongue is positioned" )
( henrySimon_00021 "For example: is it near the roof of the mouth?" )
( henrySimon_00022 "Or is it down near the bottom?" )
( henrySimon_00023 "So, how open or closed is the vocal tract by the tongue?" )
( henrySimon_00024 "And we can talk about where that positioning takes place, whether it's near the front of the mouth or the back of the mouth" )
( henrySimon_00025 "And these two dimensions, sometimes called height and front-back, characterize the vowel sounds" )
( henrySimon_00026 "Here too, there's the third dimension" )
( henrySimon_00027 "We can make an additional contrast, by slightly extending the length of the vocal tract, by protruding the lips" )
( henrySimon_00028 "And that's called rounding" )
( henrySimon_00029 "So again, there's a set of distinctive features that we can use to describe the vowel sounds: height, front-back, and rounding" )
( henrySimon_00030 "And these will become useful later on, in unit selection where we have to decide how similar two sounds are" )
( henrySimon_00031 "The next thing you need to know about is the source filter model" )
( henrySimon_00032 "This was covered in the course Speech Processing" )
( henrySimon_00033 "In a source filter model, there's a source of sound: that's either the vibration of the vocal folds, or some form of sound in the vocal tract such as release of a closure, or frication" )
( henrySimon_00034 "It's possible of course for both of those things to happen at the same time" )
( henrySimon_00035 "We might make voiced fricatives, like [v] or [z]" )
( henrySimon_00036 "The source of sound goes through a filter: that's the vocal tract" )
( henrySimon_00037 "That filter imposes a vocal tract frequency response" )
( henrySimon_00038 "One way of describing that frequency response is in terms of the peaks (the resonant frequencies)" )
( henrySimon_00039 "They're called formants" )
( henrySimon_00040 "Another way is just to talk more generally about the overall spectral envelope" )
( henrySimon_00041 "So you need to know something about the source filter model" )
( henrySimon_00042 "You should also already know about the front end, what's sometimes called the text processor" )
( henrySimon_00043 "The front end takes the text input and adds lots and lots of information to that based on either rules, or statistical models, or sources of knowledge such as the pronunciation dictionary" )
( henrySimon_00044 "This picture here captures a lot of the work that's done in the front end" )
( henrySimon_00045 "There's the input text and the front end adds things such as: part of speech tags, possibly some structural information, possibly some prosodic information, and always some pronunciation information" )
( henrySimon_00046 "As we progress we're going to see that we might find it convenient to attach all of that information to the segment - to the phoneme" )
( henrySimon_00047 "So we might end up with structures that look rather flatter, that are essentially context-dependent phonemes" )
( henrySimon_00048 "That will become clearer as we go through unit selection" )
( henrySimon_00049 "But what you need to know at this stage is where all of that information comes from: where the linguistic specification is made, and that's in the front end" )
( henrySimon_00050 "Now, we've already also covered a more basic form of speech synthesis, that's called diphone speech synthesis, in which we record one of each type of speech sound, and we use a very special speech sound: that's the second half of one phone and the first half of a consecutive phone said in connected speech and we perform quite a lot of signal processing at synthesis time to impose, for example, the prosody that we require, on that sequence of waveforms" )
( henrySimon_00051 "And the final thing that you need to know about, that we will have covered already in automatic speech recognition for example, is dynamic programming" )
( henrySimon_00052 "In unit selection, we're going to have to make a choice between many possible sequences of waveform fragments" )
( henrySimon_00053 "In other words, we're going to search amongst many possibilities and the search space could be extremely large and so we need an efficient way of doing that search and we're going to formulate the problem in a way that allows us to use dynamic programming to make that search very efficient" )
( henrySimon_00054 "Before getting into all the details, let's just play with some unit selection" )
( henrySimon_00055 "Here's a interactive example" )
( henrySimon_00056 "You can find it on the website speech" )
( henrySimon_00057 "zone" )
( henrySimon_00058 "We're going to try and synthesize my name and so I've found the appropriate diphones from a database" )
( henrySimon_00059 "I've used one of the Arctic databases for this, and I've just pulled out a few candidates for each target position" )
( henrySimon_00060 "So, along the bottom there we have the target diphone sequence, and above it we have the candidates" )
( henrySimon_00061 "Each of these candidates is just a little waveform fragment" )
( henrySimon_00062 "So, we can listen to those and, to say my name, we need to pick one candidate from each column" )
( henrySimon_00063 "So, for example" )
( henrySimon_00064 "This is interactive, so if we select" )
( henrySimon_00065 "those will synthesize the waveform" )
( henrySimon_00066 "This one this one all of those ones" )
( henrySimon_00067 "There are many other sequences we can try" )
( henrySimon_00068 "Have a go for yourself" )
( henrySimon_00069 "Try another sequence" )
( henrySimon_00070 "I've labeled each of the candidates with the utterance that it comes from, and I've also made sure that any candidates coming from the same utterance were contiguous in that utterance" )
( henrySimon_00071 "For example, these all came contiguously" )
( henrySimon_00072 "And so on" )
( henrySimon_00073 "See if you can find the best sequence out of all the possible sequences" )
( henrySimon_00074 "Now, in a real system we can't do this interactively with listeners" )
( henrySimon_00075 "We have to automate it" )
( henrySimon_00076 "We need criteria for choosing between the different candidates for each target position" )
( henrySimon_00077 "We also need to decide how well they might concatenate" )
( henrySimon_00078 "We're going to see that knowing if units were contiguous in the original database could be very helpful" )
( henrySimon_00079 "Because, of course we expect those to join perfectly" )
( henrySimon_00080 "In fact, we won't even cut them up" )
( henrySimon_00081 "We'll take them as a larger unit" )
( henrySimon_00082 "So, I'd like you to go and play with this interactive example and then continue watching the videos" )
( henrySimon_00083 "Before we get into the method of unit selection speech synthesis, it will be a good idea to get some key concepts established" )
( henrySimon_00084 "What motivates the method?" )
( henrySimon_00085 "Why does it work? And perhaps what its limitations might be" )
( henrySimon_00086 "Let's go right back to how speech is produced" )
( henrySimon_00087 "Obviously speech is produced in the human vocal tract" )
( henrySimon_00088 "Therefore the signal that we observe - the waveform - is a result of several interacting processes" )
( henrySimon_00089 "For example, when the tongue moves up and down this isn't perfectly synchronized with the opening of the lips, or the opening / closing of the velum, or the bringing together of the vocal folds to start voicing" )
( henrySimon_00090 "Each of these articulations is loosely synchronized and can spill over into subsequent sounds" )
( henrySimon_00091 "That's the process known as co-articulation" )
( henrySimon_00092 "The end result of co-articulation is that the sound that's produced is changed depending on the context in which it's produced; not just the sound that came before but also the sound that's coming next, as the articulators anticipate where they need to go next" )
( henrySimon_00093 "That's an articulatory process" )
( henrySimon_00094 "But co-articulation happens effectively at many levels, not just at the low acoustic level inside the vocal tract" )
( henrySimon_00095 "There are phonological effects such as assimilation where entire sounds change category depending on their environment" )
( henrySimon_00096 "The prosodic environment changes the way sounds are produced" )
( henrySimon_00097 "For example, their fundamental frequency and their duration are strongly influenced by their position in the phrase" )
( henrySimon_00098 "From that description of speech, it sounds like it's almost going to be impossible to divide speech into small atomic units: in other words, units that we don't subdivide any further" )
( henrySimon_00099 "Strictly speaking, that's true" )
( henrySimon_00100 "What we know about phonetics and linguistics tells us that speech is not a linear string of units like beads on a necklace" )
( henrySimon_00101 "The beads on the necklace don't overlap; you can cut them apart you can put them back together and perfectly rebuild your necklace" )
( henrySimon_00102 "We can't quite do that with speech" )
( henrySimon_00103 "However, we would like to pretend that we CAN do that with speech" )
( henrySimon_00104 "Because, if we're willing to do that - if we're willing to pretend - then we can do speech synthesis by concatenating waveform fragments" )
( henrySimon_00105 "We know that this could give very high speech quality because we're essentially playing back perfect natural speech that was pre-recorded" )
( henrySimon_00106 "So the potential is for extremely high quality" )
( henrySimon_00107 "The only catch - the thing that we have to work around - is that we can't quite cut speech into units and just put them back together again in any order" )
( henrySimon_00108 "The solution to that problem is to think about some base unit type and that those units are context-dependent" )
( henrySimon_00109 "In other words, their sound changes depending on their linguistic environment" )
( henrySimon_00110 "Therefore, rather than just having these base units, we'll have context-dependent versions or "flavours" of those units" )
( henrySimon_00111 "In fact, we'll have many, many different versions of each unit: one version for every possible different linguistic context in which it could occur" )
( henrySimon_00112 "That sounds quite reasonable" )
( henrySimon_00113 "If there was a finite set of contexts in which a sound could occur, we could just record a version of the sound for every possible context" )
( henrySimon_00114 "Then, for any sentence we needed to synthesize, we would have exactly the right units-in-context available to us" )
( henrySimon_00115 "Unfortunately, if we enumerate all the possible contexts, they'll actually be pretty much infinite because context (theoretically at least) spans the entire sentence - possibly beyond" )
( henrySimon_00116 "But it's not all bad news" )
( henrySimon_00117 "Let's think about what's really important about context" )
( henrySimon_00118 "What's important is the effect that it has on the current speech sound" )
( henrySimon_00119 "Let's state that clearly" )
( henrySimon_00120 "We can describe the linguistic context of a sound: for example, the preceding phoneme + the following phoneme" )
( henrySimon_00121 "The number of different contexts seems to be about infinite" )
( henrySimon_00122 "But what really matters is whether that context has a discernable - in other words audible - effect on the sound" )
( henrySimon_00123 "Does it change the sound? We can hope that there is actually a rather smaller number of effectively-different contexts" )
( henrySimon_00124 "That's that idea that unit selection is going to build on" )
( henrySimon_00125 "Let's reduce the problem to something a bit simpler and think only about one particular aspect of linguistic context that we definitely know affects the current sound" )
( henrySimon_00126 "That is: the identity of the preceding and the following sounds" )
( henrySimon_00127 "This is handled relatively easily because there's definitely a small number of such contexts and in fact if we use the diphone as the unit type we're effectively capturing this left or right context-dependency automatically in the base unit type" )
( henrySimon_00128 "I'll just spell that out, so we are completely clear" )
( henrySimon_00129 "This is a recording of me saying the word "complete"" )
( henrySimon_00130 "We could segment it and label it" )
( henrySimon_00131 "Let's just take that first syllable (in red)" )
( henrySimon_00132 "Let's think about the [@] sound in "complete" If we're willing to assume that the effects of the following nasal - the [n] sound - only affect the latter half of the [@], we could form diphone units by cutting in half and taking this as our base unit type" )
( henrySimon_00133 "That's the diphone that we already know about" )
( henrySimon_00134 "If there are N phoneme categories, there are about N^2 diphone types" )
( henrySimon_00135 "So there's an explosion (an exponential increase) in the number of types, just by taking one aspect of context into account" )
( henrySimon_00136 "While diphone synthesis has solved the local co-articulation problem by hardwiring that into the unit type, in other words considering left or right phonetic context, it doesn't solve any of the other problems of variation according to linguistic context" )
( henrySimon_00137 "Our single recorded example of each diphone still needs to be manipulated with some fairly extensive signal processing" )
( henrySimon_00138 "The most obvious example of that would be prosody where we would need to modify F0 and duration to impose some predicted prosody" )
( henrySimon_00139 "Now, we have signal processing techniques that can do that reasonably well, so that seems OK" )
( henrySimon_00140 "What's less obvious are the more subtle variations, for example of the spectral envelope, voicing quality, or things that do correlate with prosody" )
( henrySimon_00141 "It's not obvious what to modify there" )
( henrySimon_00142 "Our techniques for modifying the spectral envelope are not as good as the ones for modifying F0 and duration" )
( henrySimon_00143 "So there's a question mark there" )
( henrySimon_00144 "Let's summarize the key problems with diphone synthesis" )
( henrySimon_00145 "The most obvious - the one word that we hear when we listen to diphone synthesis - is the signal processing" )
( henrySimon_00146 "It introduces artifacts and degrades the signal" )
( henrySimon_00147 "That's a problem" )
( henrySimon_00148 "However, there's a deeper more fundamental problem that's harder to solve: the things that we're imposing with signal-processing have had to be predicted from text, and our predictions of them aren't perfect" )
( henrySimon_00149 "So, even if we had perfect signal processing - even if it didn't introduce any artifacts or degradation - we still wouldn't know exactly what to do with it" )
( henrySimon_00150 "What should we use the signal processing to modify?" )
( henrySimon_00151 "We have to make predictions of what the speech should sound like, from the text, and then impose those predictions with signal processing" )
( henrySimon_00152 "Unit selection is going to get us out of all of these problems by choosing units that already have the right properties" )
( henrySimon_00153 "The way that we'll get them from the database - the way that we'll select them - will be an implicit prediction of their properties from text" )
( henrySimon_00154 "We'll see that later" )
( henrySimon_00155 "Let's pursue the idea of diphones for a moment" )
( henrySimon_00156 "Although it's too naive, and going this way won't actually work, it will help us understand what we're trying to do" )
( henrySimon_00157 "Let's try hardwiring into the unit type ALL of the linguistic context" )
( henrySimon_00158 "So instead of N phoneme types giving us about N^2 diphone types, let's now have a version of each diphone in lexically stressed and unstressed positions" )
( henrySimon_00159 "The database size will double" )
( henrySimon_00160 "But that's not enough" )
( henrySimon_00161 "We need things to vary prosodically, so let's have things in phrase-final and non-final positions" )
( henrySimon_00162 "The database size will double again" )
( henrySimon_00163 "We could keep doing that for all of the linguistic context factors that we think are important" )
( henrySimon_00164 "The number of types is going to grow exponentially with the number of factors" )
( henrySimon_00165 "That's not going to work, but it's a reasonable way to start understanding unit selection" )
( henrySimon_00166 "In unit selection, we wish we could record this almost infinite database of all possible variation" )
( henrySimon_00167 "Then, at synthesis time, we'd always have the right unit available for any sentence we wanted to say" )
( henrySimon_00168 "In practice though, we can only record a fixed size database" )
( henrySimon_00169 "It might be very large but it won't be infinite" )
( henrySimon_00170 "That database can only capture some small fraction of the possible combinations of linguistic factors" )
( henrySimon_00171 "For example: stress, phrase-finality, phonetic environment," )
( henrySimon_00172 "and so on" )
( henrySimon_00173 "From this finite database we have to "make do"" )
( henrySimon_00174 "We have to do the best we can, choosing units that we think will sound as similar as possible to the unit that we wish we had, if only we had that infinite database" )
( henrySimon_00175 "What makes that possible?" )
( henrySimon_00176 "What makes unit selection synthesis feasible? The answer is that some (hopefully very many) linguistic contexts lead to about the same speech sound" )
( henrySimon_00177 "In other words, some of the linguistic environment has a very weak or negligible effect on the current sound" )
( henrySimon_00178 "More generally, certain combinations of linguistic features in the environment all lead to about the same speech sound" )
( henrySimon_00179 "What that means then is that, instead of having to record and store a version of every speech sound in every possible linguistic context, we can instead have a sufficient variety that captures the acoustic variation" )
( henrySimon_00180 "We will always find, from amongst those, one that's "good enough" at synthesis time" )
( henrySimon_00181 "When we record this database (we're going to say a lot more about that later on in the course) what we want is variety" )
( henrySimon_00182 "We want the effects of context because we don't want to have to impose them with single processing" )
( henrySimon_00183 "We want the same speech sound many, many times in many different linguistic contexts, and sounding different in each of those contexts" )
( henrySimon_00184 "The key concepts are: to record a database of natural speech - probably somebody reading out sentences - that contains the natural variation we want to hear, that has been caused by linguistic context; at synthesis time, we're going to search for the most appropriate sequence of units, in other words the one that we predict will sound the best when concatenated" )
( henrySimon_00185 "We're going to put aside the question of exactly what's in the database until a bit later, because we don't quite know yet what we want" )
( henrySimon_00186 "Neither do we quite know what the best unit size would be" )
( henrySimon_00187 "Lots of sizes are possible: the diphone is the most obvious one" )
( henrySimon_00188 "Everything that we're going to say is general though, whether we're talking about diphones or half-phones, or even whole phones" )
( henrySimon_00189 "All over the theory that we're going to talk about is going to apply to all of these different unit types" )
( henrySimon_00190 "The principles will be the same, so we don't need to decide that at this point" )
( henrySimon_00191 "Let's wrap this part up with a little orientation, putting ourselves in the bigger picture to see how far we've got, and what's coming up" )
( henrySimon_00192 "Until now, all we knew about was diphone speech synthesis, with one recorded copy of each type of unit" )
( henrySimon_00193 "We'd already decided that whole phones (recordings of phonemes) were not appropriate because of co-articulation" )
( henrySimon_00194 "So we made a first order solution to that which was just to capture the co-articulation between adjacent phones in the speech signal" )
( henrySimon_00195 "That only captures very local phonetic variation" )
( henrySimon_00196 "Everything else - for example prosody - had to be imposed using fairly extensive signal manipulation" )
( henrySimon_00197 "What we're going to do now is we're going to deliberately record the variation that we want, to be able to produce at synthesis time lots of variation: all the speech sounds in lots of different contexts" )
( henrySimon_00198 "The best way to do that is going to be to record naturally-occurring speech: people reading out sentences - natural utterances" )
( henrySimon_00199 "Synthesis is now going to involve very carefully choosing from that large database the sounds that are closest to the ones we want" )
( henrySimon_00200 "It's worth stating the terminology, because there is a potential for confusion here" )
( henrySimon_00201 "When we say diphone speech synthesis, we mean one copy of each type" )
( henrySimon_00202 "When we say unit selection speech synthesis, we mean many copies of each unit type, in fact as many as possible in as many different variations as possible" )
( henrySimon_00203 "Now, the actual base unit type in unit selection could well be the diphone" )
( henrySimon_00204 "That's the most common choice" )
( henrySimon_00205 "Now that we have those key concepts established, let's work our way up to a complete description of unit selection" )
( henrySimon_00206 "The first thing we're going to construct is a target unit sequence" )
( henrySimon_00207 "That's a sequence of the ideal units that we would like to be able to find in the database" )
( henrySimon_00208 "These target units are going to be abstract linguistic things" )
( henrySimon_00209 "They don't have waveforms" )
( henrySimon_00210 "When we talk about the search a bit later on, we'll find that we want the information about the target, about the candidates from the database, and also about the way that they join, to all be stored locally" )
( henrySimon_00211 "That's going to reduce the complexity of the search problem dramatically" )
( henrySimon_00212 "So, let's do that straight away" )
( henrySimon_00213 "What the front-end gives us is this structured linguistic representation" )
( henrySimon_00214 "It has connections between the different tiers" )
( henrySimon_00215 "It has structure" )
( henrySimon_00216 "For example, it might have some tree shapes, or some bracketing like this structure" )
( henrySimon_00217 "We're going to attach all the information to the phoneme tier" )
( henrySimon_00218 "We're going to produce a flat representation, where all of that higher-level structure - such as part of speech - is attached down on to the pronunciation" )
( henrySimon_00219 "What we've got effectively, is a string of segments (that's just a fancy word for phones) with contextual information attached" )
( henrySimon_00220 "So: context-dependent phones" )
( henrySimon_00221 "One of them might be like that, and it's part of a sequence" )
( henrySimon_00222 "In this example, my base unit type is the phoneme" )
( henrySimon_00223 "A real system probably wouldn't do that" )
( henrySimon_00224 "I'm just using it to make the diagrams simpler to draw and simpler for you to understand" )
( henrySimon_00225 "I'm going to move that to the top of the page, because we need some room to put the candidates on this diagram later" )
( henrySimon_00226 "What we have in this target unit sequence is a linear string of base unit types, and each of those is annotated with all of its linguistic context: everything that we think might be important for affecting the way that this particular phoneme is pronounced, in this particular environment" )
( henrySimon_00227 "It's essential to understand that this information here is stored inside this target unit specification" )
( henrySimon_00228 "We do not need to refer to its context, to read off that linguistic specification" )
( henrySimon_00229 "It's local" )
( henrySimon_00230 "I'm just going to repeat again that the base unit type in this diagram is the phoneme - just for simplicity" )
( henrySimon_00231 "We could build a system like that, though we wouldn't expect it to work that well" )
( henrySimon_00232 "In reality we'll probably use diphones" )
( henrySimon_00233 "That is going to make the diagram look a bit messy" )
( henrySimon_00234 "So we'll just pretend that the whole phone is the acoustic unit: so the base unit type is the phoneme" )
( henrySimon_00235 "There's our target unit sequence, and what we'd like to do now is go and find candidate waveform fragments to render that utterance" )
( henrySimon_00236 "We're going to get those candidate units from a pre-recorded database" )
( henrySimon_00237 "The full details of the database are not yet clear to us" )
( henrySimon_00238 "That's for a good reason: we don't know exactly what we need to put in that database yet, because that all depends on how we're going to select units from it" )
( henrySimon_00239 "For every target unit position - such as this one - we're going to go to the database and retrieve all the candidates that match the base unit type" )
( henrySimon_00240 "So we'll pull all of the waveform fragments out that have been labelled, in this case, with the phoneme /@/" )
( henrySimon_00241 "Here's one candidate for the first one we found, and remember that the candidates are waveform fragments" )
( henrySimon_00242 "They're also going to be annotated with the same linguistic specification as the target" )
( henrySimon_00243 "That waveform's what we're going to concatenate eventually to produce speech" )
( henrySimon_00244 "In general (if we've designed our database well), we'll have multiple candidates for each target position" )
( henrySimon_00245 "So we can go off and fetch more from the database: we'll get all of them in fact" )
( henrySimon_00246 "I've only got a tiny database in this toy example, so I just found 5" )
( henrySimon_00247 "In general, in a big system, we might find hundreds or thousands for some of the more common unit types" )
( henrySimon_00248 "We're going to repeat that for all of the target positions" )
( henrySimon_00249 "Let's do the next one" )
( henrySimon_00250 "Now, it seems a bit odd to treat silence as a recorded unit here, but remember in the case of diphones we're just going to treat silence as if it was another segment type - another phoneme" )
( henrySimon_00251 "So we can have silence-to-speech and speech-to-silence diphones, just like any other diphone" )
( henrySimon_00252 "We'll go off now and get candidates for all of the other target positions" )
( henrySimon_00253 "At this stage, I haven't applied any selection criteria at all, except that we're insisting on an exact match between the base unit type of each target and the candidates that are available to synthesize that part of the utterance" )
( henrySimon_00254 "That implies that our database minimally needs to contain at least one recording of every base unit type" )
( henrySimon_00255 "That should be pretty easy to design into any reasonable size database" )
( henrySimon_00256 "Right, where are we at this point? Let's orient ourselves again into the bigger picture" )
( henrySimon_00257 "We have run the front end, and got a linguistic specification of the complete utterance" )
( henrySimon_00258 "We've attached the linguistic specification down on to the segment - on to the pronunciation level" )
( henrySimon_00259 "That's given us a linear string: a sequence of target units" )
( henrySimon_00260 "Those target units are each annotated with linguistic features" )
( henrySimon_00261 "They do not yet have waveforms" )
( henrySimon_00262 "We're going to find - for each target - a single candidate from the database" )
( henrySimon_00263 "So far, all we've managed to do is retrieve all possible candidates from the database, and we've just matched on the base unit type" )
( henrySimon_00264 "So what remains to be done is to choose amongst the multiple candidates for each target position, so that we end up with a sequence of candidates that we can concatenate to produce output speech" )
( henrySimon_00265 "We're going to need some principle on which to select from all the different possible sequences of candidates" )
( henrySimon_00266 "Of course, what we want is the one that sounds the best" )
( henrySimon_00267 "We're going to have to formalize and define what we mean by "best sounding", quantify that, and then come up with an algorithm to find the best sequence" )
( henrySimon_00268 "It's important to remember at all times that the linguistic features are locally attached to each target and each candidate unit" )
( henrySimon_00269 "Specifically, we don't need to look at the neighbours" )
( henrySimon_00270 "That's going to be particularly important for the candidates, because for different sequences of candidate units their neighbours might change" )
( henrySimon_00271 "That will not change their linguistic features" )
( henrySimon_00272 "The linguistic features are determined by the source utterance in the recorded database where that candidate came from" )
( henrySimon_00273 "The next steps are to come up with some function that quantifies "best sounding", and then to search for the sequence of candidates that optimizes that function" )
( henrySimon_00274 "We've retrieved from the database a number of possible candidate waveform fragments to use in each target position" )
( henrySimon_00275 "The task now is to choose amongst them" )
( henrySimon_00276 "There are many, many possible sequences of candidates, even for this very small example here" )
( henrySimon_00277 "Let's just pick one of them for illustration" )
( henrySimon_00278 "and you can imagine how many more there are" )
( henrySimon_00279 "We want to measure how well each of those will sound" )
( henrySimon_00280 "We want to quantify it: put a number on it" )
( henrySimon_00281 "Then we're going to pick the one that we predict will sound the best" )
( henrySimon_00282 "So, what do we need to take into account when selecting from amongst those many, many possible candidate sequences? Perhaps the most obvious one is that, when we're choosing a candidate - let's say for this position - from these available candidates, we could consider the linguistic context of the target: in other words, its linguistic environment in this target sentence" )
( henrySimon_00283 "We could consider the linguistic environment of each individual candidate, and measure how close they are" )
( henrySimon_00284 "We're going to look at the similarity between a candidate and a target in terms of their linguistic contexts" )
( henrySimon_00285 "The motivation for that is pretty obvious" )
( henrySimon_00286 "If we could find candidates from identical linguistic contexts to those in the target unit sequence, we'd effectively be pulling out the entire target sentence from the database" )
( henrySimon_00287 "Now, that's not possible in general, because there's an infinite number of sentences that our system will have to synthesize" )
( henrySimon_00288 "So we're not (in general) going to find exactly-matched candidate units, measured in terms of their linguistic context" )
( henrySimon_00289 "We're going to have to use candidate units from mismatched non-identical linguistic contexts" )
( henrySimon_00290 "So we need a function to measure this mismatch" )
( henrySimon_00291 "We need to quantify it" )
( henrySimon_00292 "We're going to do that with a function" )
( henrySimon_00293 "The function is going to return a cost (we might call that a distance)" )
( henrySimon_00294 "The function is called the target cost function" )
( henrySimon_00295 "A target cost of zero means that the linguistic context - measured using whatever features are available to us - was identical between target and candidate" )
( henrySimon_00296 "That's rarely (if ever) going to be the case, so we're going to try and look for ones that have low target costs" )
( henrySimon_00297 "The way I've just described that is in terms of linguistic features: effectively counting how many linguistic features (for example left phonetic context, or syllable stress, or position in phrase) match and how many mis-match" )
( henrySimon_00298 "The number of mismatches will lead us to a cost" )
( henrySimon_00299 "Taylor, in his book, proposes two possible formulations of the target cost function" )
( henrySimon_00300 "One of them is what we've just described" )
( henrySimon_00301 "It basically counts up the number of mismatched linguistic features" )
( henrySimon_00302 "He calls that the "Independent Feature Formulation" because a mismatch in one feature and a mismatch in another feature both count independently towards the total cost" )
( henrySimon_00303 "The function won't do anything clever about particular combinations of mismatch" )
( henrySimon_00304 "Another way to think about measuring the mismatch between a candidate and a target is in terms of their acoustic features, but we can't do that directly because the targets don't have any acoustic features" )
( henrySimon_00305 "We're trying to synthesize them" )
( henrySimon_00306 "They're just abstract linguistic specifications at this point" )
( henrySimon_00307 "So, if we wanted to measure the difference between a target and a candidate acoustically (which really is what we want to do: we want to know if they're going to sound the same or not) we would have to make a prediction about the acoustic properties of the target units" )
( henrySimon_00308 "The target cost is a very important part of unit selection, so we're going to devote a later part of the course to that, and not go into the details just at this moment" )
( henrySimon_00309 "All we need at this point is to know that we can have a function that measures how close a candidate is to the target" )
( henrySimon_00310 "That closeness could be measured in terms of whether they have similar linguistic environments, or whether they "sound the same"" )
( henrySimon_00311 "That measure of "sounding the same" involves an extra step of making some prediction of the acoustic properties of those target units" )
( henrySimon_00312 "Measuring similarity between an individual candidate and its target position is only part of the story" )
( henrySimon_00313 "What are we going to do with those candidates after we've selected them? We're going to concatenate their waveforms, and play that back, and hope a listener doesn't notice that we've made a new utterance by concatenating fragments of other utterances" )
( henrySimon_00314 "The most perceptible artefact we get in unit selection synthesis is sometimes those concatenation points, or "joins"" )
( henrySimon_00315 "Therefore, we're going to have to quantify how good each join is, and take that into account when choosing the sequence of candidates" )
( henrySimon_00316 "So the second part of quantifying the best-sounding candidate sequence is to measure this concatenation quality" )
( henrySimon_00317 "Let's focus on this target position, and let's imagine we've decided that this candidate has got the lowest overall target cost" )
( henrySimon_00318 "It's tempting just to choose that - because we'll make an instant local decision - and then repeat that for each target position, choosing its candidate with the lowest target cost" )
( henrySimon_00319 "However, that fails to take into account whether this candidate will concatenate well with the candidates either side" )
( henrySimon_00320 "So, before choosing this particular candidate, we need to quantify how well it will concatenate with each of the things it needs to join to" )
( henrySimon_00321 "The same will be true to the left as well" )
( henrySimon_00322 "We can see now that the choice of candidate in this position depends (i" )
( henrySimon_00323 "e" )
( henrySimon_00324 ", it's going to change, potentially) on the choice of candidate in the neighbouring positions" )
( henrySimon_00325 "So, in general, then we're going to have to measure the join cost - the potential quality of the concatenation - between every possible pair of units" )
( henrySimon_00326 "and so on for all the other positions" )
( henrySimon_00327 "So we have to compute all of these costs and they have to be taken into account when deciding which overall sequence of candidates is best" )
( henrySimon_00328 "Our join cost function has to make a prediction about how perceptible the join will be" )
( henrySimon_00329 "Will a listener notice there's a join?" )
( henrySimon_00330 "Why would a listener notice there's been a join in some speech?" )
( henrySimon_00331 "Well, that's because there'll be a mismatch in the acoustic properties around the join" )
( henrySimon_00332 "That mismatch - that change in acoustic properties - will be larger than is normal in natural connected speech" )
( henrySimon_00333 "For example, sudden discontinuities in F0 don't happen in natural speech" )
( henrySimon_00334 "So, if they do happen in synthetic speech they are likely to be heard by listeners" )
( henrySimon_00335 "Our join cost function is going to measure the sorts of things that we think listeners can hear" )
( henrySimon_00336 "The obvious ones are going to be the pitch (or the physical underlying property: fundamental frequency / F0), the energy - if speech suddenly gets louder or quieter we will notice that, if it's in an unnatural way - and, more generally, the overall spectral characteristics" )
( henrySimon_00337 "Underlying all of this there's an assumption" )
( henrySimon_00338 "The assumption is that measuring acoustic mismatch is a prediction of the perceived discontinuity that a listener will experience when listening to this speech" )
( henrySimon_00339 "If we're going to use multiple acoustic properties in the join cost function, then we have to combine those mismatches in some way" )
( henrySimon_00340 "A typical way is the way that Festival's Multisyn unit selection engine works" )
( henrySimon_00341 "That's to measure the mismatch in each of those three properties separately and then sum them together" )
( henrySimon_00342 "Since some might be more important than others, there'll be some weights" )
( henrySimon_00343 "So, it'll be a weighted sum of mismatches" )
( henrySimon_00344 "It's also quite common to inject a little bit of phonetic knowledge into the join cost" )
( henrySimon_00345 "We know that listeners are much more sensitive to some sorts of discontinuities than others" )
( henrySimon_00346 "A simple way of expressing that is to say that they are much more likely to notice a join in some segment types than in other segment types" )
( henrySimon_00347 "For example, making joins in unvoiced fricatives is fairly straightforward: the spectral envelope doesn't have much detail, and there's no pitch to have a mismatch in" )
( henrySimon_00348 "So we can quite easily splice those things together" )
( henrySimon_00349 "Whereas perhaps in a more complex sound, such as a liquid or a diphthong, with a complex and changing spectral envelope, it's more difficult to hide the joins in those sounds" )
( henrySimon_00350 "So, very commonly, join costs will also include some rules which express phonetic knowledge about where the joins are best placed" )
( henrySimon_00351 "Here's a graphical representation of what the join cost is doing" )
( henrySimon_00352 "We have a diphone on the left, and a diphone on the right" )
( henrySimon_00353 "(Or, in our simple example, just whole phones) We have their waveforms, because these are candidates from the database" )
( henrySimon_00354 "Because we have their waveforms, we can extract any acoustic properties that we like" )
( henrySimon_00355 "In this example, we've extracted fundamental frequency, energy and the spectral envelope" )
( henrySimon_00356 "It's plotted here as a spectrogram" )
( henrySimon_00357 "We could parameterize that spectral envelope any way we like" )
( henrySimon_00358 "This picture is using formants to make things obvious" )
( henrySimon_00359 "More generally, we wouldn't use formants: they're rather hard to track automatically" )
( henrySimon_00360 "We'd use a more generalized representation like the cepstrum" )
( henrySimon_00361 "We're going to measure the mismatch in each of these properties" )
( henrySimon_00362 "For example" )
( henrySimon_00363 "the F0 is slightly discontinuous, so that's going to contribute something to the cost" )
( henrySimon_00364 "The energy is continuous here, so there's very low mismatch (so, low cost) in the energy" )
( henrySimon_00365 "We're similarly going to quantify the difference in the spectral envelope just before the join and just after the join" )
( henrySimon_00366 "We're going to sum up those mismatches with some weights that express the relative importance of them, perceptually" )
( henrySimon_00367 "That's a really simple join cost" )
( henrySimon_00368 "It's going to work perfectly well, although it's a little bit simple" )
( henrySimon_00369 "Its main limitation is it's extremely local" )
( henrySimon_00370 "We just took the last frame (maybe 20ms) of one diphone and the first frame (maybe the first 20ms) of the next diphone (the next candidate that we're considering concatenating) and we're just measuring the very local mismatch between those" )
( henrySimon_00371 "That will fail to capture things like sudden changes of direction" )
( henrySimon_00372 "Maybe F0 has no discontinuity but in the left diphone it was increasing and in the right diphone it was decreasing" )
( henrySimon_00373 "That sudden change from increasing to decreasing will also be unnatural: listeners might notice" )
( henrySimon_00374 "So we could improve that: we could put several frames around the join and measure the join cost across multiple frames" )
( henrySimon_00375 "We could look at the rate of change (the deltas)" )
( henrySimon_00376 "Or we could just generalize that much further and build some probabilistic model of what trajectories of natural speech parameters normally look like, compare that model's prediction to the concatenated diphones, and measure how natural they are under this model" )
( henrySimon_00377 "Now, eventually we are going to go there: we're going to have a statistical model that's going to do that for us, but we're not ready for that yet because we don't know about statistical models" )
( henrySimon_00378 "So we're going to defer that for later, once we've understood statistical models and how they can be used to synthesize speech themselves, we'll then come back to unit selection and see how that statistical model can help us compute the joint cost, and in fact also the target cost" )
( henrySimon_00379 "When we use a statistical model underlying our unit selection system we call that "hybrid synthesis"" )
( henrySimon_00380 "We can now wrap up the description of unit selection by looking at the search" )
( henrySimon_00381 "We need to understand why a search is necessary at all: what the search is finding for us" )
( henrySimon_00382 "It's finding the lowest cost sequence of candidates" )
( henrySimon_00383 "We'll see that that search can be made very efficient indeed" )
( henrySimon_00384 "We'll wrap up at the very end, by saying how that search could be made even faster if we needed to do so" )
( henrySimon_00385 "The ideas here are very similar to those in automatic speech recognition, so make sure you understand the basics of Hidden Markov Models and the Viterbi algorithm before you start on this part" )
( henrySimon_00386 "By definition, because our cost functions are measuring perceptual mismatch (either the perceptual mismatch between a target and a possible candidate for that target, or the perceptual mismatch between a candidate and a consecutive candidate that we're considering concatenating it with) the lowest cost path should sound the best" )
( henrySimon_00387 "In other words, it should sound as close as possible to the target that we're trying to say, and sound the most natural" )
( henrySimon_00388 "Of course, these cost functions are not perfect" )
( henrySimon_00389 "They're either based on linguistic features, or acoustic properties" )
( henrySimon_00390 "Those are not the same thing as perception" )
( henrySimon_00391 "Our cost functions are just predictions of perceived quality" )
( henrySimon_00392 "There's always a possibility of trying to make our cost functions better" )
( henrySimon_00393 "Eventually, the best possible current solution to these cost functions is actually a complete statistical model" )
( henrySimon_00394 "We'll come back to that much later in the course when we come full circle and look at hybrid methods" )
( henrySimon_00395 "For now, we've got relatively simple cost functions and we're going to define the best candidate sequence as the one that has the lowest total cost" )
( henrySimon_00396 "The total cost is just a sum of local costs" )
( henrySimon_00397 "Let's draw one candidate sequence and define what the cost of that sequence would be" )
( henrySimon_00398 "There's one path through this lattice of candidates" )
( henrySimon_00399 "The total cost of this sequence will be the target cost of this candidate measured with respect to this target - the mismatch between those two things - possibly that's a simple weighted sum of linguistic feature mismatches; plus the join cost between these two units; plus the target cost of this candidate with respect to its target; plus the concatenation (or join) cost to the next unit; and so on, summed across the entire sequence" )
( henrySimon_00400 "We should already understand that we can't make local choices, because the choice of one candidate depends on what we're concatenating it to" )
( henrySimon_00401 "So, through the join cost there's a kind of "domino effect"" )
( henrySimon_00402 "The choice of unit in this position will have an effect on the choice of unit in this position, and vice versa" )
( henrySimon_00403 "Everything is symmetrical" )
( henrySimon_00404 "We could have drawn that path going from right to left" )
( henrySimon_00405 "There's a definition of best path: it's simply the one with the lowest total cost, which is a sum of local costs" )
( henrySimon_00406 "We've understood now this "domino effect": that one choice, anywhere in the search, has an effect potentially on all of the other units that are chosen to go with it, because of the join cost" )
( henrySimon_00407 "Now, of course there is one of the sequences that has the lowest total cost" )
( henrySimon_00408 "It's lower than all of the rest" )
( henrySimon_00409 "The search is going to be required to find that sequence" )
( henrySimon_00410 "Now we're going to understand why it was so important that all of those costs (the target cost and the join cost) could be computed entirely locally, and therefore we can do dynamic programming" )
( henrySimon_00411 "So, let's remind ourselves in general terms how the magic of dynamic programming works" )
( henrySimon_00412 "It works by breaking the problem into separate independent problems" )
( henrySimon_00413 "Let's draw a couple of paths and see how dynamic programming could make that computation more efficient" )
( henrySimon_00414 "Consider these two paths" )
( henrySimon_00415 "Let's just give them names: refer to them a Path A and Path B" )
( henrySimon_00416 "Path A and Path B be have a common prefix" )
( henrySimon_00417 "Up to the choice of this unit they're the same" )
( henrySimon_00418 "Therefore, when we're computing the total cost of Path B, we can reuse the computations of Path A up to that point" )
( henrySimon_00419 "We only have to compute the bit that's different - this point here" )
( henrySimon_00420 "That idea generalizes to paths that have common suffixes, or common infixes" )
( henrySimon_00421 "In fact we can break the problem right down and use dynamic programming to make this search just as efficient as if this was a Hidden Markov Model" )
( henrySimon_00422 "Let's spell that out" )
( henrySimon_00423 "Let's see where the dynamic programming step happens" )
( henrySimon_00424 "To make the dynamic programming work, we're going to explore in this example from left to right" )
( henrySimon_00425 "It doesn't matter: we could do right to left, but we'll do left to right" )
( henrySimon_00426 "We'll explore all paths in parallel, this way" )
( henrySimon_00427 "We'll start at the beginning, and we'll send paths forwards in parallel" )
( henrySimon_00428 "They will propagate" )
( henrySimon_00429 "Let's look at the middle part of the problem" )
( henrySimon_00430 "Imagine considering choosing this unit" )
( henrySimon_00431 "This unit lies on several possible paths coming from the left" )
( henrySimon_00432 "It's either preceded by that unit, that unit, that one, or that one" )
( henrySimon_00433 "It has a concatenation cost and then the paths could head off in other directions: or it could go here, or here" )
( henrySimon_00434 "We can state the same thing as we stated in dynamic time warping, or in Hidden Markov Model-based speech recognition: That the lowest cost path through this point must include the lowest cost path up to this point" )
( henrySimon_00435 "Because, if we've decided that we're choosing this unit, then all of the choices here are now independent from all the choices here" )
( henrySimon_00436 "The past and the future are independent, given the present" )
( henrySimon_00437 "That's the dynamic programming step" )
( henrySimon_00438 "That looks incredibly similar to dynamic time warping on the grid" )
( henrySimon_00439 "Or we could think of this as a lattice: we're passing tokens through the lattice, so it's something like a Hidden Markov Model" )
( henrySimon_00440 "You'll see the idea written formally in the readings" )
( henrySimon_00441 "This is the classic paper from Hunt & Black, where this formulation of unit selection was written down for the first time" )
( henrySimon_00442 "This diagram is a way of writing down the search problem" )
( henrySimon_00443 "We can see that the costs are local and that the shape of this graph allows us to do dynamic programming in a very simple way" )
( henrySimon_00444 "This is essentially just a Hidden Markov Model" )
( henrySimon_00445 "As we've described it so far, unit selection concatenates small fragments of waveform" )
( henrySimon_00446 "In our rather simplified toy examples we've been pretending that those fragments are phones (whole phones: recordings of phonemes)" )
( henrySimon_00447 "But, we've been reminding ourselves all along that that's not really going to work very well" )
( henrySimon_00448 "We are better off using diphones" )
( henrySimon_00449 "In either case, there still seems to be a fundamental problem with the way that we've described the situation" )
( henrySimon_00450 "To understand that, let's just go back to this diagram" )
( henrySimon_00451 "To synthesize this target sequence, we pick one from each column of the candidates, and concatenate them" )
( henrySimon_00452 "That implies that there's a join between every pair of consecutive candidates" )
( henrySimon_00453 "That's a LOT of joins! We know that joins are the single biggest problem with unit selection speech synthesis" )
( henrySimon_00454 "The joins are what our listener is most likely to notice" )
( henrySimon_00455 "How can we reduce the number of joins?" )
( henrySimon_00456 "An obvious way is to make the units longer in duration: bigger units" )
( henrySimon_00457 "For example, instead of diphones, we could use half-syllables or whole syllables, or some other bigger unit" )
( henrySimon_00458 "That's a great idea" )
( henrySimon_00459 "That will work extremely well: bigger units = fewer joins" )
( henrySimon_00460 "Generally we're going to get higher quality" )
( henrySimon_00461 "Let's think more generally about that" )
( henrySimon_00462 "There are two sorts of system we could imagine building" )
( henrySimon_00463 "One is where all of the units are of the same type - they're all diphones, or they're all syllables - so they're all the same: they're homogeneous" )
( henrySimon_00464 "The lattice will look very much like the pictures we've drawn so far, but the unit type might change" )
( henrySimon_00465 "A more complicated system might use units of different types" )
( henrySimon_00466 "It might use whole words, if we happen to have the word in the inventory, and then syllables to make up words we don't have, and then diphones to make up syllables that we don't have" )
( henrySimon_00467 "That way, we can say anything, but we try and use the biggest units available in the database" )
( henrySimon_00468 "Older systems used to be built like that" )
( henrySimon_00469 "We say those units are heterogeneous" )
( henrySimon_00470 "The lattice is going to look a bit messy in that case, but we could still implement it and still build such a system" )
( henrySimon_00471 "Let's see that in pictures because it's going to be easier to understand" )
( henrySimon_00472 "Here's a homogeneous system" )
( henrySimon_00473 "All the units are of the same type" )
( henrySimon_00474 "Here they're whole phones" )
( henrySimon_00475 "They could be diphones" )
( henrySimon_00476 "It could be any unit you like, but they must all be of the same approximate size" )
( henrySimon_00477 "When I say size, I mean size of linguistic unit, so, a half-syllable or a syllable" )
( henrySimon_00478 "That's easy" )
( henrySimon_00479 "The number of joins is the same for any path through this lattice" )
( henrySimon_00480 "The number of concatenation points is the same" )
( henrySimon_00481 "We could potentially reduce the number of concatenation points (the number of joins) by trying to find longer units where they're available, and kind of "filling in the gaps" with smaller units when they're not available" )
( henrySimon_00482 "Here's a lattice of candidates that has these heterogeneous unit types" )
( henrySimon_00483 "When I say lattice, I'm referring to the fact that there are paths that can go through these units, like this, and so forth" )
( henrySimon_00484 "There's a lattice of paths" )
( henrySimon_00485 "You could build systems like that" )
( henrySimon_00486 "I've built ones like that with half-syllables and diphones and things, all mixed together" )
( henrySimon_00487 "They're a little bit messy to code, and you have to be a little bit careful about normalizing the costs of each path, so that they could be compared with each other" )
( henrySimon_00488 "Fortunately there's a very easy way to build a system that effectively has longer and longer units in it, where they're available in the database, but automatically falls back to shorter units" )
( henrySimon_00489 "At the same time, it can make shorter units out of longer units where that's preferable" )
( henrySimon_00490 "We can do that simply by realizing that each of these multi-phone units is made of several single phone units" )
( henrySimon_00491 "Of course, in a real system we'd have multi-diphone units made of single diphones" )
( henrySimon_00492 "This picture could simply be redrawn as follows" )
( henrySimon_00493 "We write down the individual constituent units of those larger units, but we note that they were consecutive in the database: that they were spoken contiguously together as a single unit" )
( henrySimon_00494 "That's what these red lines indicate" )
( henrySimon_00495 "There's one little trick that's very common (it's pretty much universal in unit selection systems) to take a system that's essentially homogeneous and get magically larger units out of it" )
( henrySimon_00496 "That's to just simply record these contiguous units and define the join cost as 0 between them and not calculate it" )
( henrySimon_00497 "So, for example in this particular database it looks like the word cat occurred in its entirety" )
( henrySimon_00498 "So we put that into the lattice, but we put it in as the three separate units" )
( henrySimon_00499 "We just remember that, if we make a path that passes through all three of them, it incurs no join cost" )
( henrySimon_00500 "When we search this lattice, the search is going to find (in general) lower cost paths, if it can join up more of these red lines, because they have zero join cost" )
( henrySimon_00501 "But, it's not forced to do that, because it might not always be the best path" )
( henrySimon_00502 "For example there's a path here that essentially concatenates whole words" )
( henrySimon_00503 "There it is" )
( henrySimon_00504 "Those individual words are going to sound perfect because they're just recordings of whole words from the database" )
( henrySimon_00505 "But it might be the case that the joins between them are very unnatural" )
( henrySimon_00506 "Maybe there's a big F0 discontinuity" )
( henrySimon_00507 "So that might not be the best path through this lattice" )
( henrySimon_00508 "It doesn't matter; we don't need to make a hard decision" )
( henrySimon_00509 "There might be better paths through this lattice that don't concatenate exactly those whole words" )
( henrySimon_00510 "Maybe this path" )
( henrySimon_00511 "This path takes advantage of some of those "free" or zero-cost joins" )
( henrySimon_00512 "Maybe it's got a lower total cost than the other path" )
( henrySimon_00513 "The search will decide" )
( henrySimon_00514 "We'll finish with a final reminder that this picture should really be written with diphones but that would be a little messy and confusing to understand" )
( henrySimon_00515 "Another good idea would be to write out the problem in half-phones" )
( henrySimon_00516 "Then we could put zero join costs between pairs of half-phones that make up diphones" )
( henrySimon_00517 "We'd get a system that's effectively a diphone system that can fall back to half-phones where the diphones aren't suitable" )
( henrySimon_00518 "Perhaps, because of about database design, there was a diphone missing" )
( henrySimon_00519 "It can do what's called "backing off"" )
( henrySimon_00520 "A half phone system makes a lot of sense with this zero join cost trick, where we get effectively variable-sized units from half-phone to diphone to multi-diphone" )
( henrySimon_00521 "A nice advantage of a half-phone system is that it can sometimes make joins at phone boundaries" )
( henrySimon_00522 "Generally, it's not a good idea, but there are specific cases where joining at phone boundaries works pretty well" )
( henrySimon_00523 "An obvious one is that we can put an [s] on the end of something to make the plural" )
( henrySimon_00524 "We can make that join at the phone boundary fairly successfully" )
( henrySimon_00525 "We now have a complete picture of unit selection" )
( henrySimon_00526 "We didn't say very much about the target cost" )
( henrySimon_00527 "We said that we could simply look at the mismatches in linguistic features, or that we could make some acoustic prediction about the target and then look at the mismatch in acoustic features" )
( henrySimon_00528 "But we didn't say exactly how those two things would be done" )
( henrySimon_00529 "The target cost is so important, it's covered in its own section of the course and that's coming next" )
( henrySimon_00530 "We're going to look in a lot more detail about these two different formulations: the Independent Feature Formulation and the Acoustic Space Formulation" )
( henrySimon_00531 "And mixing those two things together, which is what actually happens in many real systems" )
( henrySimon_00532 "When we talk about the Acoustic Space Formulation we'll once again point forward to statistical models and then eventually to hybrid systems" )
( henrySimon_00533 "After we've completed our look at the target cost, we'd better decide what's going in our database" )
( henrySimon_00534 "At the moment we just know there is a database" )
( henrySimon_00535 "We think it's probably got natural speech: probably someone reading out whole sentences" )
( henrySimon_00536 "But, what sentences? What's the ideal database?" )
( henrySimon_00537 "We'll look at how to design the ideal database" )
( henrySimon_00538 "We'll see that we want coverage" )
( henrySimon_00539 "We want maximum variation, so that our target cost function has a lot of candidates to choose amongst for each target position, and that our join cost function can find nice smooth joins between those candidates" )
( henrySimon_00540 "Now we've got a complete picture of how unit selection works, we can start to look in more detail at some of the most important components" )
( henrySimon_00541 "The first thing we're going to look at is the target cost function" )
( henrySimon_00542 "We're going to use Taylor's terminology here, to be consistent with his book" )
( henrySimon_00543 "We're going to first look at the simplest way we could configure the target cost function" )
( henrySimon_00544 "That's to calculate the cost as a weighted sum of mismatches in linguistic features" )
( henrySimon_00545 "When Taylor says Independent Feature Formulation, he doesn't mean that the linguistic features are completely independent of each other in a statistical sense" )
( henrySimon_00546 "What he's saying is that - in the target cost computation - the features are all considered independently" )
( henrySimon_00547 "A mismatch in one feature doesn't interact with mismatches in other features" )
( henrySimon_00548 "That makes the calculation really simple, but it is a weakness" )
( henrySimon_00549 "The source of that weakness is the sparsity of these linguistic features, due to the extremely large number of permutations of possible values" )
( henrySimon_00550 "Before carrying on, make sure that you understand the general principles of unit selection from the previous videos" )
( henrySimon_00551 "You need to know that unit selection is basically about selecting waveform fragments from a database of pre-recorded natural speech" )
( henrySimon_00552 "Obviously, that speech is going to have to be annotated so we can find those units" )
( henrySimon_00553 "We haven't said much about that yet, because it's going to come later" )
( henrySimon_00554 "The selection of candidates is based on two costs: a target cost function, which we're going to talk a lot more about now, and a join cost function, which calculates the mismatch across concatenation points (across the joins)" )
( henrySimon_00555 "Because of the join cost, the selection of one candidate depends on the preceding and following candidates, all the way to the ends of the utterance" )
( henrySimon_00556 "Therefore, to minimize the total cost, we need to conduct a search" )
( henrySimon_00557 "We've already talked about that" )
( henrySimon_00558 "So let's get into those details about the target cost: It's measuring mismatch between a target and a candidate for that target position" )
( henrySimon_00559 "We need to decide how that mismatch could be measured" )
( henrySimon_00560 "We'll start with measuring that mismatch in the simplest possible way" )
( henrySimon_00561 "We can call it simple because it's going to use things we already have from our front end" )
( henrySimon_00562 "What we already have, of course, is the linguistic specification of the targets, and that comprises a set of linguistic features" )
( henrySimon_00563 "We've already described how we can essentially flatten those on to the segment (on to the pronunciation level)" )
( henrySimon_00564 "So, what we're dealing with then is a sequence of pronunciation units: phonemes, or maybe diphones" )
( henrySimon_00565 "Each of them has a specification attached to it, so it knows the context in which it appears" )
( henrySimon_00566 "That's true in both the target sequence and for each individual candidate, because the candidates came from real recorded sentences, where we also knew the full linguistic specification" )
( henrySimon_00567 "So we know the same things for the target and for each of the candidates" )
( henrySimon_00568 "The features will be the same because they'll be produced in the same way" )
( henrySimon_00569 "It's a simple count of how many don't match" )
( henrySimon_00570 "The motivation for that should be obvious" )
( henrySimon_00571 "Ideally - although it doesn't happen very often - we would like to find exactly-matching candidates" )
( henrySimon_00572 "Those exactly-matching candidates will have a cost of zero: there'll be no mismatch (a sum of zeros)" )
( henrySimon_00573 "The more mismatched the context is between the candidate and target, the higher the cost" )
( henrySimon_00574 "If the mismatch is in terms of linguistic features, we can just sum up the individual mismatches" )
( henrySimon_00575 "Always remember that the target cost function (like the join cost function) is computing a cost, and that cost is only a prediction of how bad this candidate might sound if we were to use it in this target position" )
( henrySimon_00576 "The advantage of this Independent Feature Formulation type of target cost function is that it works with things we already know" )
( henrySimon_00577 "For every target, the front end text processor has provided us with a linguistic specification" )
( henrySimon_00578 "For every candidate that we are considering for that target position, we also know the same linguistic specification" )
( henrySimon_00579 "Now, precisely how we know that, we'll cover in the module on the database, a little bit later" )
( henrySimon_00580 "So, we know the same things for every target and for every candidate" )
( henrySimon_00581 "We can just make a direct comparison between them" )
( henrySimon_00582 "So, let's make that completely clear" )
( henrySimon_00583 "Let's focus in on one particular target position, one particular candidate that we're considering for that target" )
( henrySimon_00584 "We'll make a direct comparison between the two in terms of their linguistic specification" )
( henrySimon_00585 "That's going to include things like their phonetic context" )
( henrySimon_00586 "So we know the context in which this appears - it's actually this left and right phonetic context - although remember it can be attached locally, because this sequence is constant" )
( henrySimon_00587 "For this candidate, we also know the same things" )
( henrySimon_00588 "We know the phonetic context which it was extracted from in its source sentence" )
( henrySimon_00589 "It's not this context necessarily, it's the context of the natural sentence it came from" )
( henrySimon_00590 "That context is described as a set of separate linguistic features: phonetic context, perhaps stress, position-in-syllable, position-in-word, position-in-phrase," )
( henrySimon_00591 "anything that our front-end text processor can generate for us at synthesis time" )
( henrySimon_00592 "For example, imagine that the candidate that we're considering here (we're measuring the target cost for) actually occurred in the natural sentence "A car" )
( henrySimon_00593 "" So we know, for example, that it was phrase-initial and the target here is also phrase-initial" )
( henrySimon_00594 "We know that it was word-final - there's a word boundary here" )
( henrySimon_00595 "We also know that the target position is word-final" )
( henrySimon_00596 "And of course we know the phonetic context: this candidate came after a silence however for the target position we want something that's after "the": there's a mismatch" )
( henrySimon_00597 "We know that this candidate came from before a [k] and we also know that target comes before a [k]: that's a match" )
( henrySimon_00598 "So: left-phonetic-context mismatches, right-phonetic-context matches" )
( henrySimon_00599 "We're just going to sum up penalties for all of those mismatches" )
( henrySimon_00600 "We should know enough phonetics to know that some linguistic contexts have a bigger effect on sound - and more importantly on perception of that sound - than others" )
( henrySimon_00601 "So, we need to capture that difference in importance between the different features" )
( henrySimon_00602 "The simplest form of the Independent Feature Formulation target cost considers all the features - it considers them to be independent - and it just sums up the number of mismatches" )
( henrySimon_00603 "The only way of weighting one against the other is to put these weights as we sum up those mismatches" )
( henrySimon_00604 "So, for example, in Festival's multisyn unit selection module, these are the weights" )
( henrySimon_00605 "We can see, for example, that a mismatch in left-phonetic-context incurs a slightly higher penalty than a mismatch in right-phonetic-context" )
( henrySimon_00606 "That's capturing our knowledge of co-articulation: that left context has a stronger effect on the current sound than the right context" )
( henrySimon_00607 "Where do these weights come from?" )
( henrySimon_00608 "Well they're set by hand, by listening to a lot of synthetic speech and tuning the weights" )
( henrySimon_00609 "That's quite hard to do; that's obviously a very skilled thing" )
( henrySimon_00610 "But currently that's the best method for picking those weights" )
( henrySimon_00611 "Festival has a couple of special things in its target cost that aren't really part of the target cost itself: it's just a convenient way of implementing something" )
( henrySimon_00612 "They're there to detect problems with the database" )
( henrySimon_00613 "We're going to come back to that when we talk about the database, and we can see where these pseudo-features come from" )
( henrySimon_00614 "They're to do with the automatic labelling of the database, in fact" )
( henrySimon_00615 "Don't worry about these for now" )
( henrySimon_00616 "Concentrate on these features: phonetic context and the prosodic context" )
( henrySimon_00617 "Those are the ones produced by the front end and those are the ones used to choose between competing candidates from different linguistic contexts" )
( henrySimon_00618 "Let's work through an example to make that crystal clear" )
( henrySimon_00619 "Let's just take the main features that are produced by the front end and forget these special values that Festival uses to detect problems in the database" )
( henrySimon_00620 "So here they are, and their weights" )
( henrySimon_00621 "I'm going to consider a single target position in the sentence I'd like to say" )
( henrySimon_00622 "That's its linguistic specification" )
( henrySimon_00623 "I've got two competing candidates, each with their linguistic specifications" )
( henrySimon_00624 "We're going to look at the match / mismatch between each candidate in turn and that target specification, and compute the target cost for each of them" )
( henrySimon_00625 "It's just a simple process of deciding if there's a mismatch and noting that" )
( henrySimon_00626 "Let's do candidate 1 first" )
( henrySimon_00627 "For candidate 1: stress matches, syllable position mismatches, word position matches, Part Of Speech matches, phrase position matches, left-context matches, but right-phonetic-context mismatches" )
( henrySimon_00628 "I will do the same for candidate 2 separately: stress mismatches, syllable position matches, word position matches, Part Of Speech mismatches, phrase position matches, left-phonetic-context mismatches, right-phonetic-context matches" )
( henrySimon_00629 "Candidate 1 has two mismatches, but we need to do a weighted sum to take into account the relative importance of those mismatches" )
( henrySimon_00630 "The syllable position mismatch incurs a penalty of 5 and the right-phonetic-context mismatch incurs a penalty of 3, giving us a total of 8" )
( henrySimon_00631 "Separately for candidate 2: that stress mismatch incurs a penalty of 10, the Part Of Speech mismatch costs 6, and the left-phonetic-context mismatch costs 4, giving us a total of 20" )
( henrySimon_00632 "Now remember, we don't simply use these two values to choose between these two candidates, because we don't yet know how their waveforms will concatenate with the candidates left and right of them in the lattice" )
( henrySimon_00633 "Those costs (those target costs) just go into the lattice and become part of the total cost of all the different paths passing through each of these candidates" )
( henrySimon_00634 "As with most of the examples in this part of the course, I'm drawing my lattice in terms of whole phones because it's neater" )
( henrySimon_00635 "Let's draw a picture of what it would be like for diphone units, just so we see that it can be done" )
( henrySimon_00636 "In diphone units, I'll run the front end in the same way" )
( henrySimon_00637 "I've rewritten segments as diphones" )
( henrySimon_00638 "So that's now my target sequence, and I'm going to go and retrieve diphone candidates from the database" )
( henrySimon_00639 "Each of these candidates has a waveform, and of course also has a linguistic specification" )
( henrySimon_00640 "In the Independent Feature Formulation, it's only the linguistic specification that we're going to use for comparison" )
( henrySimon_00641 "Let's again focus in on one particular target position: we'd like to say this diphone" )
( henrySimon_00642 "We have two available candidates" )
( henrySimon_00643 "We know the recorded utterances that each of those candidates came from: "They saw each other for the first time in Boston" So the top candidate there came from that utterance" )
( henrySimon_00644 ""They ran the canoe in and climbed the high earth bank" The other candidate came from that utterance" )
( henrySimon_00645 "For each of those utterances (these are in the database) they've got natural recorded speech plus a complete linguistic specification" )
( henrySimon_00646 "We can see that we're always matching on the base unit type: that's always an exact match; that's how we retrieve the candidates, just by looking at that" )
( henrySimon_00647 "Then we can look at other features around them" )
( henrySimon_00648 "Now the calculation of target cost for diphones is just a little bit messier because we do it separately for the left and the right halves" )
( henrySimon_00649 "That's because some features might actually differ going through the diphone: it might cross (for example) a syllable or word boundary" )
( henrySimon_00650 "The left half of the diphone might be in a different Part Of Speech to the right half" )
( henrySimon_00651 "We just calculate the target cost as two sub-costs: the left and right halves, and then add those together" )
( henrySimon_00652 "An Independent Feature Formulation target cost is really rather simple" )
( henrySimon_00653 "In fact, it's a bit too simple" )
( henrySimon_00654 "If we return to this example that we just worked through, we can see that there's a problem with the Independent Feature Formulation type of target cost" )
( henrySimon_00655 "It's a bit too simplistic - it's too naive - and the simplicity is because we've treated the features as independent for the purposes of calculating the target cost" )
( henrySimon_00656 "The target cost function doesn't consider two rather important things" )
( henrySimon_00657 "One thing that it fails to consider is combinations of features" )
( henrySimon_00658 "For example, there might be interactions between the stress status of a syllable and whether it's phrase final or not" )
( henrySimon_00659 "Both of those are competing to affect F0, but this function just considers them independently, and just accumulates the penalties" )
( henrySimon_00660 "The other oversimplification of this function is that things strictly match or mismatch: it's a binary distinction" )
( henrySimon_00661 "There's no concept of a "near match"" )
( henrySimon_00662 "So there's no distance: things are either exactly the same (incurring zero penalty) or different (incurring the maximum penalty: the weight in that column)" )
( henrySimon_00663 "There's an example in the table of where a "near match" might be OK" )
( henrySimon_00664 "Candidate 2 came from a left-phonetic-context of [v]" )
( henrySimon_00665 "This has got a fairly similar place of articulation to the desired (the target) left-phonetic-context of [b]" )
( henrySimon_00666 "They're both also voiced" )
( henrySimon_00667 "So we might prefer to take candidates from [v] left-phonetic-contexts than radically different ones, like a liquid" )
( henrySimon_00668 "However, this still incurred the maximum penalty of 4 here" )
( henrySimon_00669 "It would be better if we could soften that somewhat and say that that's a "near match" and maybe there should be a lower penalty in that case" )
( henrySimon_00670 "This function is unable to do that" )
( henrySimon_00671 "So, that's pretty much all there is to the Independent Feature Formulation" )
( henrySimon_00672 "We're working with features that have already been produced by our front-end" )
( henrySimon_00673 "That's super-convenient and is also going to be computationally quick" )
( henrySimon_00674 "We've already had to do all of that front-end processing, so those features are things we already have: they come "for free"" )
( henrySimon_00675 "Those are calculations we had to do to disambiguate pronunciation (for example)" )
( henrySimon_00676 "So we're just deriving simple symbolic features from - in Festival's case - the existing utterance structure, or more generally the linguistic specification" )
( henrySimon_00677 "So computation of this is going to be cheap" )
( henrySimon_00678 "Of course a weighted sum of mismatches is very cheap to compute" )
( henrySimon_00679 "So this target cost function will be fast" )
( henrySimon_00680 "That's good! It makes some dramatic simplifications though" )
( henrySimon_00681 "Nevertheless, it will work" )
( henrySimon_00682 "This is pretty much what Festival does" )
( henrySimon_00683 "It's almost a pure Independent Feature Formulation target cost function in Festival" )
( henrySimon_00684 "Now, we didn't make any acoustic predictions at all in computing this target cost" )
( henrySimon_00685 "The function simply worked with symbolic features" )
( henrySimon_00686 "The symbolic features could optionally include symbolic prosodic features" )
( henrySimon_00687 "So, if the front-end can predict them with sufficient accuracy - for example we might attempt to predict ToBI accents and boundary tones - we will have these symbolic features that capture prosody" )
( henrySimon_00688 "Those can be taken into account when selecting candidates from the database" )
( henrySimon_00689 "Of course, we'll have to annotate the database with the same features" )
( henrySimon_00690 "But what if we don't have that? What if we don't explicitly mark up prosody even symbolically on either the target or the candidates in the database?" )
( henrySimon_00691 "How on earth will we get any prosody at all? How is prosody created using such a cost function?" )
( henrySimon_00692 "Well, very simply by choosing candidates from an appropriate context - for example, phrase final - we'll get appropriate prosody automatically" )
( henrySimon_00693 "That's the same principle that we use to get the correct phonetic co-articulation or the correct syllable stress" )
( henrySimon_00694 "We'll get prosody simply by choosing candidates essentially from the right position in the prosodic phrase" )
( henrySimon_00695 "Therefore, all we really need to do to get prosody is to make sure that the linguistic features from our front end capture sufficient contextual information relevant to prosody" )
( henrySimon_00696 "An awful lot of that rests simply on position-within-prosodic-constituents: where the syllable is within the word, within the phrase," )
( henrySimon_00697 "That will get us prosody" )
( henrySimon_00698 "Optionally - and I say optionally because predicting prosody even symbolically is very error-prone - optionally, we could attempt to predict prosody and then use that as part of the cost function as just another linguistic feature" )
( henrySimon_00699 "It would have to have its own weight" )
( henrySimon_00700 "I just stated that an Independent Feature Formulation makes no attempt to make any acoustic predictions whatsoever about the target" )
( henrySimon_00701 "It simply gets the candidates, and whatever acoustic properties they have, that's what the synthetic speech has" )
( henrySimon_00702 "But thinking about the system as a whole, of course we are making predictions about the acoustics, because we're generating synthetic speech" )
( henrySimon_00703 "It's just implicit in the procedure" )
( henrySimon_00704 "Whilst the cost function itself only deals with symbolic features, the output of the system is synthetic speech and that of course has acoustic properties" )
( henrySimon_00705 "Taken as a whole, the database, the target cost function, the search for the best candidate sequence: that whole complex system is making acoustic predictions" )
( henrySimon_00706 "It's a complicated sort of regression from the linguistic specification to a speech waveform" )
( henrySimon_00707 "However, it's completely implicit" )
( henrySimon_00708 "There's an advantage to being completely implicit" )
( henrySimon_00709 "We don't need to make explicit acoustic predictions, so we don't need complicated models for that, that will make mistakes" )
( henrySimon_00710 "We just get natural output" )
( henrySimon_00711 "There's also a weakness: we can't really inspect the system" )
( henrySimon_00712 "We can't really see how it's making this acoustic prediction" )
( henrySimon_00713 "All we can do is indirectly control that by, for example, changing the weights in the target cost" )
( henrySimon_00714 "So, what we're going to move on to now is we're going to look at a different formulation of the target cost function" )
( henrySimon_00715 "Something that does make some acoustic predictions - explicit predictions of actual acoustic properties - and then measures the difference between target and candidate in that acoustic space" )
( henrySimon_00716 "That's the Acoustic Space Formulation" )
( henrySimon_00717 "That's going to help get us out of a sparsity problem" )
( henrySimon_00718 "But also we can then observe those acoustic predictions: measure their accuracy in an objective sense" )
( henrySimon_00719 "That might help was improve the system in a way that's rather opaque in the Independent Feature Formulation" )
( henrySimon_00720 "I think this is a good time to orient ourselves again, to check that we understand where we are in the bigger picture of unit selection" )
( henrySimon_00721 "What we should understand so far is that a unit selection speech synthesizer has the same front end as as any other synthesizer" )
( henrySimon_00722 "So we run that text processor" )
( henrySimon_00723 "From the linguistic specification, we construct a target sequence, essentially flattening down the specification on to the individual targets" )
( henrySimon_00724 "For each target unit, we retrieve all possible candidates from the database" )
( henrySimon_00725 "We just go for an exact match on the base unit type and we hope for variety in all of the other linguistic features" )
( henrySimon_00726 "For each candidate, we compute a target cost" )
( henrySimon_00727 "So far, we understand the Independent Feature Formulation style of target cost" )
( henrySimon_00728 "It's just a weighted sum" )
( henrySimon_00729 "The weights are the penalties for each mismatched linguistic feature" )
( henrySimon_00730 "We compute join costs and perform a search" )
( henrySimon_00731 "We're going to look at a more sophisticated form of target cost now, where we predict some acoustic properties for the targets and compare those with actual acoustic properties of candidates" )
( henrySimon_00732 "The motivation for that is the weakness of the Independent Feature Formulation" )
( henrySimon_00733 "That compares only linguistic features: symbolic things produced by the front-end" )
( henrySimon_00734 "That's computationally efficient, but it creates an artificial form of sparsity" )
( henrySimon_00735 "We could summarize this weakness by thinking about a single candidate for a particular target position" )
( henrySimon_00736 "The target and the candidate may have differing (in other words, mismatched) linguistic features" )
( henrySimon_00737 "Yet, the candidate could be ideal for that position" )
( henrySimon_00738 "It could sound very similar to the ideal target" )
( henrySimon_00739 "It's very hard to get round that when we're only looking at these linguistic features" )
( henrySimon_00740 "It's very hard to detect which combinations of features lead to the same sound" )
( henrySimon_00741 "What we need to do is to compare how the units sound" )
( henrySimon_00742 "We want to compare how a candidate actually sounds (because we have its waveform) with how we think - or how we predict - a target should sound" )
( henrySimon_00743 "That's going to involve making a prediction of the acoustic properties of the target" )
( henrySimon_00744 "Taylor tries to summarize this situation in this one diagram" )
( henrySimon_00745 "Let's see if we can understand what's going on in this diagram" )
( henrySimon_00746 "For now, let's just think about candidates that have both linguistic specifications and actual acoustic properties" )
( henrySimon_00747 "What Taylor is saying with this diagram is that it's possible that there are two different speech units that have very different linguistic features: this one and this one" )
( henrySimon_00748 "These are maximally-different linguistic features: they mismatch in both stress and phrase finality" )
( henrySimon_00749 "(We're just considering those two dimensions in this picture" )
( henrySimon_00750 ") Yet it's possible that they sound very similar" )
( henrySimon_00751 "The axes of this space are acoustic properties, and these two units lie very close to each other in acoustic space" )
( henrySimon_00752 "This is completely possible" )
( henrySimon_00753 "It's possible that two things that have different linguistic specifications but sound very similar" )
( henrySimon_00754 "To fully understand the implications of this, we need to also think about the target units" )
( henrySimon_00755 "At synthesis time our target units do not have acoustic properties because they're just abstract linguistic structures" )
( henrySimon_00756 "We're trying to predict the acoustic properties" )
( henrySimon_00757 "There is some ideal acoustic property of each target and so the same situation could hold" )
( henrySimon_00758 "It could be the case that we are looking for a target that has this linguistic specification and - using the Independent Feature Formulation - this potential candidate here would be very far away" )
( henrySimon_00759 "It would incur a high target cost: it mismatches twice (both features)" )
( henrySimon_00760 "These other possible candidates would appear to be closer in linguistic feature space" )
( henrySimon_00761 "But if it's the case that [stress -] and [phrase-finality +] happens to sound very similar to [stress +] and [phrase-finality -] then we shouldn't consider these two things here are far apart at all" )
( henrySimon_00762 "But the only way to discover that is actually to go into acoustic space and measure the distance in acoustic space: measure this distance between these two things" )
( henrySimon_00763 "Because, in linguistic feature space, we won't be able to detect that they would have sounded similar" )
( henrySimon_00764 "Unfortunately Taylor fails to label his axes" )
( henrySimon_00765 "It's probably deliberate because he's trying to say this is an abstract acoustic space" )
( henrySimon_00766 "c1 and c2 could be any dimensions of acoustic space that you want" )
( henrySimon_00767 "It might be that this one's duration and this is some other acoustic property" )
( henrySimon_00768 "But it might be something else: maybe the other way around, or maybe something else" )
( henrySimon_00769 "It doesn't really matter" )
( henrySimon_00770 "The point is that in acoustic space things might be close together, but in linguistic space they're far apart" )
( henrySimon_00771 "They're apparently linguistically different, but they are acoustically interchangeable" )
( henrySimon_00772 "It's that interchangeability that's the foundation of unit selection: that's what we're trying to discover" )
( henrySimon_00773 "Now, for our target units to move closer to the candidates (which are acoustic things) we need to predict some acoustic properties for the targets" )
( henrySimon_00774 "We don't necessarily need to predict a speech waveform because we're not going to play back these predicted acoustic properties" )
( henrySimon_00775 "We're only going to use them to choose candidates" )
( henrySimon_00776 "So we really don't need a waveform and neither do we need to predict every acoustic property" )
( henrySimon_00777 "We just need to predict sufficient properties to enable a comparison with candidate units" )
( henrySimon_00778 "Let's try to make this clearer with a picture" )
( henrySimon_00779 "Back to this diagram again" )
( henrySimon_00780 "Again, just for the purpose of explanation, our units are phone-sized" )
( henrySimon_00781 "These candidates here are fully-specified acoustic recordings of speech" )
( henrySimon_00782 "We have waveforms from which we could estimate any acoustic properties" )
( henrySimon_00783 "We can measure duration; we could estimate F0; we could look at the spectral envelope or formants if we wanted" )
( henrySimon_00784 "The targets are abstract linguistic specifications only, with no acoustics" )
( henrySimon_00785 "So far, we only know how to compare them in terms of linguistic features, which both have" )
( henrySimon_00786 "What we're going to do now: we're going to try and move target units closer to the space in which the candidates live" )
( henrySimon_00787 "We're going to give them some acoustic properties" )
( henrySimon_00788 "Let's just think of one: let's imagine adding a value for F0 to all of the target units" )
( henrySimon_00789 "We also know F0 for all the candidates" )
( henrySimon_00790 "It will be then easy to make a comparison between that predicted F0 and the true F0 of a candidate" )
( henrySimon_00791 "We would compare these things, and we could do that for any acoustic properties we liked" )
( henrySimon_00792 "Now, what acoustic features are we going to try and add to our targets?" )
( henrySimon_00793 "Well, we have a choice" )
( henrySimon_00794 "We could do anything we like" )
( henrySimon_00795 "We could predict simple acoustic things such as F0" )
( henrySimon_00796 "In other words, have a model of prosody that predicts values of F0" )
( henrySimon_00797 "Equally, we could predict values for duration or energy (all correlates of prosody)" )
( henrySimon_00798 "So: we'd need a predictive model of prosody" )
( henrySimon_00799 "We'd have to build it, train it, put it inside the front-end, run it at synthesis time" )
( henrySimon_00800 "It would produce values for these things which you could compare to the true acoustic values of the candidates" )
( henrySimon_00801 "We could go further" )
( henrySimon_00802 "We could predict some much more detailed specification: maybe even the full spectral envelope" )
( henrySimon_00803 "Typically we're going to encode the envelope in some compact way that makes it easy to compare to the candidates" )
( henrySimon_00804 "Cepstral coefficients would be a good choice there" )
( henrySimon_00805 "It would seem that the more and more detail that we can predict, the better, because we can make more accurate comparisons to the candidates" )
( henrySimon_00806 "That's true in principle" )
( henrySimon_00807 "However, these are all predicted values and the predictions will have errors" )
( henrySimon_00808 "The more detailed the predictions need to be - for example the full spectral envelope - the less certain we are that they're correct" )
( henrySimon_00809 "It's getting harder and harder to predict those things" )
( henrySimon_00810 "So all of this is only going to work if we can rather accurately predict these properties" )
( henrySimon_00811 "If we don't think we can accurately predict them, we're better off with the Independent Feature Formulation" )
( henrySimon_00812 "Indeed that's why the earlier systems had the Independent Feature Formulation, because we didn't have sufficiently powerful statistical models or good enough data to build accurate predictors of anything else" )
( henrySimon_00813 "But we've got better at that" )
( henrySimon_00814 "We have better models, and so we could indeed today envisage predicting a complete acoustic specification - in fact, all the way to the waveform if you wanted" )
( henrySimon_00815 "How would we do that?" )
( henrySimon_00816 "Well it's a regression problem! We've got inputs: the linguistic features that we already have from the front-end for our targets" )
( henrySimon_00817 "We have a thing we're trying to predict: it could be F0, duration, energy, MFCCs," )
( henrySimon_00818 "anything that you like" )
( henrySimon_00819 "So you just need to pick your favourite regression model" )
( henrySimon_00820 "Here one you know about: the fantastic Classification And Regression Tree" )
( henrySimon_00821 "We'll run it in regression mode, because we're going to predict continuously-valued things" )
( henrySimon_00822 "For example, the leaves of this tree might have actual values for F0" )
( henrySimon_00823 "We'll write the values in here and these would be the predicted values for things with appropriate linguistic features" )
( henrySimon_00824 "It's not the greatest model in the world, but it's one we know how to use" )
( henrySimon_00825 "If you don't like that one, pick any other model you like" )
( henrySimon_00826 "Maybe you could have a neural network" )
( henrySimon_00827 "That would work fine as well, or any other statistical model that can perform regression" )
( henrySimon_00828 "We're actually going to stop talking now about Acoustic Space Formulation, because we're getting very close to statistical parametric synthesis" )
( henrySimon_00829 "That's coming later in the course" )
( henrySimon_00830 "When we fully understood statistical parametric synthesis - which will use models such as trees or neural networks - we can then come full circle and use that same statistical model to drive the target cost function and therefore to do unit selection" )
( henrySimon_00831 "We call that a "hybrid method"" )
( henrySimon_00832 "Let's wrap up our discussion of the target cost function" )
( henrySimon_00833 "We have initially made a hard distinction between two different sorts of target cost function: the Independent Feature Formulation, strictly based on linguistic features; the Acoustic Space Formulation, strictly based on comparing acoustic properties" )
( henrySimon_00834 "Of course, we don't need to have that artificial separation" )
( henrySimon_00835 "We could have both sorts of features in a single target cost function" )
( henrySimon_00836 "There's no problem with that" )
( henrySimon_00837 "We could sum up the differences in linguistic features plus the absolute difference in F0 plus the absolute difference in duration," )
( henrySimon_00838 "and so on, all with weights accordingly" )
( henrySimon_00839 "There's absolutely no problem then to build a mixed-style target cost function where we have a whole set of sub-costs; some of them using linguistic features, some using acoustic features, and we have to set weights" )
( henrySimon_00840 "It's going to be even more difficult to set the weights than in the Independent Feature Formulation case, but we'd have to do it somehow" )
( henrySimon_00841 "Then we can combine the advantages of both types of sub-cost" )
( henrySimon_00842 "The Independent Feature Formulation inherently suffers from extreme sparsity and so predicting some acoustic features can escape some of those sparsity problems inherent in that formulation" )
( henrySimon_00843 "However, we don't know how to predict every single acoustic property" )
( henrySimon_00844 "For example, things happen phrase-finally other than changes in F0 and duration and amplitude" )
( henrySimon_00845 "And things aren't easily captured even by the spectral envelope, such as for example creaky voice" )
( henrySimon_00846 "It will be very difficult to go all the way to a full prediction of that and then go find candidates with that property" )
( henrySimon_00847 "We'd probably be a lot better off using linguistic features, such as "Is it phrase final?" and pulling candidates that are phrase final and would automatically have creaky voice where appropriate" )
( henrySimon_00848 "So, using features still has a place" )
( henrySimon_00849 "We'd probably use them alongside acoustic properties as well" )
( henrySimon_00850 "Finally, of course, we should always remember that all of these features have errors in" )
( henrySimon_00851 "Even the linguistic features from the front-end will occasionally be wrong" )
( henrySimon_00852 "The acoustic predictions will have an intrinsic error in them" )
( henrySimon_00853 "The more detailed those predictions, the harder the task is in fact, so the greater the error" )
( henrySimon_00854 "So everything has errors and we need to take that into account" )
( henrySimon_00855 "To summarize: the Independent Feature Formulation uses rather more robust, perhaps slightly less error-prone features from the front-end" )
( henrySimon_00856 "But is suffering from extreme sparsity problems" )
( henrySimon_00857 "The Acoustic Space Formulation gets us over some of the sparsity problems, but we run into problems of accuracy of predicting acoustic properties" )
( henrySimon_00858 "So, many real systems use some combination of these two things: a target cost function that combines linguistic features and acoustic properties as well" )
( henrySimon_00859 "I'm going to conclude that discussion of unit selection speech synthesis, including the different forms that the target cost function could take, with a summary of the different design choices that you have when you're going to build a new system" )
( henrySimon_00860 "The first choice is: what kind of unit you're going to use" )
( henrySimon_00861 "All my diagrams were using whole phones, although that's not really a sensible choice in practice" )
( henrySimon_00862 "Far more commonly, we'll find systems using diphones or half-phones" )
( henrySimon_00863 "In either case - but especially the half-phone case - the "zero join cost trick" is very important to effectively get larger units" )
( henrySimon_00864 "Those might be actually much larger units" )
( henrySimon_00865 "That's really easy to implement" )
( henrySimon_00866 "You just need to remember which candidates were contiguous in the database and define their join cost to be zero, and not have them calculated by the join cost function" )
( henrySimon_00867 "For example, maybe these units were contiguous, and we'll just write zero join cost between them" )
( henrySimon_00868 "The lattice will be formed as usual, with all the paths" )
( henrySimon_00869 "joining everything together" )
( henrySimon_00870 "On some of those paths would be zero join costs" )
( henrySimon_00871 "On others the join cost function will compute the cost" )
( henrySimon_00872 "It doesn't matter to the search" )
( henrySimon_00873 "The search will just find the best overall path" )
( henrySimon_00874 "You need to choose what kind of target cost you going to use" )
( henrySimon_00875 "Festival is almost a pure Independent Feature Formulation style target cost" )
( henrySimon_00876 "It's just got a couple of little bits of acoustic information in there" )
( henrySimon_00877 "Or we could use a purely Acoustic Space Formulation, doing sufficient partial synthesis so that we only make comparisons in acoustic properties" )
( henrySimon_00878 "You've then got to decide which acoustic properties (which acoustic features) to predict so that that comparison is meaningful and will find you the right candidates" )
( henrySimon_00879 "But most common of all probably is to do both of those things: to use features, because we have them from the front end - they're good in some situations" )
( henrySimon_00880 "For example, features like phrase-final are really good at getting all of the different acoustic properties that correlate with phrase finality: lengthening, F0 falling, voice quality changes such as creakiness" )
( henrySimon_00881 "Those things aren't all easy to predict" )
( henrySimon_00882 "Better just to get units from the right context in the database" )
( henrySimon_00883 "But almost always we'll have some acoustic prediction in there" )
( henrySimon_00884 "So we might have a prosody model that's "sketching out" an F0 contour that we'd like to try and meet" )
( henrySimon_00885 "Or a duration model that tells us what duration candidates to prefer" )
( henrySimon_00886 "The join cost then makes sure that we only choose sequences of candidates that will concatenate smoothly and imperceptibly" )
( henrySimon_00887 "We didn't say anything about any further signal processing, but in many systems (although not in Festival) a little bit of further signal processing is done" )
( henrySimon_00888 "For example, to manipulate F0 in the locality of a join to make it more continuous" )
( henrySimon_00889 "We're not going to deviate very much from the original natural units: that would degrade quality and also it will get us further away from this implicit or explicit prediction that we got from the unit selection process" )
( henrySimon_00890 "The search is straightforward dynamic programming" )
( henrySimon_00891 "It can be done very efficiently" )
( henrySimon_00892 "It can be formulated on a lattice to make it look like this picture here" )
( henrySimon_00893 "We could implement it in any way we like: for example, Token Passing" )
( henrySimon_00894 "In a real system, the length of these lists of candidates will be much, much longer" )
( henrySimon_00895 "There might be hundreds or thousands of common diphones" )
( henrySimon_00896 "With such long candidate lists, the number of paths through the lattice becomes unmanageable" )
( henrySimon_00897 "It's too large and the system will be too slow" )
( henrySimon_00898 "It's therefore normal to do some pruning, just as in Automatic Speech Recognition" )
( henrySimon_00899 "There are many forms of pruning" )
( henrySimon_00900 "The two most common would be: firstly, to limit the number of candidates for any target position - so that will be based only on target cost, it will be computed locally and we just keep a few hundred candidates perhaps for each position (the ones with the lowest target cost); the second most common form of pruning is during the search" )
( henrySimon_00901 "During the dynamic programming, as paths explore this grid, we'll just apply beam search (just as in Automatic Speech Recognition), comparing all of the paths at any moment in time during the search to the current best path" )
( henrySimon_00902 "Those that are worse than that path in other words have a cost greater than it by some margin - called the beam - are discarded" )
( henrySimon_00903 "As in Automatic Speech Recognition, pruning is an approximation" )
( henrySimon_00904 "We're no longer guaranteed to find the lowest-cost candidate sequence" )
( henrySimon_00905 "The payoff is speed" )
( henrySimon_00906 "The final design choice - the thing that we're going to cover next - is what to put in our database" )
( henrySimon_00907 "So let's finish by looking forward to what's coming up" )
( henrySimon_00908 "We need to know a lot more about this database" )
( henrySimon_00909 "It's got to have natural speech in it" )
( henrySimon_00910 "It's going to need to be from a single speaker for obvious reasons: we're going to concatenate small fragments of it" )
( henrySimon_00911 "But what exactly should we record?" )
( henrySimon_00912 "How should we record it? Do we need to be very careful about that?" )
( henrySimon_00913 "And how do we annotate it? We need to know where all of (say) the diphones start and finish, and annotate each of them with their linguistic properties for use in either an IFF or an ASF type target cost" )
( henrySimon_00914 "That's coming next" )
( henrySimon_00915 "After we've built the database, we can then move on to a more powerful form of speech synthesis, which is to use a statistical parametric model that will generate the waveform entirely with a model" )
( henrySimon_00916 "There'll be no concatenation of waveforms" )
( henrySimon_00917 "Nevertheless, it will still need the database to learn that model" )
( henrySimon_00918 "When we come on to talk about the database, it will be important to fully understand our target cost: what features it requires, for example" )
( henrySimon_00919 "Because that will help us decide how to cover all of the permutations of features in the database" )
( henrySimon_00920 "When we think about how to annotate the database, we'll probably want to do that automatically because the database is probably going to be very large" )
( henrySimon_00921 "Finally, we'll come full circle to this thing called "hybrid synthesis" which is probably best described as unit selection driven by a statistical model" )
( henrySimon_00922 "Here's classical unit selection and a hybrid method would take the target sequence of units and replace it with predicted acoustic parameters and use those to go and match candidates from the database" )
( henrySimon_00923 "The target cost will be in this acoustic space" )
( henrySimon_00924 "So we would replace those targets with parameters: for example, F0 or some parameterization of the spectral envelope" )
( henrySimon_00925 "Here it's something called Line Spectral Pairs" )
( henrySimon_00926 "We'd have the candidates as usual from the database" )
( henrySimon_00927 "We'd form them into a lattice" )
( henrySimon_00928 "Here it's called a "sausage" but it's really a lattice" )
( henrySimon_00929 "We would choose the best path through that" )
( henrySimon_00930 "The target cost function would be making comparisons between these units here and the predicted acoustic properties from a powerful statistical model" )
( henrySimon_00931 "All modern methods of speech synthesis - including unit selection that we've already covered - rely on a fairly substantial database of recorded natural speech" )
( henrySimon_00932 "So now we need to think about what's going to go into that database" )
( henrySimon_00933 "What should we record? Before proceeding, let's do the usual check" )
( henrySimon_00934 "What should you already know? You should certainly know how the front end works, and in particular that it produces a thing called a linguistic specification" )
( henrySimon_00935 "You need to know what's in that linguistic specification" )
( henrySimon_00936 "In other words, what features the front-end is able to provide: Phonetic features, such as the current sound, preceding sound, following sound; Prosodic features; and also what we might be able to easily derive from those things, such as position - where we are in the current prosodic phrase, for example" )
( henrySimon_00937 "Given that linguistic specification, you should also understand that we're going to select units at synthesis time from the most similar context we can find to the target" )
( henrySimon_00938 "We're going to combine that similarity measure with a join cost to enable smooth concatenation" )
( henrySimon_00939 "It's the job of the target cost to measure similarity (or distance) between units in the database - which we call candidates - and the target specification" )
( henrySimon_00940 "Our target cost function is going to rank units from the database: it's going to rank candidates" )
( henrySimon_00941 "The database is going to be fairly large, and we're going to need to label it" )
( henrySimon_00942 "At the very least, we need to know where every unit starts and finishes" )
( henrySimon_00943 "So we need some time alignment" )
( henrySimon_00944 "Because the database is large, we might not want to do that by hand" )
( henrySimon_00945 "There might be some other good reasons not to do it by hand" )
( henrySimon_00946 "We're going to borrow some techniques from Automatic Speech Recognition" )
( henrySimon_00947 "So, you need to know just the basics of speech recognition: using simple Hidden Markov Models, for example context-independent models of phonemes; very simple language modelling using finite state models; and how decoding works, in other words, how we choose the best path through our network of language model and acoustic model" )
( henrySimon_00948 "Before starting the discussion of what's going in the database, let's just establish a few key concepts to make sure we have our terminology right" )
( henrySimon_00949 "The first key concept is going to be that of the "base unit type" such as the diphone" )
( henrySimon_00950 "The second key concept is that these base units (for example, diphones) occur in very varied linguistic contexts" )
( henrySimon_00951 "We might want to cover as many of those as possible in the database" )
( henrySimon_00952 "That leads us into the third concept, which is coverage: how many of these unit-types-in-linguistic-context we could reasonably get into a database of finite size" )
( henrySimon_00953 "Looking at each of those key concepts in a little bit of detail then: The base unit type is the thing that our unit selection engine uses" )
( henrySimon_00954 "Most commonly that type is going to be the diphone" )
( henrySimon_00955 "It could also be the half-phone" )
( henrySimon_00956 "In the modules about unit selection, we also talked about using heterogeneous unit types: things of variable linguistic size" )
( henrySimon_00957 "We also said that we don't really need to think about variable-size units" )
( henrySimon_00958 "We can use fixed-size units (such as the diphone) and the zero join cost trick, to effectively get larger units at runtime" )
( henrySimon_00959 "So, from now on, let's just assume that our base unit type is the diphone" )
( henrySimon_00960 "There's going to be a relatively small number of types of base unit" )
( henrySimon_00961 "It's certainly going to be finite - a closed set - and it's maybe going to be of the order of thousands: one or two thousand types" )
( henrySimon_00962 "In our unit selection engine, when we retrieve candidates from the database before choosing amongst them using the search procedure, we look for some match between the target and the candidate" )
( henrySimon_00963 "At that retrieval stage, the only thing we do is to strictly match the base unit type" )
( henrySimon_00964 "So, if the target is of one particular diphone we only go and get candidates of that exact type of diphone, from all the different linguistic contexts" )
( henrySimon_00965 "The only exception to that would be if we've made a mistake designing our database" )
( henrySimon_00966 "Then we might have to go and find some similar types of diphones, if we have no examples at all of a particular diphone" )
( henrySimon_00967 "The consequence of insisting on this strict match is that our target cost does not need to query the base unit type: they all exactly match" )
( henrySimon_00968 "The list of candidates for a particular target position are all of exactly matching diphone type" )
( henrySimon_00969 "All the target cost needs to do is to query the context in which each of the candidates occurs, and measure the mismatch between that and the target specification" )
( henrySimon_00970 "Given the base unit type then, the second key concept is that these base units occur in a natural context" )
( henrySimon_00971 "They're in sentences, typically" )
( henrySimon_00972 "Now, the context is potentially unbounded: it certainly spans the sentence in which we find the unit and we may even want to consider features beyond the sentence" )
( henrySimon_00973 "The number of linguistic features that we consider to be part of the context specification is also unlimited" )
( henrySimon_00974 "It's whatever the front-end might produce and whatever we might derive from that, such as these positional things" )
( henrySimon_00975 "So the context certainly includes the phonetic context, the prosodic environment, and these derived positional features, and anything else that we think might be interesting to derive from our front-end's linguistic specification" )
( henrySimon_00976 "The exact specification of context depends entirely on what our front-end can deliver and what our target cost is going to take into account, whether it's an Independent Feature Formulation or an Acoustic Space Formulation" )
( henrySimon_00977 "For the purposes of designing our database, we're going to keep things a little bit simple and we're just going to consider linguistic features" )
( henrySimon_00978 "We're just going to assume that our target cost is of the most simple IFF type when designing our database" )
( henrySimon_00979 "Although the context in which a speech unit occurs is essentially unbounded (there are an infinite number of possible contexts because there are an infinite number of things that a person might say), in practice it will be finite because we will limit the set of linguistic features that we consider" )
( henrySimon_00980 "We'll probably stick to features that are within the sentence" )
( henrySimon_00981 "Nevertheless, the number of possible contexts is still very, very large and that's going to be a problem" )
( henrySimon_00982 "Just think about the number of permutations of values of those linguistic specification: it's just very, very large" )
( henrySimon_00983 "If we would like to build a database of speech which literally contains every possible speech base unit type (for example each diphone - maybe there's one to two thousand different diphone types) each occurring in every possible linguistic context, that list will be very, very long" )
( henrySimon_00984 "Even if we limit the scope of context to just the preceding sound, the following sound, and some basic prosodic features, and positional features, this list will still be very, very long" )
( henrySimon_00985 "We have to ask ourselves: Would it even be possible to record one example of every unit-in-context? Let's just point out a little shorthand in the language I'm using here" )
( henrySimon_00986 "We've got "base unit types" such as diphones" )
( henrySimon_00987 "We've got "context" which is the combination of linguistic features in the environment of this unit" )
( henrySimon_00988 "So we should be talking about "base unit types in linguistic contexts"" )
( henrySimon_00989 "That's a rather cumbersome phrase!" )
( henrySimon_00990 "I am going to shorten that" )
( henrySimon_00991 "I'm going to say "unit-in-context" for the remainder of this module" )
( henrySimon_00992 "When I say "unit-in-context" I'm talking about the all the different diphones in all the different linguistic contexts" )
( henrySimon_00993 "Natural language has a very interesting property that is one of the reasons it's difficult to cover all of these contexts" )
( henrySimon_00994 "That is that they're distributed very unevenly" )
( henrySimon_00995 "Whatever linguistic unit we think of - whether it's the phoneme or indeed the letter or the word - there are very few types - and for purposes of building the database, those types are units-in-context - very few types are very frequent" )
( henrySimon_00996 "Think about words: you know that some words - such as this one here - are very, very frequent" )
( henrySimon_00997 "Other words a very infrequent" )
( henrySimon_00998 "That's true about almost any linguistic unit type" )
( henrySimon_00999 "It's certainly going to be true about our units-in-context" )
( henrySimon_01000 "The flipside of that is that there are many, many types that are individually very, very rare, but there's very large number of such types" )
( henrySimon_01001 "Taken together, they are frequent" )
( henrySimon_01002 "So we get this interesting property: that rare events are very large in number" )
( henrySimon_01003 "In other words, in any one particular sentence that we might have to synthesize at runtime, there's a very high chance that we'll need at least one rare type" )
( henrySimon_01004 "We've already come across that problem when building the front end" )
( henrySimon_01005 "We know that we keep coming across new words all the time" )
( henrySimon_01006 "These new words are the rare events, but taken together they're very frequent: they happen all the time" )
( henrySimon_01007 "Let's have a very simple practical demonstration of this distribution of types being very uneven" )
( henrySimon_01008 "Here's an exercise for you" )
( henrySimon_01009 "Go and do this on your own" )
( henrySimon_01010 "Maybe you could write it in Python" )
( henrySimon_01011 "Use any data you want" )
( henrySimon_01012 "I'm going to do it on the shell, because I'm old fashioned" )
( henrySimon_01013 "Let's convince ourselves that linguistic units of various types have got this Zipf-like distribution" )
( henrySimon_01014 "Let's take some random text" )
( henrySimon_01015 "I've downloaded something from the British National Corpus" )
( henrySimon_01016 "I'm not sure what it is, because it doesn't matter!" )
( henrySimon_01017 "Let's just have a look at that: it's just some some random text document that I found" )
( henrySimon_01018 "I'm going to use the letter as the unit" )
( henrySimon_01019 "I'm going to plot the distribution of letter frequencies" )
( henrySimon_01020 "In other words, I'm going to count how many times each letter occurs in this document and then I'm going to sort them by their frequency of occurrence" )
( henrySimon_01021 "We'll see that those numbers have a Zipf-like distribution" )
( henrySimon_01022 "I'll take my document and the first thing I'm going to do is I'm going to downcase everything, so I don't care about case" )
( henrySimon_01023 "Here's an old-fashioned way of doing that: "translate" ('tr') it" )
( henrySimon_01024 "We take all the uppercase characters and translate them individually to lowercase" )
( henrySimon_01025 "That's check that bit of the pipeline works" )
( henrySimon_01026 "Everything there is lowercase - all has become downcased, you can see" )
( henrySimon_01027 "I'm now going to pull out individual characters" )
( henrySimon_01028 "I'm only going to count the characters a-to-z" )
( henrySimon_01029 "I'm going to ignore numbers and punctuation for this exercise" )
( henrySimon_01030 "So we'll grep, and we'll print only the matching part of the pattern, and we'll grep for the pattern "any individual letter in the range a-to-z lowercase"" )
( henrySimon_01031 "Let's check that bit of the pipeline works" )
( henrySimon_01032 "That's just printing the document out letter by letter" )
( henrySimon_01033 "I'm now going to count how often each letter occurs" )
( henrySimon_01034 "There's a nice way of doing that sort of thing on the command line" )
( henrySimon_01035 "First we sort them into order, and then we'll put them through a tool called 'uniq'" )
( henrySimon_01036 "uniq finds consecutive lines that are identical and just counts how many times they occur" )
( henrySimon_01037 "In its own, it will just print out one copy of each set of duplicate lines" )
( henrySimon_01038 "We can also ask it to print the count out" )
( henrySimon_01039 "Let's see if that works" )
( henrySimon_01040 "it just takes a moment to run because we're going through this big document" )
( henrySimon_01041 "So there we now have each letter and the number of times it occurs" )
( henrySimon_01042 "There's our distribution" )
( henrySimon_01043 "It's a little bit hard to read like that because it's ordered by letter and not by frequency, so let's sort it by frequency" )
( henrySimon_01044 "I'm going to 'sort' and sort will just operate on the leftmost field, which is conveniently here the number, and we'll sort it numerically not alpha-numerically" )
( henrySimon_01045 "I'm going to reverse the sort, so I get the most frequent thing at the top" )
( henrySimon_01046 "And there is our kind-of classical Zipf-like distribution" )
( henrySimon_01047 "We can see that there are a few letters up here that are accounting for a lot of the frequency: in other words, much of the document" )
( henrySimon_01048 "There's a long tail of letters down here that's rather low in frequency: much, much lower; an order of magnitude lower than those more frequent ones" )
( henrySimon_01049 "If we were to plot those numbers (and I'll let you do that for yourself, maybe in a spreadsheet) we'd see that has this Zipf-like decaying distribution" )
( henrySimon_01050 "So, the Zipf-like distribution is true for letters, even though there are only 26 types, we still see that decaying distribution" )
( henrySimon_01051 "If we do this for linguistic objects with more and more types, we'll get longer and longer tails, until we end up looking at open-class types such as words, where we'll get a very, very long tail of things that happen just once" )
( henrySimon_01052 "Let's do one more example" )
( henrySimon_01053 "Let's do it with speech this time: transcribed speech" )
( henrySimon_01054 "We'll look at the distribution of speech sounds" )
( henrySimon_01055 "I've got a directory full of label files of transcribed speech" )
( henrySimon_01056 "It doesn't really matter where it's come from at this point" )
( henrySimon_01057 "Let's look at one of those: they're sequences of phonemes, labelling the phones in a spoken utterance, with timestamps and so on" )
( henrySimon_01058 "I was going to pull out the phoneme label and I'm going to do the same thing that I did with the letters" )
( henrySimon_01059 "So again I'm going to be old-school: just do this directly on the command line" )
( henrySimon_01060 "If you're not comfortable with that, do it in Python or whatever your favourite tool is! There's many different ways to do this kind of thing" )
( henrySimon_01061 "The first thing I'm going to do, I'm going to pull out the labels" )
( henrySimon_01062 "I know that these labels are always one or two characters long" )
( henrySimon_01063 "So let's 'grep'" )
( henrySimon_01064 "I use "extended grip" ('egrep') - it's a bit more powerful" )
( henrySimon_01065 "I don't want to print out the filenames that are matching" )
( henrySimon_01066 "Again, I just want to print out the part of the file that matches this expression" )
( henrySimon_01067 "I'm going to look for lowercase letters and I know that they should occur once or twice: so, single letters or pairs of letters, these are what the phoneme labels look like" )
( henrySimon_01068 "I also know that they happen at the end of a line" )
( henrySimon_01069 "I'm going to do that for all of my labelled speech files" )
( henrySimon_01070 "Let's just make sure that bit of pattern works" )
( henrySimon_01071 "Yes, that's pulling out all of those" )
( henrySimon_01072 "We'll do the same thing that we did for the letters: sort it,'uniq -c' it, and order it by frequency in reverse order" )
( henrySimon_01073 "Let's run that" )
( henrySimon_01074 "Again we see the same sort of pattern we saw with letters" )
( henrySimon_01075 "If we did this with words, or with any other unit, we'd get the same sort of pattern" )
( henrySimon_01076 "There are a few types up here that are very frequent" )
( henrySimon_01077 "There's a long tail of types down here that are much less frequent; again, at least an order of magnitude less frequent, and possibly more than that" )
( henrySimon_01078 "Because this is a closed set, we don't get a very long tail" )
( henrySimon_01079 "You should go and try this for yourself with a much bigger set of types" )
( henrySimon_01080 "I suggest doing it with words or with linguistic unit-types-in-context: perhaps something like triphones" )
( henrySimon_01081 "But, even for just context-independent phonemes, there are a few that are very low frequency" )
( henrySimon_01082 "I'm using over a thousand sentences of transcribed speech here, and in those thousand sentences there are a couple of phonemes that occurred fewer than a hundred times, regardless of the context" )
( henrySimon_01083 "That's going to be one of the main challenges in creating our database" )
( henrySimon_01084 "Plotting those distributions of frequencies-of-types, from the most frequent to the least frequent (ordering them by their frequency of occurrence) and then plotting their frequency on this axis we always tend to get this sort of shape, this decaying curve" )
( henrySimon_01085 "Now, you'll often see this curve called a Zipf distribution" )
( henrySimon_01086 "That should have a particular exact equation: it's a particular sort of distribution" )
( henrySimon_01087 "Of course, real data doesn't exactly obey these distributions" )
( henrySimon_01088 "It just is somewhat similar, and has the same sort of properties" )
( henrySimon_01089 "In particular, it has this Large Number of Rare Events" )
( henrySimon_01090 "So really we should be talking about a Zipf-like distribution, not exactly a Zipf distribution" )
( henrySimon_01091 "We've established the key concepts of base unit type (let's just assume that's a diphone), of context in which those base unit types occur (that context applies to the sentences in the database and applies equally to the sentences we're going to synthesize)" )
( henrySimon_01092 "Because base units can occur in many possible contexts, there's a very large number of possible types that we'd like to record in our database" )
( henrySimon_01093 "We've seen this Zipf-like distribution of linguistic units which makes that very hard to achieve" )
( henrySimon_01094 "If we just randomly chose text to record, we would get that Zipf-like distribution, whatever our unit type is, whatever the context is" )
( henrySimon_01095 "The only thing we could do to improve coverage would be to increase the size of that database: to record more and more sentences" )
( henrySimon_01096 "As we did that, the number of tokens, the number of recorded tokens, of frequent types would just increase steadily" )
( henrySimon_01097 "The number of infrequent types would grow very slowly, because that's the long tail in the Zipf distribution" )
( henrySimon_01098 "In other words, as we increase database size, we don't change the shape of this curve" )
( henrySimon_01099 "All we do is move it upwards, so frequent types become ever more frequent and the rare types slowly become more frequent" )
( henrySimon_01100 "Because we're just scaling things up, potentially linearly with the database size" )
( henrySimon_01101 "So it would take a very long time to cover these things in the tail" )
( henrySimon_01102 "In fact, we would find that even for very large databases, almost all types (in other words almost all units-in-context) will have no tokens at all" )
( henrySimon_01103 "We know that - however large the database goes - we'll never cover all of those, because of this Zipf-like distribution" )
( henrySimon_01104 "In practice, it's going to be impossible to find a database (composed of a set of sentences) that includes at least one token of every unit-in-context type" )
( henrySimon_01105 "So what can we do then?" )
( henrySimon_01106 "Well, all we can do then is to try and design a script that's better than random selection, in terms of coverage and maybe some other properties" )
( henrySimon_01107 "At first glance, it would appear the main design goal of our script is to improve coverage" )
( henrySimon_01108 "In other words, to cover as many units-in-context as possible" )
( henrySimon_01109 "What's that going to achieve? Well it would appear to increase the chance of finding an exact match at synthesis time" )
( henrySimon_01110 "In other words, finding exactly the candidate that has the properties of the target: with all of the linguistic specification being the same" )
( henrySimon_01111 "Now, we certainly would increase that, but it would remain very unlikely" )
( henrySimon_01112 "In fact, the point of unit selection is that we don't need an exact match between the specification of the candidate and the specification of the target" )
( henrySimon_01113 "The target costs will quantify how bad the mismatch is, but the mismatch does not have to be zero" )
( henrySimon_01114 "The target cost will rank and help us choose between various degrees of mismatch in the various linguistic features" )
( henrySimon_01115 "Just as important then, is that - for each target position - we have a list of candidates from which the join cost can choose" )
( henrySimon_01116 "The longer that list, then the more chance there is of finding sequences that concatenate well together" )
( henrySimon_01117 "So what we're really looking for is not to cover every possible context (because that's impossible), it's to cover a wide variety of contexts so that the target cost and the join cost can between them choose units that don't mismatch too badly in linguistic features, and join together well" )
( henrySimon_01118 "We want to achieve that with the smallest possible database" )
( henrySimon_01119 "There's a few good reasons for keeping the database size small" )
( henrySimon_01120 "One is obvious: it will take time to record this thing" )
( henrySimon_01121 "A side effect of taking a long time to record something is that it's harder and harder to maintain a very consistent speaking style over longer recording periods" )
( henrySimon_01122 "Amateur speakers (like me, and probably you) find that very hard" )
( henrySimon_01123 "In particular, when the recording sessions are split over days or weeks or maybe even months, it's very hard to have the same speaking effort, voice quality, and so on" )
( henrySimon_01124 "Professional speakers are much better at that; that's one reason to use them" )
( henrySimon_01125 "The second reason to keep the database size small is that, at least in unit selection, the runtime system will include an actual copy of that entire database: the waveforms" )
( henrySimon_01126 "So if we've got to store the database in the runtime system (that we might be shipping to our customer) we don't want it to be too many gigabytes" )
( henrySimon_01127 "There might be other goals that we'd like to include in our script design, not just coverage in the smaller script possible" )
( henrySimon_01128 "We won't consider these in any great depth here" )
( henrySimon_01129 "That's because you can explore them for yourself in the "Build your own unit selection voice" exercise" )
( henrySimon_01130 "The sort of things that you might include in your script design might be: choosing sentences that are easy to read out loud, so that your speaker can say them fluently without too many mistakes; you might want to cover low-frequency linguistic forms such as questions; you might want to boost the coverage of phrase-final and phrase-initial units, because in long sentences they're very rare; and you might want to include some domain-specific material, if you think your final system is going to be more frequently used in a particular domain (for example, reading out the news, or reading out emails, or something really simple like telling the time)" )
( henrySimon_01131 "You're going to explore some of those things for yourself in the exercise, so we won't cover them too much more here" )
( henrySimon_01132 "What we will do is look at a typical, simple approach to script design" )
( henrySimon_01133 "It's going to be an algorithm: in other words, it's automatic" )
( henrySimon_01134 "It's going to start from a very large text corpus and make a script from that" )
( henrySimon_01135 "In other words, we're going to choose - one at a time - sentences from a very large corpus, and accumulate them in our script" )
( henrySimon_01136 "We'll stop at some point: perhaps when the script is long enough, or when we think coverage is good enough" )
( henrySimon_01137 "Now, there's as much art as there is science in script design! I'm not presenting this as the only solution" )
( henrySimon_01138 "Every company that makes speech synthesis has their own script design method and probably has their own script that's evolved through many voice builds" )
( henrySimon_01139 "We're going to use a simple greedy algorithm" )
( henrySimon_01140 "In other words, we're going to make decisions and never backtrack" )
( henrySimon_01141 "The algorithm goes like this: we take our large text corpus, and for every sentence in that corpus we give it a score" )
( henrySimon_01142 "The score is about how good it would be if it was added to the script" )
( henrySimon_01143 "The sort of thing we might use to score will be, perhaps, finding sentences with the largest number of types that were not yet represented in our script" )
( henrySimon_01144 ""Types" here would be units-in-context" )
( henrySimon_01145 "We add the best sentence from the large corpus to the script, and then we iterate" )
( henrySimon_01146 "This is about the simplest possible algorithm" )
( henrySimon_01147 "At the end, we'll look at a few little modifications we might make to that" )
( henrySimon_01148 "The algorithm requires the large corpus" )
( henrySimon_01149 "That needs to come from somewhere" )
( henrySimon_01150 "You might want to be very careful about where that text comes from" )
( henrySimon_01151 "If you care about copyright, then you might want to get text for which either there is no copyright (for example, out-of-copyright material), or you might want to obtain permission from the copyright holder" )
( henrySimon_01152 "Regardless of where you get the text from, it's most likely that this is written language and was never meant to be read out loud" )
( henrySimon_01153 "That would have consequences for the readability" )
( henrySimon_01154 "It might be hard to read newspaper sentences out loud" )
( henrySimon_01155 "It might be hard to read sentences from old novels out loud" )
( henrySimon_01156 "You're going to find out that for yourself in the exercise! Because written text was not usually intended to be read aloud, its readability might be poor" )
( henrySimon_01157 "Also, the sort of variation we get in it might be unlike what we normally get in spoken language" )
( henrySimon_01158 "For example" )
( henrySimon_01159 "the prosodic variation might be limited" )
( henrySimon_01160 "There might be very simple differences, like there are far fewer questions in newspaper text than there are in everyday speech" )
( henrySimon_01161 "We've already mentioned that phrase-initial and phrase-final segments might be rather low frequency in text because the sentences are much longer than in spoken language" )
( henrySimon_01162 "We might want to correct for that in our text selection algorithm" )
( henrySimon_01163 "If you're looking for a source of text to use in your own algorithm, the obvious choice is to go to Project Gutenberg where there's a repository of text of out of copyright novels, which you can scrape and use as a source of material" )
( henrySimon_01164 "But be very careful, because historical novels might have language that's archaic and might be very difficult for your speaker to read out loud" )
( henrySimon_01165 "To get a better understanding of the issues in text selection, let's work through a rather simplified example" )
( henrySimon_01166 "We'll assume we have some large corpus of text to start from" )
( henrySimon_01167 "Maybe we've taken lots of novels from Project Gutenberg" )
( henrySimon_01168 "The first step would be to clean up the corpus" )
( henrySimon_01169 "In that text there's likely to be a lot of words for which we don't have reliable pronunciation information" )
( henrySimon_01170 "For example: they're not in our dictionary" )
( henrySimon_01171 "And because, for example, they might be proper names, we don't anticipate that our letter-to-sound rules will work very well" )
( henrySimon_01172 "We're going to therefore need to clean up the text a bit" )
( henrySimon_01173 "We might throw away all the sentences that have words that are not in our dictionary, because we don't trust letter-to-sound rules" )
( henrySimon_01174 "We might throw away all sentences that are rather long: they're hard to read out loud with reasonable prosody, and we're also much more likely to make mistakes" )
( henrySimon_01175 "We might also throw away very short sentences because their prosody is atypical" )
( henrySimon_01176 "Depending on who your speaker is, you might also want to throw away sentences that you deem "hard to read"" )
( henrySimon_01177 "There are readability measures (that are beyond the scope of this course) that you could use, or we could base that on vocabulary" )
( henrySimon_01178 "We could throw away sentences with very low frequency or polysyllabic words that we think our speaker will find difficult" )
( henrySimon_01179 "The goal of our text selection algorithm is going to simply be coverage of unit types-in-context" )
( henrySimon_01180 "So we need to know - for all the sentences in this large text corpus - what units they contain" )
( henrySimon_01181 "Now we don't have a speaker reading these sentences out yet" )
( henrySimon_01182 "We only have the text, so all we can really do is put that text through the front end of our text-to-speech system and obtain - for each sentence - the base unit sequence (for example, the sequence of diphones) and the linguistic context attached to each of those" )
( henrySimon_01183 "One way to think about the algorithm is to imagine a "wish list" that enumerates every possible type that we're looking for" )
( henrySimon_01184 "If we were just looking for diphones (ignoring context for a moment), we would just write out the list of all possible diphones: from this one" )
( henrySimon_01185 "to this one" )
( henrySimon_01186 "(Remembering that silence would also be treated as a phoneme in this system" )
( henrySimon_01187 ") If we start adding linguistic context, that wish list will grow in size exponentially as we add more and more context features" )
( henrySimon_01188 "Imagine just asking for versions of each diphone in stressed and unstressed prosodic environments" )
( henrySimon_01189 "Imagine then adding all possible linguistic features and enumerating a very long wish list in this way" )
( henrySimon_01190 "If you implement an algorithm, you may or may not actually construct this list, because it's going to be huge" )
( henrySimon_01191 "You might not actually store it in memory" )
( henrySimon_01192 "For the worked example, I'm going to actually just ignore linguistic context and try and get coverage just of diphones" )
( henrySimon_01193 "The method will work the same for diphones-in-context, of course" )
( henrySimon_01194 "Here's part of my very large text corpus, that I've put through my text-to-speech front end" )
( henrySimon_01195 "It's given me a sequence of phonemes, from which I've got the sequence of diphones" )
( henrySimon_01196 "This is just the first few sentences of this very large corpus" )
( henrySimon_01197 "I'm going to write down my wish list" )
( henrySimon_01198 "Here's my wish list: it's just the diphones" )
( henrySimon_01199 "Again, in reality we might attach context to those" )
( henrySimon_01200 "What I'm going to do, I'm going to score each sentence for "richness"" )
( henrySimon_01201 "Richness is going to be defined as the number of diphones that I don't yet have in my script" )
( henrySimon_01202 "When we're doing that scoring, if a sentence contains two copies of a particular unit-in-context (here, just the diphone) then only one of them will count" )
( henrySimon_01203 "So we can get rid of these duplicates" )
( henrySimon_01204 "What we need is a function that assigns a score to each of these sentences" )
( henrySimon_01205 "We won't write that out" )
( henrySimon_01206 "We'll just do this impressionistically" )
( henrySimon_01207 "If we were just a count the number of types, then we would pretty much always choose long sentences, because they're more likely to have more types in" )
( henrySimon_01208 "So at the very least, we're going to control for length" )
( henrySimon_01209 "Perhaps we'll normalize "number of types" by "the length of the sentence"" )
( henrySimon_01210 "Under my scoring function it turns out that this sentence here scores the highest" )
( henrySimon_01211 "It's got the most new types in the smallest sentence" )
( henrySimon_01212 "So I will select that sentence, and I'll put it in my script for my speaker to read out in the recording studio later" )
( henrySimon_01213 "I'll remove it from the large database" )
( henrySimon_01214 "Then I'll repeat that procedure" )
( henrySimon_01215 "But before I carry on, I'm going to cross off all the diphones that I got with that sentence" )
( henrySimon_01216 "So I'll scan through the sentence and I'll look at all the diphones that occurred there and I'll cross them off my wish list" )
( henrySimon_01217 "So: these diphones" )
( henrySimon_01218 "and various other diphones have gone" )
( henrySimon_01219 "Our wish list has got smaller, and sentences will no longer score any points for containing those diphones because we've already got them" )
( henrySimon_01220 "That sentence has been selected: it disappears from the large corpus" )
( henrySimon_01221 "Then we'll score the remaining sentences" )
( henrySimon_01222 "The scores will be different than the first time round, because any diphones that have already gone into the script no longer score points" )
( henrySimon_01223 "Remember that was these ones" )
( henrySimon_01224 "and some other ones" )
( henrySimon_01225 "The result of this algorithm is going to be a list of sentences in a specific order: in order of descending richness" )
( henrySimon_01226 "So, when we record that script, we probably want to record it in that order too, so we maximize richness" )
( henrySimon_01227 "And we can stop at any point: we could record a hundred, or a thousand, or ten thousand sentences, depending how much data we wanted" )
( henrySimon_01228 "The order of the sentences will be defined by the selection algorithm" )
( henrySimon_01229 "That's neat, because we can just run our algorithm and select a very large script and go into the studio and record for as long as (for example) we have money" )
( henrySimon_01230 "I've already said there's as much art as there is science to script design, so it's perfectly reasonable to try and craft in some extra selection criteria into your text selection script" )
( henrySimon_01231 "One sensible thing - that our algorithm doesn't currently do - will be to guarantee at least one token of every base unit type" )
( henrySimon_01232 "That will mean we'll never have to back off at synthesis time" )
( henrySimon_01233 "If our base unit is the diphone, then our first N sentences (our first few hundred sentences) will be designed just to get one of each diphone" )
( henrySimon_01234 "After that we'll switch to looking for diphones-in-context" )
( henrySimon_01235 "When we start looking for diphones-in-context, we might actually want to go looking for the hardest-to-find units first: the rare ones first" )
( henrySimon_01236 "In other words, give sentences a higher score for containing low-frequency diphones-in-context" )
( henrySimon_01237 "That's because we'll get the high frequency ones along "for free" anyway" )
( henrySimon_01238 "Another thing we might do is try and include some domain-specific material for one or more domains" )
( henrySimon_01239 "This is to make sure we have particularly good coverage in these smaller domains, so our voice will perform particularly well on these domains" )
( henrySimon_01240 "These might be decided by, for example, the particular product that our synthesizer is going into" )
( henrySimon_01241 "If we just selected a script of strictly in-domain sentences, we'd expect very good performance in that domain but we might be missing a lot of units that we need for more general-purpose synthesis" )
( henrySimon_01242 "So a standard approach to getting a domain-specific script is to first use your in-domain sentences (they might be manually written, or from some language-generation system); measure the coverage of that; then fill in the gaps with a standard text selection algorithm, from some other large corpus" )
( henrySimon_01243 "Then we can get the best of both worlds: particularly good coverage in a domain and general-purpose coverage, so we can also say anything else" )
( henrySimon_01244 "All that remains then is to go into the recording studio!" )
( henrySimon_01245 "Find a voice talent who can read sentences fluently with a pleasant voice, and ask that person to read each of our sentences" )
( henrySimon_01246 "Then we're going to have a recorded database" )
( henrySimon_01247 "The next step will be to label that recorded database" )
( henrySimon_01248 "We'll finish off this module on the database by looking at how we're going to label it ("annotate" it) But let's just orient ourselves in the bigger picture before we continue" )
( henrySimon_01249 "What we've got so far is a script, which is composed of individual sentences" )
( henrySimon_01250 "That script will have been designed, probably by a text selection algorithm that we've written" )
( henrySimon_01251 "It will aim to: cover the units-in-context; to be readable; to provide each base unit in a wide variety of different linguistic contexts; and possibly some other things as well, such as specific domains" )
( henrySimon_01252 "With that script, we've gone into a recording studio and asked a speaker (sometimes called the "voice talent") to record those sentences" )
( henrySimon_01253 "They'll be recorded generally as isolated sentences" )
( henrySimon_01254 "Our text selection algorithm will have very likely provided us with a script in an order of decreasing richness" )
( henrySimon_01255 "So we'll record the script in that same order, meaning that we can stop at any point and maximize the coverage for that given amount of material" )
( henrySimon_01256 "What remains to be done is to segment the speech: to put phonetic labels on it, so we know where each (for example) diphone starts and ends" )
( henrySimon_01257 "On top of that phonetic labelling (or "segmentation"), we need to annotate the speech with all of the supra-segmental linguistic information: all the other things that the target cost might need to query" )
( henrySimon_01258 "We'll start by looking at the time-aligned phonetic transcription" )
( henrySimon_01259 "We're going to use a technique borrowed from speech recognition" )
( henrySimon_01260 "Then we'll see how we attach the supra-segmental (in other words, the stuff above the phonetic level), how we attach the supra-segmental information to that phonetic transcription that's been time aligned" )
( henrySimon_01261 "Let's think about two extremes of ways that we might label the speech, to understand why hand labelling might not be the right answer" )
( henrySimon_01262 "If we think that we need a transcription of the speech that's exactly faithful to how the speaker said the text: It gets every vowel reduction, every slight mispronunciation, every pause, everything exactly faithful to the way the speaker said the text" )
( henrySimon_01263 "Then we might think we want to hand label from scratch" )
( henrySimon_01264 "In other words, from a blank starting sheet without any prior information" )
( henrySimon_01265 "We'll be down at this end of the continuum" )
( henrySimon_01266 "But, if we think about what we're going to do with this data" )
( henrySimon_01267 "We're going to do unit selection speech synthesis" )
( henrySimon_01268 "We're going to retrieve units and that retrieval will try to match a target sequence" )
( henrySimon_01269 "The target sequence will have gone through our text-to-speech front-end" )
( henrySimon_01270 "The front-end is not perfect" )
( henrySimon_01271 "It might make mistakes, but it will be at least consistent" )
( henrySimon_01272 "It'll always give you the same sequence for the same input text" )
( henrySimon_01273 "But that sequence might not be the same as our speaker said the particular sentence in the database" )
( henrySimon_01274 "So another extreme would be to label the database in a way that's entirely consistent with what the front-end is going to do at synthesis time" )
( henrySimon_01275 "We can call that the "canonical phone sequence"" )
( henrySimon_01276 "In other words, the sequence that is exactly what comes out of the front end" )
( henrySimon_01277 "If we had to choose between these two things, we'd actually want to choose this end, because we want consistency between the database and the runtime speech synthesis" )
( henrySimon_01278 "Consider the example of trying to say a sentence that exists in its entirety in the database" )
( henrySimon_01279 "We would obviously want to pull out the entire waveform and play it back and get perfect speech" )
( henrySimon_01280 "The only way we could do that, is if the database had exactly the same labels on it that our front end predicts at the time we try and synthesize that sentence, regardless of how the speaker said it" )
( henrySimon_01281 "Now there are some points in between these two extremes, and we're going to take one of those as our basis for labelling" )
( henrySimon_01282 "We're going to slightly modify the sequence that comes out of the front end" )
( henrySimon_01283 "We're going to move it a little bit closer to what the speaker actually said" )
( henrySimon_01284 "We'll see exactly how we make those modifications, and why, as we go through the next few sections" )
( henrySimon_01285 "To summarize that situation: we have some text that our speaker reads out; we could put that through the text-to-speech front-end and get a phonetic sequence from that" )
( henrySimon_01286 "That's the canonical sequence" )
( henrySimon_01287 "We can then make some time alignment between that canonical sequence and what the speaker actually said (their waveform)" )
( henrySimon_01288 "That will be very consistent, but there might be things our speaker did that are radically different to what's in that canonical sequence" )
( henrySimon_01289 "A good example of that might be that the speaker put a pause between two words that our front end did not predict, because maybe our pausing model in the front end is not perfect" )
( henrySimon_01290 "We could start from what the speaker said and we could hand transcribe and get a phonetic sequence" )
( henrySimon_01291 "That phonetic sequence will be very faithful to what the speaker said, but it might be rather hard to match that up with what the front end does at synthesis times" )
( henrySimon_01292 "There might be systemic mismatches there" )
( henrySimon_01293 "Those mismatches will mean that - when we try and say this whole sentence, or perhaps just fragments of it - at synthesis time, we won't retrieve long contiguous sequences of units from the database" )
( henrySimon_01294 "In other words, we'll make more joins than necessary" )
( henrySimon_01295 "Joins are bad!" )
( henrySimon_01296 "Joins are what listeners notice" )
( henrySimon_01297 "Consistency will help us pull out longer contiguous units by getting an exact match between the labels on the database and what the front end does at synthesis time" )
( henrySimon_01298 "Our preference is going to be start from the text that we asked the speaker to read, get the phonetic sequence, and then make some further small modifications to adjust it so it's a slightly closer fit to what the speaker said in (for example) pausing" )
( henrySimon_01299 "The sort of labelling we're doing, Taylor calls "analytical labelling"" )
( henrySimon_01300 "Do the readings to understand precisely what he means by that" )
( henrySimon_01301 "We're going to prefer this to be done automatically" )
( henrySimon_01302 "Yes, that's faster and cheaper, and that's a very important reason for doing it" )
( henrySimon_01303 "But an equally important reason is that it's more consistent between what's in the database and what happens when we synthesize an unseen sentence" )
( henrySimon_01304 "A good way to understand that is to think about the labels on the database as not being a close phonetic transcription of the speech, but being just an index: a way of retrieving appropriate units for our search to choose amongst" )
( henrySimon_01305 "Having consistent names for those units in that index is more important than being very faithful to what the speech actually says" )
( henrySimon_01306 "A natural question is whether we could automatically label speech and then, by hand, make some small changes to match what the speaker actually said" )
( henrySimon_01307 "Of course, that is possible, and that's standard practice actually in some companies" )
( henrySimon_01308 "Those corrections are not going to be small changes to alignments ('microscopic changes')" )
( henrySimon_01309 "They're really going to be looking for gross errors such as bad misalignments, or speakers saying something that really doesn't match the text" )
( henrySimon_01310 "We're not going to consider this idea of manual correction here: it's too time-consuming and too expensive" )
( henrySimon_01311 "We're going to consider only a way of doing this fully automatically" )
( henrySimon_01312 "In other words, if the speaker deviated from the text in some way - such as inserting a pause where the front end didn't predict a pause - we're going to discover that completely automatically" )
( henrySimon_01313 "The way that we're going to do that is basically to do automatic speech recognition to transcribe the speech" )
( henrySimon_01314 "But this is much easier than full-blown speech recognition, because we know the word sequence" )
( henrySimon_01315 "Knowing the word sequence is basically like having a really, really good language model: very highly constrained" )
( henrySimon_01316 "In automatic speech recognition, we normally only want to recover the word sequence, because that's all we want to output" )
( henrySimon_01317 "But if you go back to look at the material on token passing, you'll realize that we can ask the tokens to remember anything at all while they're passing through the HMM states, not just the ends of words" )
( henrySimon_01318 "They could also remember the times (the frames) where they left each model: in other words, each phoneme" )
( henrySimon_01319 "Or we could ask them to remember when they left each state" )
( henrySimon_01320 "We could get model- or state-alignments trivially, just by asking the tokens to record these things as they make their way around the recognition network" )
( henrySimon_01321 "So the ingredients for a building forced aligner are basically exactly the same ingredients as for automatic speech recognition" )
( henrySimon_01322 "We need acoustic models, that is, models of the units that we want to align" )
( henrySimon_01323 "They're going to be phone-sized models" )
( henrySimon_01324 "We need a pronunciation model that links the word level to the phone level" )
( henrySimon_01325 "That's just going to be our pronunciation dictionary: the same one we already have for synthesis" )
( henrySimon_01326 "We might extend it in ways that we don't normally do for speech recognition, such as putting in pronunciation variation" )
( henrySimon_01327 "We're going to see in a moment that some rule-based variation, and specifically vowel reduction, is often built in" )
( henrySimon_01328 "And we need a language model" )
( henrySimon_01329 "That doesn't need to be a full-blown N-gram" )
( henrySimon_01330 "We don't need coverage" )
( henrySimon_01331 "What we need is just a model of the current word sequence for the current sentence" )
( henrySimon_01332 "That's a very simple language model" )
( henrySimon_01333 "In fact, the language model will be different for every sentence: we'll switch the language model in and out as we're aligning each sentence" )
( henrySimon_01334 "One thing we might do is add optional silences between the words" )
( henrySimon_01335 "We'll come back to exactly how to train the acoustic models in a moment" )
( henrySimon_01336 "Let's assume we have a set of fully-trained phone models for now, and see what the language model looks like" )
( henrySimon_01337 "Let's write the simplest language model we can think of" )
( henrySimon_01338 "Here's the sentence we asked the speaker to say" )
( henrySimon_01339 "So that's what we're going to force align to the speech that they produced" )
( henrySimon_01340 "It's a finite state language model" )
( henrySimon_01341 "The states are these words, and we just join them up with arcs, with an end state and a start state" )
( henrySimon_01342 "That's a finite state language model" )
( henrySimon_01343 "We're going to compile that together with the acoustic model and pronunciation model to make our recognition network, do token passing, and ask the tokens to record when they left every single state or phone, depending what alignment we want" )
( henrySimon_01344 "That will get forced alignment for us" )
( henrySimon_01345 "That was the language model" )
( henrySimon_01346 "The next ingredient is a pronunciation model that maps the words in the language model to phones, of which we have HMMs" )
( henrySimon_01347 "Our pronunciation model is basically a dictionary" )
( henrySimon_01348 "It maps words - such as this word - to pronunciations, such as this" )
( henrySimon_01349 "We're going to add a little rule-based pronunciation variation: we're going to allow every vowel to be reduced to schwa" )
( henrySimon_01350 "We'll write out our finite state pronunciation model of the word "can", add arcs, and optionally, instead of the full vowel, we could generate a reduced vowel" )
( henrySimon_01351 "So here's our finite state network model of the pronunciation of the word /k ae n/, but it can also be reduced to /k ax n/" )
( henrySimon_01352 "I can say "What can [k ae n] it do for" )
( henrySimon_01353 "" or "What can [k ax n] it do for" )
( henrySimon_01354 "" This recognition network can align either of those variants" )
( henrySimon_01355 "The third and final ingredient is the acoustic model, that's going to actually emit observations" )
( henrySimon_01356 "We could borrow fully-trained models from an existing speech recognition system, for example speaker-independent models, although actually in practice we do tend to get better results with rather simpler models which we can make speaker-dependent, because we can train them on the same data that we're aligning" )
( henrySimon_01357 "We might have thousands or tens of thousands of sentences, which is plenty of data to train context-independent phone models" )
( henrySimon_01358 "Now, you might be shouting out at this point that training the models on the same data we're aligning is cheating!" )
( henrySimon_01359 "That's not true" )
( henrySimon_01360 "We're not really doing recognition: we're doing alignment" )
( henrySimon_01361 "The product is not the word sequence, it's just the timestamps" )
( henrySimon_01362 "So there's no concept of a split between training and testing here" )
( henrySimon_01363 "We've just got data" )
( henrySimon_01364 "We train models on the data and then find the alignment between the models and the data" )
( henrySimon_01365 "It's that alignment that we want, not the word sequence" )
( henrySimon_01366 "Those were our ingredients for forced alignment: a language model, a pronunciation model and an acoustic model" )
( henrySimon_01367 "We saw how the language model is just derived from the sentences that we ask the speaker to read" )
( henrySimon_01368 "We saw how the pronunciation model was simply the dictionary from our speech synthesizer with some rule-based vowel reduction" )
( henrySimon_01369 "If our dictionary was more sophisticated and had full pronunciation variation capabilities, that could be expressed in a finite state form and would become part of the alignment network" )
( henrySimon_01370 "The other remaining ingredient to build is the acoustic model" )
( henrySimon_01371 "So how can we train our acoustic models on the recorded speech data?" )
( henrySimon_01372 "Well it's no different to building any other speech recognition system" )
( henrySimon_01373 "We know the word transcriptions of all the data and we have an alignment at sentence boundaries between the transcriptions and the speech" )
( henrySimon_01374 "If all you know about automatic speech recognition is how to use whole word models, then you might think that we need to align the data at the word level before we can train the system" )
( henrySimon_01375 "But think again: when we train whole word models such as in the "Build your own digit recognizer" exercise, those word models have many states and we did not need to align the states to the speech" )
( henrySimon_01376 "So, building a speech recognition system never needs state-level alignments" )
( henrySimon_01377 "That we're very tedious to try and do by hand" )
( henrySimon_01378 "I've no idea how you would do that" )
( henrySimon_01379 "We can generalize the idea of not needing state-level alignments to not needing model- or word-level alignments" )
( henrySimon_01380 "That's easy, in fact" )
( henrySimon_01381 "We just take our sub-word models (say, phone models) and we concatenate them together to get models of words, and then we concatenate word models to get a model of a sentence" )
( henrySimon_01382 "We get a great, big, long HMM" )
( henrySimon_01383 "We know that the beginning of the HMM aligns with the beginning of the audio, and the end of the HMM aligns with the end of the audio" )
( henrySimon_01384 "Training that big, long HMM is no different to training a whole word model on segmented data" )
( henrySimon_01385 "Using data where we just have a word transcription that's only aligned at the sentence level is so important and is the standard way of training an automatic speech recognition system, it comes with a special name" )
( henrySimon_01386 "It's called "flat start training"" )
( henrySimon_01387 "Let's see how flat start training is just a generalization of what we already know about speech recognition" )
( henrySimon_01388 "Let's pretend for a moment that these HMMs here are whole word models" )
( henrySimon_01389 "They're models of digits" )
( henrySimon_01390 "In the exercise to "Build your own digit recognizer", we needed to know that the beginning of this model aligned with the speech and where the end of the model aligned with the speech" )
( henrySimon_01391 "Then, given this set of observations, we could train the model of "one" and the same for all the other digits" )
( henrySimon_01392 "So we essentially had isolated digit training data" )
( henrySimon_01393 "We just generalise that idea" )
( henrySimon_01394 "This HMM now is an HMM of this little phrase" )
( henrySimon_01395 "We know the start aligns with the start of the audio, the end aligns with the end of the audio" )
( henrySimon_01396 "We just do exactly the same sort of training to train this long model from this long observation sequence" )
( henrySimon_01397 "That extends out to a whole sentence" )
( henrySimon_01398 "Right, we've got all the ingredients then: a language model constructed from the sentences we know; a pronunciation model from the dictionary, plus rules; acoustic models created with this thing called flat start training" )
( henrySimon_01399 "Let's just make our language model a little bit more sophisticated, to accommodate variations that the speaker might make that our front end doesn't predict, and that is inserting pauses between words" )
( henrySimon_01400 "This speaker has inserted a pause between these two words" )
( henrySimon_01401 "Perhaps our front end didn't predict a pause in that situation" )
( henrySimon_01402 "The way that we do that is to insert an additional acoustic model at every word juncture, that's a model of optional silence" )
( henrySimon_01403 "This model's just an HMM" )
( henrySimon_01404 "So it's got a state, it's got a self-transition, it's got a start and an end non-emitting state (because we're using HTK)" )
( henrySimon_01405 "That's just a 1-state HMM that can emit observations" )
( henrySimon_01406 "As it stands there, it must emit at least one observation to get from the start to the end" )
( henrySimon_01407 "We'd like to be able to emit no observations so that we have optionality, in other words it can have zero duration" )
( henrySimon_01408 "We can do that just by adding this extra transition, like this" )
( henrySimon_01409 "This skip transition has given us a model of optional silence" )
( henrySimon_01410 "This state here is going to contain a Gaussian or Gaussian mixture model that emits observations with an appropriate distribution for silence" )
( henrySimon_01411 "So we need to train this model" )
( henrySimon_01412 "It's not obvious how to train this model, because we don't know where these optional silences are" )
( henrySimon_01413 "But what we do know is that there's silence at the beginning and the end of the sentence and we're going to have a 'long silence' model to deal with those" )
( henrySimon_01414 "So we're always going to have our traditional (perhaps 3-state) silence model" )
( henrySimon_01415 "This 3-state silence model (we'll typically call it silence, or something like that)" )
( henrySimon_01416 "This model here, we're going to call 'sp' and there's an easy way to initialize the parameters of the state of this model and it's just to tie them to the centre state of this model, which will be easier to train because we'll always have a few 100 ms of silence at the beginning and end of every sentence that we recorded in the studio" )
( henrySimon_01417 "So that's a little trick to get us an optional short pause model and to train it easily by tying it to our main silence model" )
( henrySimon_01418 "Right, let's do some speech recognition!" )
( henrySimon_01419 "We're going to do it in the only way we know how: that's the way that HTK does it in its simple HVite tool" )
( henrySimon_01420 "That's to compile together language model, pronunciation model, and acoustic model into a single finite state network, and then do token passing" )
( henrySimon_01421 "Let's start with the language model" )
( henrySimon_01422 "There's a language model: that's finite state" )
( henrySimon_01423 "Let's just remind ourselves: it's got arcs and states like this" )
( henrySimon_01424 "We'll compile this model with the pronunciation model, which essentially means replacing each word with its sub-word units" )
( henrySimon_01425 "That's this model here" )
( henrySimon_01426 "Again, remember these are all finite state and there are arcs joining all of those together" )
( henrySimon_01427 "I won't draw them in, just to keep things neat" )
( henrySimon_01428 "We can now enhance that with those two little tricks" )
( henrySimon_01429 "One was to allow every vowel to be reduced, so it's optional vowel reduction" )
( henrySimon_01430 "The other was to put this special short pause model at every word juncture, in case speakers put pauses where our front-end didn't predict it in the phone sequence" )
( henrySimon_01431 "So we add some more nodes in the network for that, and now we can draw the arcs in to see how this finite state network looks" )
( henrySimon_01432 "Let's draw the arcs on the network" )
( henrySimon_01433 "I'll omit the arrows (they all flow from left to right, of course)" )
( henrySimon_01434 "So each word could have its canonical pronunciation, like this" )
( henrySimon_01435 "Or it has, optionally, vowel reduction like this" )
( henrySimon_01436 "Between words we always go through the short pause model, which can emit zero or more frames of silence" )
( henrySimon_01437 "The word can have its canonical full pronunciation, or the vowel can be reduced" )
( henrySimon_01438 "We go through the short pause model" )
( henrySimon_01439 "That's already a schwa, so can't be reduced any further" )
( henrySimon_01440 "Again the canonical pronunciation, or reduce the vowel" )
( henrySimon_01441 "The optional short pause model at the word juncture" )
( henrySimon_01442 "The canonical pronunciation or the vowel reduction" )
( henrySimon_01443 "Then we end" )
( henrySimon_01444 "On this network here, we just do token passing" )
( henrySimon_01445 "Let's imagine a route that the token might take" )
( henrySimon_01446 "We might say "There" )
( henrySimon_01447 "" - may be we left a pause, maybe we didn't - the number of frames we spend here will tell us if there was any silence" )
( henrySimon_01448 "we maybe reduce this vowel" )
( henrySimon_01449 "maybe we say this with its full pronunciation" )
( henrySimon_01450 "and this with its full pronunciation" )
( henrySimon_01451 "This token would remember its state sequence and its model sequence and would let us recover the timestamps" )
( henrySimon_01452 "In other words, we'd know the time that we left each of these phone models" )
( henrySimon_01453 "We'll repeat that for every sentence in the database with our fully-trained models, that have been acquired using flat start training" )
( henrySimon_01454 "What we now have then is a phonetic sequence with timestamps" )
( henrySimon_01455 "We know the start and end times of every segment" )
( henrySimon_01456 "That's not enough" )
( henrySimon_01457 "We need to attach supra-segmental information to that" )
( henrySimon_01458 "Here's what our speaker said" )
( henrySimon_01459 "Here's the phonetic sequence from forced alignment We're going to attach that to all the supra-segmental information" )
( henrySimon_01460 "We're just going to get the supra-segmental information from the text, using the front-end" )
( henrySimon_01461 "We're not going to do any alignment or modifications to try and make it match what the speaker said" )
( henrySimon_01462 "We'll just take the predictions from the front end" )
( henrySimon_01463 "That's a little bit simplistic: we might imagine we could do better than that by, for example, hand-labelling prosody (if we think we can do that accurately" )
( henrySimon_01464 ")" )
( henrySimon_01465 "But the simple method actually works quite well and it's the standard way of building voices when we use Festival, for example" )
( henrySimon_01466 "This level was the force-aligned phone sequence" )
( henrySimon_01467 "It's got timestamps" )
( henrySimon_01468 "This was the canonical sequence from the front end" )
( henrySimon_01469 "You just take the timestamps off one and transfer them to the other" )
( henrySimon_01470 "Those sequences are not identical, but they're very similar, so we can make that transfer and in doing so we can also add in the short pauses where they existed, and we can mark which vowels got reduced by the speaker when he or she said this sentence" )
( henrySimon_01471 "If we looked inside the Festival utterance structure after all of this process, we'd see that some timestamps had appeared on it" )
( henrySimon_01472 "That concludes our look at databases: what to put in the recording script; how to annotate that speech once we've recorded in the studio" )
( henrySimon_01473 "Unit selection then is just retrieval of candidates from that labelled database, followed by a search" )
( henrySimon_01474 "Now we have a full working speech synthesizer" )
( henrySimon_01475 "Hopefully you're doing the exercise at the same time" )
( henrySimon_01476 "You've built that voice and listened to it and so you're asking yourself now, "How good is that synthetic voice?" We need to evaluate that, so the topic of the next module will be evaluation" )
( henrySimon_01477 "We'll think about what are fair means to evaluate it" )
( henrySimon_01478 "Of course we should listen to it ourselves: that's going to be helpful! We probably want to ask other people to listen to it, so we can get multiple listeners for a bit more reliability" )
( henrySimon_01479 "Maybe we can measure some objective properties of the speech to decide how good it is?" )
( henrySimon_01480 "But, in general, we need to have a good think about what do we want to measure and why exactly do we want to do evaluation" )
( henrySimon_01481 "So the questions we're going to answer in the next module are: Can we judge how good a synthetic voice is in isolation? Or, is it only possible to do that by comparing to some other system that's better or worse than it?" )
( henrySimon_01482 "We'll answer the question about who should be listening to the speech, and whether it should be us or other listeners, or indeed some algorithms (some objective measures)" )
( henrySimon_01483 "All of those have advantages and disadvantages and we'll consider those" )
( henrySimon_01484 "We'll think in detail about exactly what aspects of the speech we want to measure and put quantities on: Is it naturalness?" )
( henrySimon_01485 "Is it how intelligible the speech is? Or is there something else we can measure?" )
( henrySimon_01486 "In this module, we're going  to talk about evaluation" )
( henrySimon_01487 "We'll start right at the beginning" )
( henrySimon_01488 "Think about why we even need to evaluate" )
( henrySimon_01489 "What we're going to do with the result of that" )
( henrySimon_01490 "That will help us think about  when it's appropriate to evaluate" )
( henrySimon_01491 "Do we do that while we're building a system? Do we wait until we're finished?" )
( henrySimon_01492 "There are many aspects of a system" )
( henrySimon_01493 "We might evaluate its internal components,   its reliability, or speed" )
( henrySimon_01494 "But we are mainly going to   focus on the more obvious speech synthesis  evaluation, which is to listen to the speech   and make some judgements, perhaps about  its naturalness and its intelligibility" )
( henrySimon_01495 "Once we have established those things, we'll  move on to thinking about exactly how to do that" )
( henrySimon_01496 "How do you evaluate? In that section,   we will look at methodologies for evaluation" )
( henrySimon_01497 "How we present the stimuli to listeners" )
( henrySimon_01498 "Who those listeners might be" )
( henrySimon_01499 "What the stimulus should be" )
( henrySimon_01500 "And some other aspects of experimental design" )
( henrySimon_01501 "And once we've finished evaluation, we  need to do something with what we've found" )
( henrySimon_01502 "So, what do we do with the  outcome of an evaluation?" )
( henrySimon_01503 "Before you look at this module, you should just  check that you already know the following things" )
( henrySimon_01504 "Of course, you should have a pretty  good understanding of the complete   process of text to speech synthesis by this point" )
( henrySimon_01505 "And because you've got that understanding, you  should have some ideas about where errors can come   from, why synthetic speech is not perfect" )
( henrySimon_01506 "For example, in the front end,   things might go wrong very early in text normalisation,   the wrong words are said" )
( henrySimon_01507 "Pronunciations could be incorrect:   letter-to-sound could go wrong" )
( henrySimon_01508 "And other things like prosody could be wrong" )
( henrySimon_01509 "Things will also go wrong  when we generate the waveform" )
( henrySimon_01510 "Let's just think about unit  selection in this section" )
( henrySimon_01511 "Unit selection errors might be that the units we  chose were from inappropriate contexts" )
( henrySimon_01512 "So they have the wrong  co-articulation, for example" )
( henrySimon_01513 "Or they might not have joined very well" )
( henrySimon_01514 "We'll get concatenation artefacts To have a good understanding of why people  hear some errors but not other errors,   it will be useful to go and  revise your acoustic phonetics   and make sure you know a little  bit about speech perception" )
( henrySimon_01515 "Different errors will lead to  different perceptual consequences" )
( henrySimon_01516 "They'll impact different  aspects of the synthetic speech" )
( henrySimon_01517 "Some things are going to obviously affect  the naturalness of the synthetic speech" )
( henrySimon_01518 "It will sound unnatural in  some way: unnatural prosody,   unnatural signal quality  because of concatenation, perhaps" )
( henrySimon_01519 "Other types of errors might in fact affect intelligibility" )
( henrySimon_01520 "An obvious one there is: if text normalisation goes  wrong - the synthesiser says the wrong words   and the listener understands the wrong thing" )
( henrySimon_01521 "But intelligibility could also be impacted by   audible joins that disrupt the listener's perception" )
( henrySimon_01522 "So both naturalness and intelligibility  can be affected by things that happen   in the front end and in waveform generation" )
( henrySimon_01523 "We're going to see that's a general trend   in evaluation: that we might be able to measure  something in the synthetic speech, but that thing   that we measure doesn't have a direct connection  back to only one property of the system" )
( henrySimon_01524 "We have to figure out that for ourselves" )
( henrySimon_01525 "And that's one reason it's rather hard   to automatically optimise the system  based on the results a listening test" )
( henrySimon_01526 "Because you can't feed back the  results of that listening test   down into the insides of the system and say,  "This error was because of letter-to-sound"" )
( henrySimon_01527 "Now, before we just jump in and  try and evaluate synthetic speech,   let's sit down and think  very carefully about that" )
( henrySimon_01528 "We're going to be a little bit systematic" )
( henrySimon_01529 "We're not just going to make some synthetic   speech, play it to listeners  and see what they think" )
( henrySimon_01530 "We're going to make a plan" )
( henrySimon_01531 "We're going to start right   back at the beginning, thinking: "Why do we want to evaluate?"  "What is it that we want to  get out of that evaluation?" Most of the time, we're trying to learn  something for ourselves that will help us   make our system better" )
( henrySimon_01532 "We're trying to guide   the future development of the system" )
( henrySimon_01533 "When we think we've got a pretty good system,   we might then go out and compare it somebody  else's system and hope that we're better" )
( henrySimon_01534 "Maybe then we can publish a paper" )
( henrySimon_01535 "Our technique is an  improvement over some baseline" )
( henrySimon_01536 "If we're going to sell this  thing, we might simply want to say   it's good enough to put in front of customers  and that'll be just a simple pass-fail decision" )
( henrySimon_01537 "Depending on our goals, we might then need to  decide when we're going to do that evaluation" )
( henrySimon_01538 "If it's to improve our own system,  we might do it fairly frequently" )
( henrySimon_01539 "It might be during development" )
( henrySimon_01540 "That might be of individual components,   or the end-to-end system,  depending what we want to learn" )
( henrySimon_01541 "Assuming that it's the synthetic speech we're  going to evaluate rather than the performance of   some component of the system, we have to think: "What is it about speech that we   could actually measure?" Some obvious things will be:  Can you understand what was said? Did it sound something like natural speech?  Maybe less obviously, and something that'll become  a lot more clear when we move on to parametric   forms of synthesis, is speaker similarity" )
( henrySimon_01542 "Because there's no guarantee that the synthetic   speech sounds like the person  that we want it to sound like" )
( henrySimon_01543 "Then, having established all  of that, we'll get to the meat" )
( henrySimon_01544 "We'll think about how to evaluate" )
( henrySimon_01545 "We'll think about what we're going   to ask our listeners to do" )
( henrySimon_01546 "We're going to design a task" )
( henrySimon_01547 "Put that into some test design, which  includes the materials we should use on" )
( henrySimon_01548 "We'll think about how to measure the listeners'  performance on that task, with those materials" )
( henrySimon_01549 "We'll also quite briefly mentioned  the idea of objective measures" )
( henrySimon_01550 "In other words, measures that don't need  a listener - measures that are in fact an   algorithm operating on the synthetic speech" )
( henrySimon_01551 "For example, comparing it to a natural  example and measuring some distance" )
( henrySimon_01552 "When you've done all of that, you need  to then make a decision what to do next" )
( henrySimon_01553 "For example, how do we improve our system,  knowing what we've learned in the listening test?  So what do we do with the outcome of  listening test or some other evaluation?" )
( henrySimon_01554 "So on to the first of those  in a bit more detail, then" )
( henrySimon_01555 "Why do we need to evaluate it all?  It's not always obvious, because it's  something that's just not spelled out ever" )
( henrySimon_01556 "I was never taught this explicitly, and  I've never seen it really in a textbook" )
( henrySimon_01557 "But why do we evaluate? Well, it's to make decisions" )
( henrySimon_01558 "Imagine I have basic system" )
( henrySimon_01559 "I've taken the Festival speech synthesis system" )
( henrySimon_01560 "I've had four brilliant ideas  about how to make it better" )
( henrySimon_01561 "I've built four different variations on Festival,  each one embodying one of these brilliant ideas" )
( henrySimon_01562 "Now I'd like to find out which  of them was the best idea" )
( henrySimon_01563 "So I'll generate some examples from those systems" )
( henrySimon_01564 "I'll make my evaluation" )
( henrySimon_01565 "There was some outcome from that" )
( henrySimon_01566 "The outcome helps me make a decision" )
( henrySimon_01567 "Which of those ideas was best?" )
( henrySimon_01568 "Let's imagine that the idea in  this system was a great idea" )
( henrySimon_01569 "So perhaps I'll drop the other ideas" )
( henrySimon_01570 "I'll take this idea, and I'll make some further   enhancements to it - some more variants on it" )
( henrySimon_01571 "So I'll make some new systems in   this evolutionary way" )
( henrySimon_01572 "You have now got another   bunch of systems you would like to evaluate" )
( henrySimon_01573 "I had again four ideas (it's a magic number!)" )
( henrySimon_01574 "And again, I'd like to find out  which of those was the best idea" )
( henrySimon_01575 "Again, we'll do another evaluation, and perhaps  one of those turns out to be better than the rest" )
( henrySimon_01576 "And I'll take that idea forward and  the other ideas will stay on the shelf" )
( henrySimon_01577 "And so research is a little bit like this   greedy evolutionary search" )
( henrySimon_01578 "We have an idea" )
( henrySimon_01579 "We compare it to our other ideas" )
( henrySimon_01580 "We pick the best of them" )
( henrySimon_01581 "We take that forward and refine it and  improve it until we can't make it any better" )
( henrySimon_01582 "Evaluation is obviously playing a critical role  in this because it's helping us to make the   decision that this was the best, and this was the  best, and that the route our research should take   should be like this, not some other path" )
( henrySimon_01583 "So that's why we need to evaluate" )
( henrySimon_01584 "You could do these evaluations  at many possible points in time" )
( henrySimon_01585 "If we're building a new front end for a language  or trying to improve the one we've already got,   we'll probably do a lot of testing  on those isolated components" )
( henrySimon_01586 "For example, we might have a module  which does some normalisation" )
( henrySimon_01587 "We're going to put a better part of speech tagger in, or  the letter-to-sound model might have got better,   or we might have improved the dictionary" )
( henrySimon_01588 "We might be able to - in those cases - do some   sort of objective testing against Gold Standard  data: against things we know, with labels" )
( henrySimon_01589 "That's just normal machine learning  with a training set and the test set" )
( henrySimon_01590 "But we also might want to know what the  effect of those components is when they   work within a complete system" )
( henrySimon_01591 "Some components, of course,   only make sense in a complete system, such  as the thing that generates a waveform" )
( henrySimon_01592 "We have to look at the waveforms (i" )
( henrySimon_01593 "e" )
( henrySimon_01594 ", listen  to the waveforms) to know how good they are" )
( henrySimon_01595 "We're not going to say too much more about  evaluating components - that's better covered when   we're talking about how these components work" )
( henrySimon_01596 "We really going to focus on complete systems" )
( henrySimon_01597 "We're not in industry here, so we're not  going want to know: Did Does it pass or fail?  We really going to be concentrating  on comparing between systems" )
( henrySimon_01598 "Now, there might be two of our own systems,  like the four variants of my great ideas" )
( henrySimon_01599 "They might be against the baseline - an  established standard - that's just Festival" )
( henrySimon_01600 "They might be competitive against other people   as in, for example, the Blizzard  Challenge evaluation campaigns" )
( henrySimon_01601 "Now, when we're making those  comparisons between variants of systems,   we need to be careful to control  things so that when we have a winner,   we know the reason was because of our  great idea, not some other change" )
( henrySimon_01602 "We made two in the Blizzard Challenge, and  indeed, in all sorts of internal testing   we'll keep certain things under control" )
( henrySimon_01603 "For example, we'll keep the same front end, and   we'll keep the same database if we're trying to  evaluate different forms of waveform generation" )
( henrySimon_01604 "So we're already seeing some  aspects of experimental design" )
( henrySimon_01605 "We need to be sure that the only difference  between the systems is the one we're interested in   and everything else is controlled so that - when  we get our outcome - we know the only explanation   is the variable of interest and  not some other confounding thing" )
( henrySimon_01606 "Like, we change the database" )
( henrySimon_01607 "Now there's a whole lot of terminology flying  around testing, whether it's software testing   or whole system testing, whatever it might be,  we're not really going to get bogged down in it" )
( henrySimon_01608 "But let's just look at a couple of  things that come up in some textbooks" )
( henrySimon_01609 "Sometimes we see this term: "glass box"" )
( henrySimon_01610 "That means we can look inside the   system that we're testing" )
( henrySimon_01611 "We have complete access to it" )
( henrySimon_01612 "We could go inside the code" )
( henrySimon_01613 "We could even put changes into the code   for the purposes of testing" )
( henrySimon_01614 "This kind of testing is   normally about things like reliability and  speed to make sure the system doesn't crash,   make sure it runs fast enough to be usable" )
( henrySimon_01615 "We're really not going to talk much about that" )
( henrySimon_01616 "If we wanted to, we could go look at source code" )
( henrySimon_01617 "For example, in this piece of source code,   we can see who wrote it, so there's a  high chance there might be a bug here" )
( henrySimon_01618 "We might put in specific tests unit tests  to check that there are no silly bugs" )
( henrySimon_01619 "Put in test cases with known correct  output and compare against them" )
( henrySimon_01620 "Coming back to this terminology, we'll  sometimes see this term: "black box"" )
( henrySimon_01621 "This is now when we're not allowed to  look inside and see how things work" )
( henrySimon_01622 "We can't change the code for  the purpose of testing it" )
( henrySimon_01623 "All we could do is put  things in and get things out" )
( henrySimon_01624 "So to measure performance, we can maybe get some  objective measures against gold standard data" )
( henrySimon_01625 "That will be the sort of thing we  might do for a Part-Of-Speech tagger" )
( henrySimon_01626 "One would hope that making an improvement  anywhere in the system would lead to an   improvement in the synthetic speech" )
( henrySimon_01627 "If only that was the case!  Systems like Text-to-Speech  synthesisers are complex" )
( henrySimon_01628 "They typically have something like a  pipeline architecture that propagates errors   and that can lead to very tricky  interactions between the components" )
( henrySimon_01629 "Those interactions can actually  mean that improving something   early in the pipeline actually causes  problems later in the pipeline" )
( henrySimon_01630 "In other words, making improvement  actually makes synthetic speech worse!" )
( henrySimon_01631 "Let's take some examples" )
( henrySimon_01632 "Imagine we fix a problem in text normalisation   so that currencies are now correctly normalised  whereas they used to be incorrectly normalised" )
( henrySimon_01633 "However, if we only do that in the run-time  system and don't change the underlying database,   we will now have a mismatch  between the database labels   and the content of what we try to say at run time" )
( henrySimon_01634 "We might get worse performance - for example,   lower naturalness - now,  because we have more joins" )
( henrySimon_01635 "Similarly, improving the letter-to-sound module  might start producing phoneme sequences which are   low frequency in the database, because the  database used the old letter-to-sound module,   which never produced those sequences" )
( henrySimon_01636 "So again, we will get more joins in our units" )
( henrySimon_01637 "So, in general then, these pipeline architectures,  which are the norm in Text-to-Speech,   can lead to unfortunate interactions" )
( henrySimon_01638 "And in general, of course, in all of software   engineering, fixing one bug can easily reveal  other bugs that you hadn't noticed until then" )
( henrySimon_01639 "Nevertheless, we're always going  to try and improve systems" )
( henrySimon_01640 "We want to improve those components,  but we might have to propagate those   improvements right through the pipeline" )
( henrySimon_01641 "We might have to completely rebuild the system   and re-label the database whenever we change,  for example, our letter-to-sound module" )
( henrySimon_01642 "So we know we need to evaluate: to make decisions,  for example, about where to go with our research" )
( henrySimon_01643 "We can do those evaluations for  components or the whole systems" )
( henrySimon_01644 "We decided when to do it" )
( henrySimon_01645 "And now, when you think about   what it is about speech that we could evaluate" )
( henrySimon_01646 "So we're now going to focus on  just synthetic speech evaluation   and forget about looking inside the system" )
( henrySimon_01647 "What aspects of speech could we possibly quantify?  There's lots of descriptors, lots of  words we could use to talk about this" )
( henrySimon_01648 "It's tempting to use the word "quality"" )
( henrySimon_01649 "That's a common term in speech coding" )
( henrySimon_01650 "For transmission down telephone systems we  talk took about the "quality" of the speech" )
( henrySimon_01651 "That's a little bit of a vague  term for synthetic speech,   because there are many different dimensions" )
( henrySimon_01652 "So tend not to talk about that [quality] so much" )
( henrySimon_01653 "Rather, we use the term naturalness" )
( henrySimon_01654 "Naturalness, implies some similarity to  natural speech from a real human talker" )
( henrySimon_01655 "In general, it's assumed that that's  what we're aiming for in Text-to-Speech" )
( henrySimon_01656 "I would also like that  speech to be understandable" )
( henrySimon_01657 "And there's a load of different terms you  could use to talk about that property,   the most common one is "intelligibility"" )
( henrySimon_01658 "That's simply the ability of a listener to recall,   or to write down, the words that he or she heard" )
( henrySimon_01659 "We might try and evaluate some higher level   things, such as understanding or comprehension,  but then we're going to start interacting with   things like the memory of the listener" )
( henrySimon_01660 "So we're going to start measuring   listener properties when really we want to  measure our synthetic speech properties" )
( henrySimon_01661 "Occasionally we might measure speaker similarity" )
( henrySimon_01662 "As I've already mentioned, in the parametric   synthesis case, it's possible to produce  synthetic speech that sounds reasonably natural,   is highly intelligible, but doesn't sound  very much like the person that we recorded" )
( henrySimon_01663 "That sometimes matters" )
( henrySimon_01664 "It doesn't always matter,   so there's no reason to evaluate  that unless you care about it" )
( henrySimon_01665 "And there's a whole lot of other  things you might imagine evaluating" )
( henrySimon_01666 "Go away and think about what they might be  and then put them into practise yourself" )
( henrySimon_01667 "You are going evaluate synthetic speech along a  dimension that's not one of the ones on this slide and see if you can find something  new that you could measure" )
( henrySimon_01668 "We're no longer going to consider these things" )
( henrySimon_01669 "They will be straightforward to measure" )
( henrySimon_01670 "You could do those in experiments for yourself" )
( henrySimon_01671 "You could consider how pruning affects speed and how that trades off against,  for example, naturalness" )
( henrySimon_01672 "Now, even these simple descriptors  are probably not that simple" )
( henrySimon_01673 "And in particular, it seems to me that  naturalness is not a single dimension" )
( henrySimon_01674 "We could imagine speech that's segmentally natural  - the phonemes have reproduced nicely- but it's   prosodically unnatural" )
( henrySimon_01675 "Or vice versa" )
( henrySimon_01676 "So naturalness might need unpacking,  but the convention in the field is to   give that as an instruction to the listener:  "Please rate the naturalness  of the synthetic speech" )
( henrySimon_01677 ""  and assume that they can do that  along a 1-dimensional scale" )
( henrySimon_01678 "Similarly, intelligibility is usually defined  as the ability to transcribe what was said,   but there might be more to listening to synthetic  speech than just getting the words right" )
( henrySimon_01679 "You might like to think about whether somebody  really understood the meaning of the sentence" )
( henrySimon_01680 "Managed to transcribe the words,  but if the prosody was all wrong,   they might have understood a different meaning" )
( henrySimon_01681 "More generally, we might think about how much   effort it is to listen to synthetic speech" )
( henrySimon_01682 "It seems a reasonable hypothesis that it's   hard work listening to synthetic  speech compared to natural speech" )
( henrySimon_01683 "There are methods out there to try and  probe people's effort or attention,   or all sorts of other factors" )
( henrySimon_01684 "We have measured things about their pupils" )
( henrySimon_01685 "Sticking electrodes on their scalp to  measure things about their brain activity" )
( henrySimon_01686 "These are very much research tools" )
( henrySimon_01687 "They're not widely used in  synthetic speech evaluation" )
( henrySimon_01688 "The reason for that is that is then very hard to  separate out measuring things about the listener   from things about the synthetic speech" )
( henrySimon_01689 "And so there's a confound there" )
( henrySimon_01690 "For example, we're measuring the listeners working  memory, not how good the synthetic speech was" )
( henrySimon_01691 "So at the moment these things are not widely used" )
( henrySimon_01692 "It would be nice to think that we could use them  to get a deeper understanding of synthetic speech" )
( henrySimon_01693 "But that's an open question" )
( henrySimon_01694 "So I put that to one side" )
( henrySimon_01695 "For now, let's wrap this  section up with a quick recap" )
( henrySimon_01696 "We know why we should evaluate to  find stuff out and make decisions" )
( henrySimon_01697 "We could do it at various  points: and you need to choose" )
( henrySimon_01698 "And we've listed initially some aspects of  the the system, specifically of this speech,   that we could measure" )
( henrySimon_01699 "So from this point on in the next video,  we're going to focus on the mainstream" )
( henrySimon_01700 "What's normal in the field? What would be expected if you wanted to publish   a paper about your speech synthesis research? We're going to evaluate the output   from a complete system" )
( henrySimon_01701 "Are we going to do that   for an end-to-end Text-to-Speech  system: text in, synthetic speech out" )
( henrySimon_01702 "We're going to measure the two  principal things that we can:   the naturalness and the intelligibility" )
( henrySimon_01703 "And so what we need to do now is find out how" )
( henrySimon_01704 "So now on to how to do the evaluation" )
( henrySimon_01705 "There's two main forms of evaluation" )
( henrySimon_01706 "Subjective, in which we use human beings as listeners" )
( henrySimon_01707 "And their task involves listening to synthetic speech and doing something, making some response" )
( henrySimon_01708 "So we're going to look at how to design a test of that form, including things such as what materials you would use" )
( henrySimon_01709 "The other form of evaluation, something called objective and that would use some algorithms, some automated procedure to evaluate the synthetic speech without the need for listeners" )
( henrySimon_01710 "That's a very attractive idea because using listeners can be slow, expensive and just inconvenient to recruit people and get them to listen to your synthetic speech" )
( henrySimon_01711 "However, objective measures are far from perfect, but they're currently not a replacement for subjective evaluation" )
( henrySimon_01712 "We'll look at a couple of forms off objective measure just in principle, not in huge detail" )
( henrySimon_01713 "The most obvious idea would be to take some natural speech and measure somehow the difference - the distance between your synthetic speech and this reference sample of natural speech on the assumption that the distance of zero is the best you can do, and then you're perfectly natural, or you could use something a bit more sophisticated" )
( henrySimon_01714 "You could try and model something about human perception, which isn't as simple as just a distance" )
( henrySimon_01715 "And we might need a model of perception to do that That's even harder" )
( henrySimon_01716 "And that's definitely a research topic and not a well established way of evaluating synthetic speech at this time" )
( henrySimon_01717 "So we'll focus on the subjective, in other words, the listening test" )
( henrySimon_01718 "So in subjective evaluation, the subjects are people sometimes called listeners" )
( henrySimon_01719 "And they're going to be asked to do something" )
( henrySimon_01720 "They're going to be given a task, and it's up to us what that task might be" )
( henrySimon_01721 "In all cases, it's going to be best if it's simple and obvious to the listener" )
( henrySimon_01722 "In other words, it doesn't need a lot of instruction because people don't read instructions" )
( henrySimon_01723 "We might just play pairs off samples of synthetic speech, perhaps from two different variants of our system, and just say, which one do you prefer? That's a forced choice pairwise preference test" )
( henrySimon_01724 "We might want more graded judgement than that For example, we might ask them to make a rating on a scale, maybe a Likert scale with a number of points on it" )
( henrySimon_01725 "Those points might be described" )
( henrySimon_01726 "Sometimes we just described the end points" )
( henrySimon_01727 "Sometimes it described all the points" )
( henrySimon_01728 "They'll listen to one sample and give a response here on a 1 to 5 scale that's very common for naturalness" )
( henrySimon_01729 "Their task might be to do something else, for example, to type in the words that they heard" )
( henrySimon_01730 "It's reasonable to wonder whether just anybody could do these tasks" )
( henrySimon_01731 "And so we might ask, Should we train the listeners in order to, for example, pay attention to specific aspects of speech? This idea of training is pretty common in experimental phonetics, where we would like the listeners to do something very specific to attend to a particular acoustic property" )
( henrySimon_01732 "But in evaluating synthetic speech, we're usually more concerned with getting a lot of listeners" )
( henrySimon_01733 "And if we want a lot of listeners and they're going to listen to a lot of material and we're going to repeat test many times, training listeners is a bit problematic" )
( henrySimon_01734 "It's quite time consuming, and we could be never certain that they've completely learned to do what we ask them to do" )
( henrySimon_01735 "So this is quite uncommon in evaluating synthetic speech" )
( henrySimon_01736 "The exception to that would be an expert listener" )
( henrySimon_01737 "For example, the linguist, the native speaker in a company listening to a system - a prototype system - and giving specific feedback on what's wrong with it" )
( henrySimon_01738 "But naive listeners, the one we can recruit on the street and pay to do our listening test in general would not be trained" )
( henrySimon_01739 "We'll just assume as, for example, as native speakers of the language, they were able to choose between two things and express a preference" )
( henrySimon_01740 "That such a simple, obvious task, they can do it without any further instructional training" )
( henrySimon_01741 "If we wanted a deeper analysis than simply a preference, an alternative to training the listeners is to give them what appears to be a very simple task and then you some sophisticated statistical analysis to untangle what they actually did and to measure, for example, on what dimensions they were making" )
( henrySimon_01742 "Those judgements about difference in this pairwise forced choice test" )
( henrySimon_01743 "Doing this more sophisticated analysis - here is something called multi-dimensional scaling, which projects the differences into a space and then we can interpret the axes - is not really mainstream" )
( henrySimon_01744 "It's not so common: by far and away the most common thing is to give a very obvious task and either pairwise or Likert scale type tasks or typing test for intelligibility" )
( henrySimon_01745 "These are what we're going to concentrate on So we've decided to give our listeners a simple and obvious task" )
( henrySimon_01746 "And now we need to think, how are they going to do on this task" )
( henrySimon_01747 "For example, are listeners able to give absolute judgements about naturalness played a single sample with no reference" )
( henrySimon_01748 "Are they going to reliably rate it always as a three out of five? If we think that's true, we could design the task that relies on this absolute nature of listeners judgments" )
( henrySimon_01749 "That's possibly not true for things like naturalness" )
( henrySimon_01750 "If you've just heard a very unnatural system and then a more natural system, your rating would be inflated by that" )
( henrySimon_01751 "So many times we might want to make a safer assumption that listeners make relative judgments and one way to be sure that they're always making relative judgments and to give some calibration to that is to include some references" )
( henrySimon_01752 "And the most obvious reference, of course, is natural speech itself" )
( henrySimon_01753 "But there are other references, such as a standard speech synthesis system that never changes as our prototype system gets better" )
( henrySimon_01754 "When we've decided then whether our listeners needs some help calibrating their judgments or whether they can be relied upon to give absolute, in other words, repeatable judgments every time with a need to present, stimulated them and get these judgments back" )
( henrySimon_01755 "And that needs an interface" )
( henrySimon_01756 "Very often that will be done in a Web browser so that we could do these tests online" )
( henrySimon_01757 "It needs to present the stimulus" )
( henrySimon_01758 "And it needs to obtain their response" )
( henrySimon_01759 "That's pretty straightforward" )
( henrySimon_01760 "So we decided to get let's say, relative judgments from listeners, present them with a reference stimulus, and then the things they've got to judge - get them to, for example, choose from a pull down menu from a five point scale and get their response back" )
( henrySimon_01761 "And what remains then, is how many samples to play them" )
( henrySimon_01762 "So how big to make the test" )
( henrySimon_01763 "And how many listeners to do this with? So I need to think about the size of the test" )
( henrySimon_01764 "And something that we might talk about as we go through these points in detail, but always keep in mind the listeners themselves" )
( henrySimon_01765 "Sometimes they're called subjects" )
( henrySimon_01766 "What type of listener are they? Maybe they should be native speakers" )
( henrySimon_01767 "Maybe it doesn't matter" )
( henrySimon_01768 "Where are we going to find them, while offering a payment is usually effective" )
( henrySimon_01769 "And importantly, how do we know that they're doing the job well? So, for example, when we failed to find any difference between two systems, is it because really there was no difference?" )
( henrySimon_01770 "Or is it because the listeners weren't paying attention? So we want some quality control and that would be built in to the test design as we're going through" )
( henrySimon_01771 "Let's examine each of those points in a little bit more detail and make them concrete with some examples of how they might appear to a listener by far and away" )
( henrySimon_01772 "The most common sort of listening test is one that attempts to measure the naturalness of the speech synthesiser" )
( henrySimon_01773 "And in this test, listeners hear a single stimulus in isolation, typically one sentence and then they give a judgement on that single stimulus, and then we take the average of those on DH" )
( henrySimon_01774 "We call that the mean opinion score" )
( henrySimon_01775 "Now, here we have to call this an absolute judgement because that score is on a scale of 1 to 5, and it's on a single stimulus" )
( henrySimon_01776 "It's not relative to anything else" )
( henrySimon_01777 "However, we must be very careful to not conflate two things It's absolute in the sense that it's all a single stimulus, and we expect the listener to be able to do that task without reference to some baseline or some top line" )
( henrySimon_01778 "However, that does not mean that if we repeat this task, another time will get exactly the same judgments" )
( henrySimon_01779 "So in other words, it's not necessarily repeatable, and it's certainly not necessary comparable across listening tests" )
( henrySimon_01780 "There's no guarantee of that" )
( henrySimon_01781 "I would have to design that in to understand To understand why there's this difference between the task being absolute in terms of the judgement the listener gives and the test not necessarily being repeatable or comparable: imagine we have a system that's quite good" )
( henrySimon_01782 "And we put it in the listening test and in the same listening test are some variants on that system, which all are all really, really bad, our "quite good" system is going to get good scores" )
( henrySimon_01783 "Maybe our listeners going to keep scoring four out of five because it's quite good" )
( henrySimon_01784 "It's not perfect, but it's quite good" )
( henrySimon_01785 "Let's imagine another version of the test" )
( henrySimon_01786 "We put exactly the same system in its still quite good, but it's mixed in with some other variants on the system, and they're also quite good" )
( henrySimon_01787 "In fact, it's really hard to tell the difference between them, so they're all somewhere in the middle" )
( henrySimon_01788 "It's very likely our listeners in that case, we'll just give everything three, which is halfway between one and five, because it's not really bad" )
( henrySimon_01789 "It's not really good" )
( henrySimon_01790 "They can't tell the difference between them" )
( henrySimon_01791 "So just give everything a score of three" )
( henrySimon_01792 "So we might get a different score for the same system, depending on the context around it In other words, listeners probably do recalibrate themselves according to what they've heard recently more elsewhere in the test" )
( henrySimon_01793 "We need to worry about that" )
( henrySimon_01794 "One solution to this problem of not being able to get truly absolute calibrated opinions from listeners is not to ask for them at all" )
( henrySimon_01795 "But I ask only for comparisons" )
( henrySimon_01796 "So ask only for relative judgments, so we'll give them multiple things to listen to, and the most obvious thing is two things, and we'll ask them to say which do they prefer" )
( henrySimon_01797 "If you want to capture the strength of the preference, you might also put in a don't care or equally natural or can't tell the difference sort of option" )
( henrySimon_01798 "And if they always to choose that, then we know that these systems are hard to tell apart" )
( henrySimon_01799 "That's optional" )
( henrySimon_01800 "We could just have two options" )
( henrySimon_01801 "A is better or B is better" )
( henrySimon_01802 "There are variations on this that aren't just pairwise forced choice so we might use more than two stimuli" )
( henrySimon_01803 "And we might include some references and might even hybridise rating and sorting" )
( henrySimon_01804 "We'll look a test in a moment that's called MUSHRA that attempts to take the best of the pairwise forced choice, which essentially relative and the MOS, which is essentially absolute and the idea of calibration by providing reference samples, putting all of that into a single test design that's intuitive for listeners and has some nice properties for us" )
( henrySimon_01805 "So mean opinion score is the most common by far, and that's because the most common thing we want to evaluate his naturalness" )
( henrySimon_01806 "So here's a typical interface" )
( henrySimon_01807 "It's got on audio player, in this case, the listener can listen as many times as they want, and it's got a way of giving the response" )
( henrySimon_01808 "Here is the pull down menu, but it could equally be boxes to tick, which is one option" )
( henrySimon_01809 "And here we can see that all the points along the scale are described and when they've done that, they submit their score and move on to the next sample" )
( henrySimon_01810 "If we're asking them to transcribe what they heard, maybe that the interface would look like this some way of playing the audio and a place to type in their text" )
( henrySimon_01811 "In this particular design they're only allowed to listen to the speech once" )
( henrySimon_01812 "And that's another design decision we have to to make: would their judgement change if they're allowed to listen many, many times" )
( henrySimon_01813 "Certainly they would take longer to do the test" )
( henrySimon_01814 "And other designs are possible" )
( henrySimon_01815 "We won't go into a lot of detail on this one, but we could ask for multiple judgments on the same stimulus that might be particularly appropriate if the stimulus is long" )
( henrySimon_01816 "For example, a paragraph from an audio book and we might try and get things that are not just naturalness, but maybe some of those sub-dimensions of naturalness" )
( henrySimon_01817 "And here are some examples on these scales and finally, that MUSHRA design, which is an international standard" )
( henrySimon_01818 "There's variants on it, but this is the official MUSHRA design" )
( henrySimon_01819 "We have a reference that we could listen to that would be natural speech" )
( henrySimon_01820 "And then we have a set of stimuli, that we have to listen to: in this test there are eight so we can see you can do a lot of samples side by side and for each of them, the user, the listener has to choose a score, but in doing so is also implicitly sorting the systems" )
( henrySimon_01821 "So it's a hybrid sorting on rating task" )
( henrySimon_01822 "MUSHRA builds in a nice form of quality control" )
( henrySimon_01823 "It instructs the listener that one of these eight stimulate is in fact the reference, and then they must give it a score of 100 and in fact, they're not allowed to move on to the next set until they do so" )
( henrySimon_01824 "So this forces them to listen to everything, and it gives some calibration" )
( henrySimon_01825 "We might also put a lower bound a bottom sample in that we know should always be worse than all of the systems that's known as the anchor, not obvious what that would be for synthetic speech, so it's not currently used" )
( henrySimon_01826 "But the idea of having this hidden reference is very useful because it both calibrates it provides a reference to listen to" )
( henrySimon_01827 "And it catches listeners who are not doing the task properly, so it some quality control and some calibration" )
( henrySimon_01828 "Now, this is definitely not a course on statistics" )
( henrySimon_01829 "And so we're not going to go into the nitty gritty of exactly how the size of a sample determines the statistical power that we would need to make confident statements" )
( henrySimon_01830 "Such as system A is better than system B, but what we can have is some pretty useful rules of thumb that we can use in all listening tests that we know from experience tends to lead to reliable results" )
( henrySimon_01831 "The first one is not to stress the listeners out too much on very definitely not to allow them to become bored because their judgments might change" )
( henrySimon_01832 "So a test duration of 45 minutes is actually really quite long, and we certainly wouldn't want to go beyond that" )
( henrySimon_01833 "We might actually go much smaller than that, and in online situations where we don't have control over the listeners, and they're listening situation where they're recruited via the Web" )
( henrySimon_01834 "We might prefer to have much, much shorter tasks" )
( henrySimon_01835 "Because one individual listener might be atypical - they might just hear synthetic speech in a different way, they might have different preferences to the population" )
( henrySimon_01836 "We don't want a single listener's responses to have an undue influence on the overall statistics" )
( henrySimon_01837 "And the only way to do that is to have a lot of different listeners" )
( henrySimon_01838 "I would say we need at least 20 listeners in any reasonable listening test, and preferably always more than that, maybe 30 or more" )
( henrySimon_01839 "The same applies to the material text that we synthesise and then play to listeners" )
( henrySimon_01840 "It's possible that one sentence is a typical favours one system over another, just out of luck" )
( henrySimon_01841 "And so again the only way to mitigate that is to use as many different sentences as possible" )
( henrySimon_01842 "And our test design might combine numbers of listeners and numbers of sentences as we're going to see in a bit, so the number of sentences might be determined for us by our number of systems And the number of listeners that we want to use" )
( henrySimon_01843 "Far and away the easiest thing to do in the listening test is to construct one listening test and then just to repeat the same test with many different listeners" )
( henrySimon_01844 "In other words, all listeners individually, each hear everything" )
( henrySimon_01845 "They all hear the same stimuli and the most we might do is to put them in a different random order for each listener" )
( henrySimon_01846 "That seems a great idea because it's going to be be simple to deploy and it's going to be balanced because all listeners hear hear all stimuli" )
( henrySimon_01847 "But there are two situations where it's not possible to do that" )
( henrySimon_01848 "One of them is obvious" )
( henrySimon_01849 "If we want to compare so many different systems and we sure we need many different texts, we simply can't fit all of that into a 45 minute test or a lot less" )
( henrySimon_01850 "So we would have to split that across multiple listeners" )
( henrySimon_01851 "But there's a more complex and much more important reason that we might not have a within subjects design, and that's because we might not want to play certain sequences or certain combinations of stimulus to the one listener, and that's because there might be effects off priming" )
( henrySimon_01852 "In other words having heard one thing the response with some other thing changes" )
( henrySimon_01853 "Or ordering, for example, if we hear a really good synthesiser, then a really bad synthesiser, the bad one's score will be even lower because of that ordering effect" )
( henrySimon_01854 "So if we worried about these effects we're going to have to have a different sort of design" )
( henrySimon_01855 "And that design is called between subjects" )
( henrySimon_01856 "On the essence of this design, is we form a virtual single subject from a group of people such that we can split the memory effect such that one thing heard by one listener can't possibly affect another thing heard by a different listener because they don't communicate with each other" )
( henrySimon_01857 "In other words, there's no memory carry over effect from listener to listener, so we can effectively make a virtual listener who doesn't have a memory" )
( henrySimon_01858 "In both designs, whether it's within subjects or between subjects, we can build various forms of quality control, and the simplest one is actually to deliberately repeat some items and make sure they give about the same judgement in the repeated case" )
( henrySimon_01859 "So to check listeners are consistent and not random" )
( henrySimon_01860 "One way to do that in a forced choice - a pairwise test - is simply to repeat a pair, ideally in the opposite order and in fact, in some pairwise listening tests" )
( henrySimon_01861 "Every pair, every A/B pair is played in the order, A followed by B and somewhere else in the test it's played as B followed by A so all pairs of repeated" )
( henrySimon_01862 "And then we look at the consistency across that to get a measure of how reliable our listening was" )
( henrySimon_01863 "We might use throwaway listeners who are very unreliable" )
( henrySimon_01864 "So I'm now going to explain one type of between subjects design that achieves a few very important goals" )
( henrySimon_01865 "The goals of the following that we have a set of synthesisers" )
( henrySimon_01866 "Here I've numbered them: 0 1 2 3 4" )
( henrySimon_01867 "So five synthesisers" )
( henrySimon_01868 "We would like them to each synthesize the same set of sentences" )
( henrySimon_01869 "We'd like those sentences to be heard by a set of listeners" )
( henrySimon_01870 "Here they're called subjects" )
( henrySimon_01871 "But there are some constraints" )
( henrySimon_01872 "We can't allow an individual subject to hear the same sentence more than once" )
( henrySimon_01873 "Now that means it's not possible for a single subject to do the whole listening test because that would involve hearing every sentence synthesised by all five synthesisers" )
( henrySimon_01874 "So what we do, we form groups of subjects, which are the rows of this square" )
( henrySimon_01875 "The square is called a Latin square" )
( henrySimon_01876 "It's got the special property that each number appears in every row and every column just once" )
( henrySimon_01877 "So we'll take one of our subjects and they will listen across a row of this square, so they will hear Sentence A said by synthesiser number zero" )
( henrySimon_01878 "And they would perform a task" )
( henrySimon_01879 "Now here we're doing an intelligibility task where it's absolutely crucial that no subject hear's the same sentence more than once" )
( henrySimon_01880 "So they must make one pass through one row of the Matrix, and they can't do any of the other rows" )
( henrySimon_01881 "So they'll typing in what they heard, and then they'll move on and they'll hear the next one on the listening across a row of this Latin Square, and you'll notice that they're going to hear every sentence just once each and each time, it said, by a different synthesiser, different number in that cell" )
( henrySimon_01882 "And then this achieves the property that we only hear each sentence once, but the subjects hearing all the different synthesises so they'll be somehow calibrated" )
( henrySimon_01883 "Their relative judgments will be affected by having heard both the best and the worst synthesiser and not only bad ones are only good ones" )
( henrySimon_01884 "Now, when this subject has completed this row of the square, they've heard every synthesiser Well each synthesiser was only saying a single sentence" )
( henrySimon_01885 "So that's not fair, because sentence A might be easier to synthesise then sentence B so at the moment System zero has an unfair advantage" )
( henrySimon_01886 "So we need to complete that" )
( henrySimon_01887 "We need to balance the design by taking another subject and listening to the sentences said by a different permutation off the synthesisers and work our way down these rows" )
( henrySimon_01888 "So we've got five individual subjects, but they're grouped together in forming a single virtual listener" )
( henrySimon_01889 "And so we need to have at least five people" )
( henrySimon_01890 "And if we want more than five, we need multiples of five" )
( henrySimon_01891 "So we put the same number of people in each row" )
( henrySimon_01892 "This virtual listener, composed of five human beings, listens like this through the Latin square and they hear every synthesiser saying every sentence" )
( henrySimon_01893 "That's five by five, 25 things" )
( henrySimon_01894 "But no individual human being ever hears the same sentence twice" )
( henrySimon_01895 "And then we just aggregate the opinions or the responses in this case, the type in responses, for example, word error rates across all subjects to form our final statistics" )
( henrySimon_01896 "The assumption here is that all subjects behave the same and that we can take five individual people, split the test across them and then aggregate the results" )
( henrySimon_01897 "Okay, we got into a bit of detail there about a very specific listening test design, although it is a very highly recommended one and it's widely used, particularly in the Blizzard Challenge, to make sure that we don't have effects off repeated presentation of the same text to a listener" )
( henrySimon_01898 "And that's crucial in intelligibility because they will remember those sentences" )
( henrySimon_01899 "So we're talking still about subjective evaluation, in other words, using listeners and getting them to do a task" )
( henrySimon_01900 "We decided what the task might be, such as typing in or choosing from a five point scale" )
( henrySimon_01901 "We looked at various test interfaces" )
( henrySimon_01902 "They might be pull down menus or type in boxes and if it's necessary, and it very often is, using this between subjects design to remove the problem of repeated stimuli" )
( henrySimon_01903 "But what sentences are we actually going to synthesise and play to the listeners? In other words, what are the materials we should use Now there's a possible tension when choosing the materials to record" )
( henrySimon_01904 "If our systems for a particular domain, maybe it's a personal assistant, we would probably want to synthesise this sentences in that domain on measure its performance, saying naturalness on such sentences" )
( henrySimon_01905 "That might conflict with other requirements of evaluation and the sort of analysis we might want to do, particularly if we want to test intelligibility" )
( henrySimon_01906 "So we might sometimes even want to use isolated words to narrow down the range of possible errors a listener can make and make our analysis much simpler" )
( henrySimon_01907 "So could even use minimal pairs" )
( henrySimon_01908 "That's not so common these days" )
( henrySimon_01909 "But it's still possible" )
( henrySimon_01910 "Or more likely we'll use full sentences to get bit more variety, but also to make things a little harder to analyse" )
( henrySimon_01911 "That's gonna be a lot more pleasant for listeners" )
( henrySimon_01912 "Let's look at the sort of materials that are typical when testing intelligibility" )
( henrySimon_01913 "We would perhaps prefer to use nice, normal sentences, either from the domain of application or pull from a source such as a newspaper" )
( henrySimon_01914 "The problem with these sentences is that in quiet conditions, which we hope our listeners are in" )
( henrySimon_01915 "We'll tend to get a ceiling effect" )
( henrySimon_01916 "They're basically perfectly intelligible" )
( henrySimon_01917 "Now that's success in the sense that our system works" )
( henrySimon_01918 "But it's not useful experimentally because we can't tell the difference between different systems" )
( henrySimon_01919 "One might be more intelligible than the other" )
( henrySimon_01920 "We can't tell if they're both synthesising such easy material, and so we have to pull them apart by making things harder for listeners" )
( henrySimon_01921 "The standard way of making the task harder for listeners is to make the sentences less predictable and we tend to pick things that are syntactically correct, because otherwise it would sound very unnatural but semantically unpredictable because they kind of have conflicting meanings within them" )
( henrySimon_01922 "These are very far from actual system usage" )
( henrySimon_01923 "That's a reasonable criticism of them, but they will take us away from the ceiling effect and help us to differentiate between different systems" )
( henrySimon_01924 "That could be very important, especially in system development" )
( henrySimon_01925 "A simpler way off doing intelligibility testing that gets us down to specific individual errors is to use minimal pairs and will typically embed them in sentences because it's nicer for the listener" )
( henrySimon_01926 "Now we will say cold again" )
( henrySimon_01927 "We'll say gold again" )
( henrySimon_01928 "They differing one phonetic feature and we can tell if I synthesizer is making that error" )
( henrySimon_01929 "This is very, very time consuming because we're getting one small data point from this full sentence" )
( henrySimon_01930 "That's actually rarely used these days, much more common" )
( henrySimon_01931 "in fact, fairly standard is to use semantically unpredictable sentences" )
( henrySimon_01932 "These could be generated by algorithm from template or a set of template sentences into which slots we drop words from some lists" )
( henrySimon_01933 "And those lists might be of words of controlled frequency, medium frequency words or so on" )
( henrySimon_01934 "There are other standards out there for measuring intelligibility as there are for Naturalness and for quality" )
( henrySimon_01935 "You need to be a little bit careful about just simply applying these standards because they're almost exclusively developed for measuring natural speech" )
( henrySimon_01936 "And so what they're trying to capture is not the effects of synthetic speech, but the effects of a transmission channel and the degradations it's imposed upon original natural speech, so these don't always automatically translate to the synthetic speech situation" )
( henrySimon_01937 "There are other ways than semantically unpredictable sentences to avoid the ceiling effect" )
( henrySimon_01938 "We might have the noise that's always going to make the task harder" )
( henrySimon_01939 "We might distract the listener with a parallel task that's increasing their cognitive load" )
( henrySimon_01940 "But in this case, we're now starting to worry again that we're measuring something about the listeners ability and not about synthetic speech" )
( henrySimon_01941 "Maybe you can think off some novel ways to avoid the ceiling effect without using rather unnatural, semantically unpredictable sentences" )
( henrySimon_01942 "Naturalness is more straightforward because we can use normal sentences" )
( henrySimon_01943 "Naturalness more straightforward" )
( henrySimon_01944 "We can use relatively normal sentence" )
( henrySimon_01945 "Just pull them from some domain" )
( henrySimon_01946 "It could be the domain of usage of the system" )
( henrySimon_01947 "It might be some other domain" )
( henrySimon_01948 "We still, though, might pay a little bit of attention to them and use some design text" )
( henrySimon_01949 "And the most common form of that are sometimes known as the Harvard or the IEEE sentences" )
( henrySimon_01950 "These have the nice property that within these lists, there's some phonetic balance" )
( henrySimon_01951 "Now, while using listeners to evaluate your synthetic speech is by far the most common thing to do" )
( henrySimon_01952 "It would be nice if we could find a measure an algorithm perhaps that could evaluate objectively" )
( henrySimon_01953 "So we're using the word objectively here to imply that listeners are subjective" )
( henrySimon_01954 "So is that possible? In a subjective test, we have subjects, and they express perhaps an opinion about the synthetic speech" )
( henrySimon_01955 "In an objective test, we have an algorithm" )
( henrySimon_01956 "It might be a simpler is measuring distances between synthetic speech and a reference sample, which is almost certainly going to be natural speech" )
( henrySimon_01957 "Or we might use some more sophisticated model and the model will try and take account of human perception" )
( henrySimon_01958 "So let's turn our minds then to whether an objective measure is even possible" )
( henrySimon_01959 "Think about why it would be non trivial, and then we'll look at what can be done so far" )
( henrySimon_01960 "But throughout all of this, let's always remember that were not yet able to replace listeners" )
( henrySimon_01961 "Simple, objective measures involve just comparing synthetic speech to a reference" )
( henrySimon_01962 "The reference will be natural speech and the comparison will probably be just some distance" )
( henrySimon_01963 "Now there's already a huge number of assumptions in doing that" )
( henrySimon_01964 "First of all, it assumes that natural speech is somehow gold standard, and we can't do better than that" )
( henrySimon_01965 "But any natural speaker's rendition of a sentence is just one possible way of saying that sentence" )
( henrySimon_01966 "And there are many, many possible ways" )
( henrySimon_01967 "It also assumes that distance between a synthetic sample on this natural reference is somehow going to indicate what listeners would have said about it is going to correlate with their opinion score" )
( henrySimon_01968 "Most objective measures are just a sum of local differences" )
( henrySimon_01969 "So we're going to align the natural and synthetic that could be just, say, dynamic, time warping" )
( henrySimon_01970 "Or we could force out synthesisers to generate speech with the same durational pattern is a natural reference" )
( henrySimon_01971 "And then we'll sum the local differences, and that will be some total distance" )
( henrySimon_01972 "And that would be our measure, and a large distance would imply less natural" )
( henrySimon_01973 "But this use off a single natural reference as gold standard is obviously flawed for the reason that we've already stated: there is more than one correct way of saying any sentence" )
( henrySimon_01974 "So the method, as it stands, fails to account for natural variation" )
( henrySimon_01975 "We could try and mitigate that by having multiple natural examples" )
( henrySimon_01976 "We can't really capture all of the possible valid and correct natural ways of saying a sentence" )
( henrySimon_01977 "These simple, objective measures are just based on properties of the signal" )
( henrySimon_01978 "That's all we have to go on" )
( henrySimon_01979 "And the properties are the obvious things, the stuff that might correlate with phonetic identity" )
( henrySimon_01980 "For example, spectral envelope and the stuff that might correlate with prosody, F0 contour, maybe energy" )
( henrySimon_01981 "For the special envelope, we just think about a distortion of the difference between natural and synthetic" )
( henrySimon_01982 "We would want to do that in a representation that's, somehow relevant to perception, captures some perceptual properties" )
( henrySimon_01983 "And one thing that we know off that does that is the Mel Cepstrum" )
( henrySimon_01984 "So Mel Cepstral distortion" )
( henrySimon_01985 "For an F0 contour, there's a couple of different things we might measure" )
( henrySimon_01986 "My just look at the difference in Hertz or some other units between the natural and synthetic contours" )
( henrySimon_01987 "And sum those up and calculate the root mean squared error between those two contours" )
( henrySimon_01988 "That's just a sum of local differences" )
( henrySimon_01989 "That has a problem that if there's just a small offset between the two that will turn up to look like rather a large error" )
( henrySimon_01990 "And so we might also measure the shape of the two contours with something like correlation" )
( henrySimon_01991 "If we produce a synthetic F0 contour that essentially has the right shape but is offset or is its amplitude is a little bit too big or too small, we would still predict that sounds very nice to listeners" )
( henrySimon_01992 "It has peaks in the right places, for example" )
( henrySimon_01993 "So for F0 we might have a pair of measures: Error and Correlation" )
( henrySimon_01994 "Let's just see what properties those measures are looking at" )
( henrySimon_01995 "So if we've got a natural and a synthetic version of a sentence, the first thing of course we're going to do is make some alignment between them" )
( henrySimon_01996 "So we'll extract some features" )
( henrySimon_01997 "Maybe MFCCs" )
( henrySimon_01998 "We'll do some procedure of alignment" )
( henrySimon_01999 "A good way to do that would be dynamic time warping" )
( henrySimon_02000 "That's just going to make some non linear alignment between these two sequences, matching up the most similar sound with the most similar sound" )
( henrySimon_02001 "And then we could take frames that have been aligned with one another and look at the local difference" )
( henrySimon_02002 "Maybe we'll take that frame there on its corresponding frame" )
( henrySimon_02003 "So those two were aligned by the dynamic time warping and we'll extract from this one" )
( henrySimon_02004 "This is just a spectrum with frequency here and magnitude" )
( henrySimon_02005 "Here we might extract the spectral envelope represent that with cepstrum" )
( henrySimon_02006 "We'll do the same here" )
( henrySimon_02007 "And in the cepstral domain" )
( henrySimon_02008 "compare these two things on measure the difference or distortion" )
( henrySimon_02009 "Then we'll just sum that up for every frame off the utterance" )
( henrySimon_02010 "That'll be Mel Cepstral Distortion" )
( henrySimon_02011 "Now this is a pretty low level signal measure is the same sort of thing we might do in speech recognition to say if two things were the same or different, but it's got some properties that seem reasonable" )
( henrySimon_02012 "If these two signals were identical than the distortion would be zero, that seems reasonable" )
( henrySimon_02013 "If the two signals were extremely different, distortion would be high and that seems reasonable" )
( henrySimon_02014 "So to that extent that will correlate with listeners judgments very high cepstral distortion would suggest that they'll say they sound very different or if played only the synthetic sample" )
( henrySimon_02015 "They would say that sounds very unnatural" )
( henrySimon_02016 "And zero distortion means the synthetic is identical to natural" )
( henrySimon_02017 "So for big differences, this measure is probably going to work, however, that relationship between Mel Cepstral Distortion and what listeners think isn't completely smooth and monotonic and so small differences are not going to be captured so reliably by this measure" )
( henrySimon_02018 "And in system development, as we incrementally improve our system, it's actually small differences that we really want to measure the most" )
( henrySimon_02019 "Nevertheless, this distance measure or distortion in the mel cepstral domain is very widely used in a statistical parametric synthesis" )
( henrySimon_02020 "It's very much the same thing that we're actually minimising when we're training our systems And so it's a possible measure of system performance or of predicted naturalness of the final speech" )
( henrySimon_02021 "Something to think about for yourself is, would this measure make sense for synthetic speech made by concatenation of wave forms, remembering that those are locally, essentially, perfectly natural, so any local frame is natural speech" )
( henrySimon_02022 "It might not be the same as the natural reference, but it's perfectly natural" )
( henrySimon_02023 "Would this measure capture naturalness of unit selection speech" )
( henrySimon_02024 "That's something to think about for yourself" )
( henrySimon_02025 "Let's move on to the other common thing to measure objectively, and that's F0 and here again" )
( henrySimon_02026 "We'll have to make some alignment between synthetic and natural" )
( henrySimon_02027 "We'll look at local differences" )
( henrySimon_02028 "Perhaps just this absolute difference or the mean squared difference and sum that up across so that we get this root mean squared error" )
( henrySimon_02029 "Correlation would measure the similarity in the shapes of these two things" )
( henrySimon_02030 "For example, whether they have peaks in the same place" )
( henrySimon_02031 "Again this has some reasonable properties" )
( henrySimon_02032 "If the contours are identical, the RMSE is zero" )
( henrySimon_02033 "And we would expect listeners to say this prosody was perfect or perfectly natural" )
( henrySimon_02034 "If they're radically different, we get a large error, and that's a prediction of unnatural this" )
( henrySimon_02035 "But once again, there are lots of valid natural contours" )
( henrySimon_02036 "And our one reference contour isn't the only way of saying the sentence, and so error won't perfectly correlate with listeners' opinions" )
( henrySimon_02037 "So the summary message for the simple objective measures is: you'll find them widely used and reported in the literature, especially for statistical parametric synthesis" )
( henrySimon_02038 "They have some uses, a development tool because they could be done very quickly during development without going out to listeners" )
( henrySimon_02039 "They're actually quite close to the measures were minimising when training statistical models anyway" )
( henrySimon_02040 "But we should exercise their use with caution and they're not a replacement for using listeners" )
( henrySimon_02041 "We might want to report these results alongside subjective results and if there's a disagreement, we'll probably believe the subjective result, and not this objective measure" )
( henrySimon_02042 "But these are very simple, low level, signal processing based measures" )
( henrySimon_02043 "There's not a whole lot to do with perception in here" )
( henrySimon_02044 "The cepstrum might be Mel cepstrum to get some perceptual warping" )
( henrySimon_02045 "In F0 we might not do it on Hertz" )
( henrySimon_02046 "We might put that onto a perceptual scale" )
( henrySimon_02047 "Maybe we'll just take the log and then expressed these differences in semitones" )
( henrySimon_02048 "We could put a little perceptual knowledge, but not a lot" )
( henrySimon_02049 "And so it seems reasonable to try and put much more complex perceptual model into our objective measure" )
( henrySimon_02050 "There is a place where reasonably sophisticated models of perception in fact, things that have been fitted to perceptual data are widely used and are reliable" )
( henrySimon_02051 "They're in fact a part of international standards" )
( henrySimon_02052 "And that's from the field of telecommunications" )
( henrySimon_02053 "So once again, for the transmission of natural speech, which gets distorted in transmission on these things either measure the receive signal or the difference between the transmitted and received signal" )
( henrySimon_02054 "The standard measure until recently was called PESQ and recently, there's a new, better measure being proposed that's called POLQA" )
( henrySimon_02055 "These both standards the exist in software implementation and they're used widely by telecommunications companies" )
( henrySimon_02056 "As they stand - certainly you can say for PESQ - they don't well correlate, or they don't in fact correlate at all with listeners opinions of synthetic speech" )
( henrySimon_02057 "So we can't just take these black boxes and use them to evaluate the naturalness of synthetic speech, pretending that synthetic species just a distorted form of natural speech because the distortions are completely different to the sort of distortions we get in transmission of speech" )
( henrySimon_02058 "However, there are attempts to take these measures, which are typically big combinations of many, many different features and modify them" )
( henrySimon_02059 "For example, modify the weights in this waited combination and fit those weights to listening test results for synthetic speech" )
( henrySimon_02060 "So there are some modified versions, and they do work to some limited extent" )
( henrySimon_02061 "They're not yet good enough to replace listeners, but they are now correlating, roughly speaking with listeners opinions" )
( henrySimon_02062 "So to wrap this part up" )
( henrySimon_02063 "There are standards out there, like PESQ" )
( henrySimon_02064 "That's tempting to think we could just apply those two synthetic speech, and they will give us a number" )
( henrySimon_02065 "Unfortunately, that number's pretty meaningless" )
( henrySimon_02066 "It's not a good predictor of what listeners would say if we did the proper listening test" )
( henrySimon_02067 "We could try modifying PESQ which has been done" )
( henrySimon_02068 "So that's about all we have to say about the evaluation of speech synthesis" )
( henrySimon_02069 "We could evaluate things about the system, but mainly we wanted evaluate the speech itself" )
( henrySimon_02070 "So it's the evaluation of synthetic speech" )
( henrySimon_02071 "And let's just wrap up by reminding ourselves why we were doing that in the first place and looking again at what to do with the outcome of that So let's just repeat our diagram of how research works and, indeed, how development works We need carefully controlled experiments to tell the differences between, for example, these four system variants that might be all very similar" )
( henrySimon_02072 "Brilliant idea may have made only a very small improvement in the quality of the synthetic speech" )
( henrySimon_02073 "We need a very sensitive evaluation that can detect that and tell us to take that improvement forward and to leave the others behind" )
( henrySimon_02074 "We need to make sure there's no confounding factors" )
( henrySimon_02075 "So when we look at these 1, 2, 3, 4 systems, the only difference between them must be the thing we changed and everything else must be kept constant" )
( henrySimon_02076 "For example, the front end, the database, the signal processing, whatever we haven't changed must be identical, so there are no confounds when we do this evaluation and find that one of the variants was better and take it forward, we're then, assuming that it was our change that was responsible for that, what we can't do easily is do a listening test, Look at the result of it and somehow back propagate that through the pipeline of the text-to-speech system and find that it was the letter to sound system that was to blame" )
( henrySimon_02077 "Now that's because these pipeline architectures are simply not invertable" )
( henrySimon_02078 "We can push things through them one direction" )
( henrySimon_02079 "We can't push the errors back through them in the other direction" )
( henrySimon_02080 "If we had a complete end-to-end machine learning approach to the problem, for example, a great big neural net that went all the way from text to a waveform, we could imagine now back propagating errors through the system" )
( henrySimon_02081 "And that's one direction to field is heading into - something that's learnable in an end to end fashion and not just in a modular fashion" )
( henrySimon_02082 "However, we're not quite there yet" )
( henrySimon_02083 "Of course, that great big machine learning black box isn't a final solution, because although we might be able to learn in an end-to-end fashion When it does make mistakes, we really can't point to any part of the system to blame for it because it's a black box" )
( henrySimon_02084 "So there's still an advantage of a pipeline architecture made of modules that we understand that we can take apart and we can replace" )
( henrySimon_02085 "Let's finish off with a table of recommendations about what test to use to measure what property, so depending what you want to evaluate" )
( henrySimon_02086 "What tests should you pick? Naturalness is the most common thing to be evaluated" )
( henrySimon_02087 "It's perfectly good to use Mean Opinion Score very often on a five point scale that you might like a seven point scale for some reason, or something that's closely related to that which is MUSHRA, which has a built in error checking and calibration mechanism" )
( henrySimon_02088 "And a forced choice is also perfectly okay, because it's quite a straightforward task to explain to listeners which of these two sample sounds the most natural" )
( henrySimon_02089 "I can't immediately think of a task that you could ask listeners to do other than those things from which you could gauge the naturalness of a signal" )
( henrySimon_02090 "Similarity to Target Speaker is essentially the same sort of task is naturalness, so people tend to do MOS or MUSHRA type tests" )
( henrySimon_02091 "Obviously, with a reference sample of what the target speakers supposed to sound like" )
( henrySimon_02092 "You could use forced choice to say which of the two sounds more like a particular target speaker Judging whether something is or is not a target speaker is a slightly odd task for listeners because in real life, someone either is or is not the target making graded distinctions maybe a little bit tricky" )
( henrySimon_02093 "This is probably fine" )
( henrySimon_02094 "One thing you'll find in the literature and indeed in some standards, is the use of the opinion scores to rate intelligibility" )
( henrySimon_02095 "It's hard to see where that will be acceptable" )
( henrySimon_02096 "How do you know whether you've understood something? Okay, so if something is perfectly intelligible or very unintelligible, then we could make a judgement on that and give an opinion" )
( henrySimon_02097 "But fine distinctions" )
( henrySimon_02098 "If we miss here a word, how do we know we've misheard it? So I would never recommend the use of opinion scores or MUSHRA or anything like that to rate intelligibility" )
( henrySimon_02099 "I would only really, ever trust people typing in what they heard as a task" )
( henrySimon_02100 "The only exception to That might be if there are only a couple of possible things they could hear, such as in minimal pairs, and you could possibly do a forced choice" )
( henrySimon_02101 "But this is very uncommon these days" )
( henrySimon_02102 "You will see reports or evaluations that don't really say what they're looking for It's just preference" )
( henrySimon_02103 "They're implying natural" )
( henrySimon_02104 "That's probably but maybe not saying it" )
( henrySimon_02105 "In this case, if we're really not sure what we're asking listeners to do, we're just saying, Do you like this system more or this other system more and all you can really do is forced choice preference test, because you're not really telling them what to listen to it all, just an overall preference that would also be appropriate for choosing between two different voices, which was most pleasant, for example, which is different to naturalness" )
( henrySimon_02106 "Well, we've reached the end of the first part of the course" )
( henrySimon_02107 "And it's all about unit selection, the data behind it and how to evaluate it" )
( henrySimon_02108 "What we'll move on to next is a different form of synthesis, and that's called Statistical Parametric Speech Synthesis" )
( henrySimon_02109 "And what you've learned in this unit selection part will still be highly relevant for several reasons" )
( henrySimon_02110 "Of course, we will want to evaluate that synthesis from the statistical parametric method" )
( henrySimon_02111 "And what we've talked about in this module on evaluation, all still applies" )
( henrySimon_02112 "We'll still need a database" )
( henrySimon_02113 "We'll probably still want coverage in that database, although it might not be as important as in unit Selection" )
( henrySimon_02114 "And eventually we'll join together the statistical parametric method and the unit selection method for something called hybrid synthesis" )
( henrySimon_02115 "So now that you know all of this, take what we've learned and go and put it into practise and go and build your own unit selection voice" )
